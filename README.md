# Currently Hosted at : https://ami-sme-frontend-production.up.railway.app/chat 

# AI SME - Intelligent Documentation Assistant

An AI-powered assistant trained on Confluence documentation and GitHub codebases to answer team questions and provide instant access to documentation and code references.

## ğŸ¯ Project Overview

This POC demonstrates an enterprise-grade RAG (Retrieval Augmented Generation) system that:
- Indexes Confluence documentation and GitHub repositories
- Answers questions with source citations
- Supports uploading additional documents (PDF, DOCX, TXT)
- Provides a modern chat interface for developers

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     React Frontend (Next.js)        â”‚
â”‚  - Chat UI                          â”‚
â”‚  - Document Upload                  â”‚
â”‚  - Source Display                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     FastAPI Backend                 â”‚
â”‚  - RAG Pipeline                     â”‚
â”‚  - Document Processing              â”‚
â”‚  - API Endpoints                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     ChromaDB Vector Store           â”‚
â”‚  - Embeddings                       â”‚
â”‚  - Semantic Search                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
AI SME/
â”œâ”€â”€ backend/              # Python backend service
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ scrapers/    # Confluence & GitHub scrapers
â”‚   â”‚   â”œâ”€â”€ indexers/    # Document indexing logic
â”‚   â”‚   â”œâ”€â”€ rag/         # RAG pipeline implementation
â”‚   â”‚   â”œâ”€â”€ api/         # FastAPI endpoints
â”‚   â”‚   â”œâ”€â”€ config/      # Configuration management
â”‚   â”‚   â””â”€â”€ utils/       # Helper utilities
â”‚   â”œâ”€â”€ tests/           # Backend tests
â”‚   â”œâ”€â”€ requirements.txt # Python dependencies
â”‚   â”œâ”€â”€ .env.example     # Environment template
â”‚   â””â”€â”€ main.py          # Application entry point
â”œâ”€â”€ frontend/            # React frontend
â”‚   â”œâ”€â”€ app/            # Next.js app directory
â”‚   â”œâ”€â”€ components/     # React components
â”‚   â”œâ”€â”€ lib/            # Utilities & API client
â”‚   â””â”€â”€ package.json    # Node dependencies
â”œâ”€â”€ data/               # Data storage
â”‚   â”œâ”€â”€ raw/           # Raw scraped data
â”‚   â””â”€â”€ processed/     # Processed documents
â”œâ”€â”€ docs/              # Documentation
â””â”€â”€ docker-compose.yml # Container orchestration
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Node.js 18+
- OpenAI API key (or Azure OpenAI)

### Backend Setup

```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
cp .env.example .env
# Edit .env with your API keys
python main.py
```

### Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

## ğŸ”§ Configuration

Create a `.env` file in the backend directory:

```env
OPENAI_API_KEY=your_key_here
VECTOR_DB_PATH=./chroma_db
CONFLUENCE_BASE_URL=https://your-confluence.atlassian.net
GITHUB_TOKEN=your_github_token
```

## ğŸ“Š Current Status

### âœ… Week 1 Progress (Backend Foundation)
- [ ] Project structure setup
- [ ] Confluence scraper
- [ ] GitHub indexer
- [ ] Vector database setup
- [ ] RAG pipeline
- [ ] API endpoints
- [ ] Document upload processing

### ğŸ”œ Week 2 (Frontend Development)
- [ ] Next.js setup
- [ ] Chat interface
- [ ] Source citations display
- [ ] File upload UI
- [ ] Advanced features

### ğŸ”œ Week 3 (Polish & Demo)
- [ ] Quality improvements
- [ ] Admin panel
- [ ] Documentation
- [ ] Deployment setup

## ğŸ“ POC Data Source

Currently using **Apache Kafka** project for POC:
- **Confluence**: https://cwiki.apache.org/confluence/display/KAFKA
- **GitHub**: https://github.com/apache/kafka

This demonstrates the system with real-world, production-quality documentation and code.

## ğŸ“ License

Internal use only - Wells Fargo

## ğŸ‘¥ Contact

For questions or support, contact the development team.
