# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4-turbo-preview
EMBEDDING_MODEL=text-embedding-3-large

# Alternative: Azure OpenAI (for Wells Fargo production)
# AZURE_OPENAI_API_KEY=your_azure_key
# AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/
# AZURE_OPENAI_DEPLOYMENT_NAME=your-deployment
# AZURE_OPENAI_API_VERSION=2024-02-15-preview

# Vector Database
VECTOR_DB_TYPE=chroma  # Options: chroma, pinecone
VECTOR_DB_PATH=./chroma_db
CHROMA_PERSIST_DIRECTORY=./chroma_db

# Pinecone (optional - if using Pinecone instead of ChromaDB)
# PINECONE_API_KEY=your_pinecone_key
# PINECONE_ENVIRONMENT=us-west1-gcp
# PINECONE_INDEX_NAME=ai-sme-index

# Data Sources
CONFLUENCE_BASE_URL=https://cwiki.apache.org/confluence
GITHUB_ORG=apache
GITHUB_REPOS=kafka

# GitHub Authentication (optional - for private repos)
# GITHUB_TOKEN=your_github_token_here

# Confluence Authentication (for private Confluence - not needed for POC)
# CONFLUENCE_USERNAME=your.email@company.com
# CONFLUENCE_API_TOKEN=your_confluence_api_token

# Application Settings
APP_NAME=AI SME Assistant
APP_VERSION=1.0.0
DEBUG=true
LOG_LEVEL=INFO

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
CORS_ORIGINS=http://localhost:3000,http://localhost:3001

# RAG Configuration
CHUNK_SIZE=800
CHUNK_OVERLAP=100
RETRIEVAL_TOP_K=5
LLM_TEMPERATURE=0.3
MAX_RESPONSE_TOKENS=1000

# Document Upload
MAX_UPLOAD_SIZE_MB=10
ALLOWED_FILE_TYPES=.txt,.md,.pdf,.docx,.doc

# Redis (optional - for conversation memory)
# REDIS_URL=redis://localhost:6379
# REDIS_PASSWORD=

# Rate Limiting
RATE_LIMIT_PER_MINUTE=60

# Monitoring (optional)
# SENTRY_DSN=your_sentry_dsn
