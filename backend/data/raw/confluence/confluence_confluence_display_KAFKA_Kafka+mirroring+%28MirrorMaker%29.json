{
  "id": "confluence_display_KAFKA_Kafka+mirroring+%28MirrorMaker%29",
  "title": "Kafka mirroring (MirrorMaker) - Apache Kafka - Apache Software Foundation",
  "content": "Kafka's mirroring feature makes it possible to maintain a replica of an existing Kafka cluster. The following diagram shows how to use the\nMirrorMaker\ntool to mirror a source Kafka cluster into a target (mirror) Kafka cluster. The tool uses a Kafka consumer to consume messages from the source cluster, and re-publishes those messages to the local (target) cluster using an embedded Kafka producer.\nThere is also documentation on the MirrorMaker at\nhttps://kafka.apache.org/documentation.html#basic_ops_mirror_maker\n.\nHow to set up a mirror\nSetting up a mirror is easy - simply start up the mirror-maker processes after bringing up the target cluster. At minimum, the mirror maker takes one or more consumer configurations, a producer configuration and either a whitelist or a blacklist. You need to point the consumer to the source cluster's ZooKeeper, and the producer to the mirror cluster's ZooKeeper (or use the\nbroker.list\nparameter).\nbin/kafka-mirror-maker.sh --consumer.config sourceCluster1Consumer.config --consumer.config sourceCluster2Consumer.config --num.streams 2 --producer.config targetClusterProducer.config --whitelist=\".*\"\nImport configuration parameters for the mirror maker\nWhitelist or blacklist\nThe mirror-maker accepts exactly one of whitelist or blacklist. These are standard Java regex patterns, although comma (',') is interpreted as the regex-choice symbol ('|') for convenience.\nProducer timeout\nIn order to sustain a higher throughput, you would typically use an asynchronous embedded producer and it should be configured to be in blocking mode (i.e.,\nqueue.enqueueTimeout.ms=-1\n). This recommendation is to ensure that messages will not be lost. Otherwise, the default enqueue timeout of the asynchronous producer is zero which means if the producer's internal queue is full, then messages will be dropped due to\nQueueFullExceptions\n. A blocking producer however, will wait if the queue is full, and effectively throttle back the embedded consumer's consumption rate. You can enable trace logging in the producer to observe the remaining queue size over time. If the producer's queue is consistently full, it indicates that the mirror-maker is bottle-necked on re-publishing messages to the local (mirror) cluster and/or flushing messages to disk.\nProducer retries\nIf you use\nbroker.list\nin the producer configuration and point it to a hardware load-balancer, then you can configure the number of retry attempts on producer failures. (The retry option only applies when you specify a load-balancer in the\nbroker.list\noption since the broker is re-selected on retry only if you use a hardware load-balancer.)\nNumber of producers\nYou can use the\n--num.producers\noption to use a producer pool in the mirror maker to increase throughput. This helps because each producer's requests are effectively handled by a single thread on the receiving Kafka broker. i.e., even if you have multiple consumption streams (see next section), the throughput can be bottle-necked at handling stage of the mirror maker's producer requests.\nNumber of consumption streams\nUse the\n--num.streams\noption to specify the number of mirror consumer threads to create. Note that if you start multiple mirror maker processes then you may want to look at the distribution of partitions on the source cluster. If the number of consumption streams is too high per mirror maker process, then some of the mirroring threads will be idle by virtue of the consumer rebalancing algorithm (if they do not end up owning any partitions for consumption).\nShallow iteration and producer compression (Kafka 0.7)\n(N/A for Kafka 0.8, see JIRA issue KAFKA-732 )\nOur recommendation is to enable shallow iteration in the mirror maker's consumer. This means that the mirror maker's consumer will not attempt to decompress message-sets of compressed messages. It will simply re-publish these messages as is.\nIf you enable shallow iteration, you must disable compression in the mirror maker's producer, or message-sets can become double-compressed.\nConsumer and source cluster socket buffer sizes\nMirroring is often used in cross-DC scenarios, and there are a few configuration options that you may want to tune to help deal with inter-DC communication latencies and performance bottlenecks on your specific hardware. In general, you should set a high value for the socket buffer size on the mirror-maker's consumer configuration (\nsocket.buffersize\n) and the source cluster's broker configuration (socket.send.buffer). Also, the mirror-maker consumer's fetch size (\nfetch.size\n) should be higher than the consumer's socket buffer size. Note that the socket buffer size configurations are a hint to the underlying platform's networking code. If you enable trace logging, you can check the actual receive buffer size and determine whether the setting in the OS networking layer also needs to be adjusted.\nHow to check whether a mirror is keeping up\nThe consumer offset checker tool is useful to gauge how well your mirror is keeping up with the source cluster. Note that the\n--zkconnect\nargument should point to the source cluster's ZooKeeper (DC1 in this scenario). Also, if the topic is not specified, then the tool prints information for all topics under the given consumer group. For example:\nbin/kafka-consumer-offset-checker.sh --group KafkaMirror --zkconnect dc1-zookeeper:2181 --topic test-topic\nGroup           Topic                          Pid Offset          logSize         Lag             Owner\nKafkaMirror     test-topic                     0   5               5               0               none\nKafkaMirror     test-topic                     1   3               4               1               none\nKafkaMirror     test-topic                     2   6               9               3               none",
  "url": "https://cwiki.apache.org/confluence/display/KAFKA/Kafka+mirroring+%28MirrorMaker%29",
  "space": "KAFKA",
  "labels": [],
  "last_modified": null,
  "source_type": "confluence"
}