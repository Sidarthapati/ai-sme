{
  "id": "confluence_display_KAFKA_Consumer+API+changes",
  "title": "Consumer API changes - Apache Kafka - Apache Software Foundation",
  "content": "New consumer API\n/**\n*  Create a list of MessageStreams for each topic.\n*\n*  @param topicCountMap  a map of (topic, #streams) pair\n*  @param decoder Decoder to decode each Message to type T\n*  @return a map of (topic, list of KafkaStream) pairs.\n*          The number of items in the list is #streams. Each stream supports\n*          an iterator over message/metadata pairs.\n*/\ndef createMessageStreams[T](topicCountMap: Map[String,Int],\ndecoder: Decoder[T] = new DefaultDecoder)\n: Map[String,List[KafkaStream[T]]]\n/**\n*  Create a list of message streams for all topics that match a given filter.\n*\n*  @param topicFilter Either a Whitelist or Blacklist TopicFilter object.\n*  @param numStreams Number of streams to return\n*  @param decoder Decoder to decode each Message to type T\n*  @return a list of KafkaStream each of which provides an\n*          iterator over message/metadata pairs over allowed topics.\n*/\ndef createMessageStreamsByFilter[T](topicFilter: TopicFilter,\nnumStreams: Int = 1,\ndecoder: Decoder[T] = new DefaultDecoder)\n: Seq[KafkaStream[T]]\nQuestions/discussion\nWhat is a\nTopicFilter\n?\nTopicFilter\ncan be either a whitelist or a blacklist. e.g.,\nExample of a whitelist\nTopicFilter\n:\nnew Whitelist(\"white.*\")\nExample of a blacklist\nTopicFilter\n:\nnew Blacklist(\"black.*\")\nAlthough Java regex allows you to specify anything with a single regex (i.e., you don't really need a blacklist option per se), negating a whitelist in Java regex is clumsy. It is convenient to be able to easily specify a whitelist and blacklist. Although right now\nTopicFilter\nsupports only one of whitelist/blacklist in future we may want to support a chain of filters to do more elaborate topic selection.\nWhat is a\nMessageAndMetadata\n?\ncase class MessageAndMetadata[T](message: T, topic: String = \"\", offset: Long = -1L)\nThe\nKafkaStream[T]\n's iterator is a\nConsumerIterator[T]\nwhich is an iterator over\nMessageAndMetadata[T]\nobjects.\nCan we eliminate the need for two methods in the API? Also, providing a topic-count-map in the\ncreateMessageStreams\nAPI is burdensome. Can we get rid of that?\nIf we don't support the one-shot approach of creating multiple streams for multiple topics, then the most obvious alternative is:\ndef createMessageStreams[T](topic: String, numStreams: Int,\ndecoder: Decoder[T] = new DefaultDecoder)\n: Seq[KafkaStream[T]]\nAdvantages\nSimpler, more intuitive API which is consistent with the\ncreateMessageStreamsByFilter\nAPI as well.\nIt may be possible to combine the\ncreateMessageStreams\nand\ncreateMessageStreamsByFilter\ncalls into one API. This would need to be fleshed out in some detail, but we could have a higher-level\nTopic\nclass that can either be a static topic, or a\nTopicFilter\n. Another advantage of this is that the high-level\nTopic\nclass it could do things like validate topic names. However, the consumer code would need to explicitly call (\nnew Topic(new Whitelist(\"white.*\")\n) or (\nnew Topic(\"topicname\")\n) but that does not seem so bad.\nDisadvantages\nThe above also reveals an advantage of creating multiple streams for multiple topics at one-shot . If you want to create multiple streams for multiple topics, then you would need to make a\ncreateMessageStreams\ncall for each topic, which would trigger one rebalance for each topic. With the one-shot call (which receives atopic-count-map), only one rebalance (for all topics) will be required.\nNot a disadvantage, but additional work: the consumer connector code is currently broken with respect to supporting multiple calls to\ncreateMessageStreams\non the same connector object. For example, the\nconsumerIdString\nis per connector object, and not per call. There are a bunch of other global variables that may need to become per-call instances. Anyway, the point is that we would need to completely fix that if we want to deprecate the option to provide a topic-count-map.\nImpact to clients\nClient code will need to change, since the current pattern of:\nfor (message <- stream) {\n// process(message)\n}\nwill change to:\nfor (msgAndMetadata <- stream) {\n// processMessage(msgAndMetadata.message)\n// can also access msgAndMetadata.offset, topic, etc. if appropriate\n}\nExisting API\n/**\n*  Create a list of MessageStreams for each topic.\n*\n*  @param topicCountMap  a map of (topic, #streams) pair\n*  @return a map of (topic, list of  KafkaMessageStream) pair. The number of items in the\n*          list is #streams. Each KafkaMessageStream supports an iterator of messages.\n*/\ndef createMessageStreams[T](topicCountMap: Map[String,Int],\ndecoder: Decoder[T] = new DefaultDecoder)\n: Map[String,List[KafkaMessageStream[T]]]\nReferences\nhttps://issues.apache.org/jira/browse/KAFKA-249\nMailing list discussion",
  "url": "https://cwiki.apache.org/confluence/display/KAFKA/Consumer+API+changes",
  "space": "KAFKA",
  "labels": [],
  "last_modified": null,
  "source_type": "confluence"
}