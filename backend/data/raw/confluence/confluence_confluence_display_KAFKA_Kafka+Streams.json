{
  "id": "confluence_display_KAFKA_Kafka+Streams",
  "title": "Kafka Streams - Apache Kafka - Apache Software Foundation",
  "content": "Check out the docs at Apache Kafka web site:\nhttp://kafka.apache.org/documentation/streams/\nSub-pages:\nUsing Kafka Streams:\nUsage Patterns\nApplication Reset Tool\nJoin Semantics\nStreams FAQs\nData (Re)Processing Scenarios\nDevelopment:\nKIP overview by release\nDevelopment Plan\nDiscussions\nData (Re)Processing Scenarios\nKafka Streams DSL Grammar\nStreams Runtime Architecture with New Threading\nInternals:\nData Management\nArchitecture\nDSL Optimizer\nFind more links about Kafka Streams at\nKafka Ecosystem\npage.\nKafka Streams related\nKIPs\n:\nBelow is a list of KIPs that are not release yet. Go to\nKafka Streams KIP Overview\nfor KIPs by release (including discarded KIPs).\nUnder discussion\nKIP-1027: Add MockFixedKeyProcessorContext and TestFixedKeyRecordFactory\nKIP-1088: Replace KafkaClientSupplier with KafkaClientInterceptor\nKIP-1128: Replace KTable.transformValues with KTable.processValues and add new KStreams.process\n(draft)\nKIP-1174: Expose addReadOnlyStateStore in DSL (StreamsBuilder)\nKIP 1215: Graceful stop on Kafka Streams exceptions processing handlers\nKIP-1225: Add Optional TTL Support to Kafka Streams State Stores\nKIP-1238: Multipartition for TopologyTestDriver in Kafka Streams\nKIP-1244 Drop support for streams-scala in Kafka 5.0 (deprecate in 4.3)\nKIP-1245: Enforce 'application.server' <server>:<port> format at config level\nKIP-1253: Add TopologyValidator Utility for Kafka Streams Topology Compatibility\nKIP-1259: Add configuration to wipe Kafka Streams local state on startup\nKIP-1270: Introduce ProcessExceptionalHandler for GlobalThread\nKIP-1271: Allow to Store Record Headers in State Stores\nAdopted\ninactive, not (fully) implemented (feel free to pick up):\nKIP-149: Enabling key access in ValueTransformer, ValueMapper, and ValueJoiner\n(partially implemented in v1.1)\nKIP-216: IQ should throw different exceptions for different errors\nKIP-258: Allow to Store Record Timestamps in RocksDB\n(partially implemented in v2.3)\nKIP-300: Add Windowed KTable API in StreamsBuilder\n(accepted but postponed because current code base does not allow to implement it as proposed)\nKIP-328: Ability to suppress updates for KTables\n(partially implemented in v2.1)\nKIP-557: Add emit on change support for Kafka Streams\n(\npartially implemented in v2.6\nreverted again in 2.8.0, 2.7.1, and 2.6.2 due to potential data loss)\nKIP-655: Windowed Distinct Operation for Kafka Streams API\nKIP-796: Interactive Query v2\n(split up into multiple sub KIPs)\nKIP-878: Internal Topic Autoscaling for Kafka Streams\nKIP-1127 Flexible Windows for Late Arriving Data\nAccepted (blocked until 5.0 release):\nKIP-1125: Remove Invalid 'numberOfOpenFiles' Metric from RocksDB State Store\nWIP (open PR / in review):\nKIP-698: Add Explicit User Initialization of Broker-side State to Kafka Streams\nKIP-759: Unneeded repartition canceling\nKIP-770: Replace \"buffered.records.per.partition\" & \"cache.max.bytes.buffering\" with \"{statestore.cache}/{input.buffer}.max.bytes\"\n(partially implemented in v3.4)\nKIP-892: Transactional Semantics for StateStores\n(blocked â€“ waiting for KIP-1035 to be finished first)\nKIP-1035: StateStore managed changelog offsets\nKIP-1071: Streams Rebalance Protocol\n(Early Access in v4.1; General Availability with limited feature set in v4.2)\nKIP-1138: Clean Up TopologyConfig and API for supplying configs needed by the topology\nKIP-1250: Add metric to track size of in-memory state stores\nnext release Kafka 4.2 (merged):\nKIP-1034: Dead letter queue in Kafka Streams\nKIP-1071: Streams Rebalance Protocol\n(General Availability with limited feature set; not completed yet)\nKIP-1146: Anchored punctuation\nKIP-1153: Refactor Kafka Streams CloseOptions to Fluent API Style\nKIP-1195: deprecate and remove org.apache.kafka.streams.errors.BrokerNotFoundException\nKIP-1216: Add rebalance listener metrics for Kafka Streams\nKIP-1221: Add application-id tag to Kafka Streams state metric\nKIP-1230: Add config for file system permissions\nInactive (feel free to pick up and resume the discussion):\nKIP-159: Introducing Rich functions to Streams\nKIP-311: Async processing with dynamic scheduling in Kafka Streams\nKIP-314: KTable to GlobalKTable Bi-directional Join\nKIP-362: Support dynamic gap session window\nKIP-406: GlobalStreamThread should honor custom reset policy\nKIP-408: Add Asynchronous Processing To Kafka Streams\nKIP-424: Allow suppression of intermediate events based on wall clock time\nKIP-457: Add DISCONNECTED status to Kafka Streams\nKIP-459: Improve KafkaStreams#close\nKIP-463: Auto-configure non-default Serdes passed alongside the TopologyBuilder\nKIP-508: Make Suppression State Queriable\nKIP-513: Distinguish between Key and Value serdes in scala wrapper library for kafka streams\nKIP-540: Implement per key stream time tracking\nKIP-560: Auto infer external topic partitions in stream reset tool\nKIP-598: Augment TopologyDescription with store and source / sink serde information\nKIP-645: Replace Windows with a proper interface\nKIP-647: Add ability to handle late messages in streams-aggregation\nKIP-669: Preserve Source Partition in Kafka Streams from context\nKIP-674: Metric Reporter to Aggregate Metrics in Kafka Streams\nKIP-718: Make KTable Join on Foreign key unopinionated\nKIP-747 Add support for basic aggregation APIs\nKIP-807: Refactor KafkaStreams exposed metadata hierarchy\nKIP-816: Topology changes without local state reset\nKIP-819: Merge multiple KStreams in one operation\nKIP-839: Provide builders for KafkaProducer/KafkaConsumer and KafkaStreams\nKIP-857: Streaming recursion in Kafka Streams\nKIP-948: Allow custom prefix for internal topic names in Kafka Streams\nKIP-969: Support range Interactive Queries (IQv2) for Versioned State Stores\nKIP-997: update WindowRangeQuery and unify WindowKeyQuery and WindowRangeQuery",
  "url": "https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams",
  "space": "KAFKA",
  "labels": [],
  "last_modified": null,
  "source_type": "confluence"
}