{
  "id": "confluence_display_KAFKA_Ecosystem",
  "title": "Ecosystem - Apache Kafka - Apache Software Foundation",
  "content": "Here is a list of tools we have been told about that integrate with Kafka outside the main distribution. We haven't tried them all, so they may not work!\nClients, of course, are listed separately\nhere\n.\nKafka Connect\nKafka has a\nbuilt-in framework\ncalled Kafka Connect for writing sources and sinks that either continuously ingest data into Kafka or continuously ingest data in Kafka into external systems. The connectors themselves for different applications or data systems are federated and maintained separately from the main code base.\nAn externally hosted list of connectors is maintained by Confluent\nat the\nConfluent Hub\n.\nDistributions &\nPackaging\nConfluent:\nConfluent Cloud\n(SaaS, fully managed) and\nConfluent Platform\n(software download for self-managed/on-premise)\nCloudera distribution -\nhttps://www.cloudera.com/products/open-source/apache-hadoop/apache-kafka.html\nEmblocSoft distribution and CPFA training -\nhttps://www.emblocsoft.com/pages/en/solutions/kafka/support/\nIBM Event Streams -\nhttps://www.ibm.com/cloud/event-streams\n- Apache Kafka on premise and the public cloud\nStrimzi -\nhttp://strimzi.io/\n- Apache Kafka Operator for Kubernetes and Openshift. Downloads and Helm Chart -\nhttps://github.com/strimzi/strimzi-kafka-operator/releases/latest\nTIBCO Messaging - Apache Kafka Distribution -\nhttps://www.tibco.com/products/apache-kafka\nDownloads -\nhttps://www.tibco.com/products/tibco-messaging/downloads\nStream Processing\nKafka Streams\n- the built-in stream processing library of the Apache Kafka project\nDocumentation in Apache Kafka\nDocumentation in Confluent Platform\nKafka Streams code examples in Apache Kafka\nKafka Streams code examples provided by Confluent\nKafka Streams Ecosystem:\nComplex Event Processing (CEP):\nhttps://github.com/fhussonnois/kafkastreams-cep\n.\nFluent\nKafka Streams Test:\nhttps://github.com/bakdata/fluent-kafka-streams-tests\n(blog post:\nhttps://medium.com/bakdata/fluent-kafka-streams-tests-e641785171ec\n)\nAzkarra Streams\n- A lightweight java framework to make it easy to build and manage streaming microservices based on Kafka Streams.\nStorm\n- A stream-processing framework.\nSamza\n- A YARN-based stream processing framework.\nStorm Spout\n- Consume messages from Kafka and emit as Storm tuples\nKafka-Storm\n- Kafka 0.8, Storm 0.9, Avro integration\nSparkStreaming\n- Kafka receiver supports Kafka 0.8 and above\nFlink\n- Apache Flink has an integration with Kafka\nIBM Streams\n- A stream processing framework with Kafka source and sink to consume and produce Kafka messages\nSpring Cloud Stream\n- a framework for building event-driven microservices,\nSpring Cloud Data Flow\n- a cloud-native orchestration service for Spring Cloud Stream applications\nApache Apex\n- Stream processing framework with connectors for Kafka as source and sink.\nLogstash\n-\nInput\nand\nOutput\nplugins to enrich events and optionally store in Elasticsearch\nLogagent\n-\nKafka Input\nand\nKafka Output\nplugins\nHadoop Integration\nConfluent HDFS Connector\n- A sink connector for the Kafka Connect framework for writing data from Kafka to Hadoop HDFS\nCamus\n- LinkedIn's Kafka=>HDFS pipeline. This one is used for all data at LinkedIn, and works great.\nKafka Hadoop Loader\nA different take on Hadoop loading functionality from what is included in the main distribution.\nFlume\n- Contains Kafka source (consumer) and sink (producer)\nKaBoom\n- A high-performance HDFS data loader\nDatabase Integration\nConfluent JDBC Connector\n- A source connector for the Kafka Connect framework for writing data from RDBMS (e.g. MySQL) to Kafka\nOracle Golden Gate Connector\n- Source connector that collects CDC operations via Golden Gate and writes them to Kafka\nSearch and Query\nElasticsearch\n-\nThis project, Kafka Standalone Consumer will read the messages from Kafka, processes and index them in Elasticsearch. There are also several\nKafka Connect connectors for Elasticsearch\n.\nPresto\n- The Presto Kafka connector allows you to query Kafka in SQL using Presto.\nHive\n- Hive SerDe that allows querying Kafka (Avro only for now) using Hive SQL\nOpenMLDB Kafka Connector\n-\nThis project allows you to define and extract features from data streams using SQL for ML applications.\nManagement Consoles\nKafka Manager\n-\nA tool for managing Apache Kafka.\nkafkat\n- Simplified command-line administration for Kafka brokers.\nKafka Web Console\n- Displays information about your Kafka cluster including which nodes are up and what topics they host data for.\nKafka Offset Monitor\n- Displays the state of all consumers and how far behind the head of the stream they are.\nCapillary\n–\nDisplays the state and deltas of Kafka-based\nApache Storm\ntopologies. Supports Kafka >= 0.8. It also provides an API for fetching this information for monitoring purposes.\nDoctor Kafka\n- Service for cluster auto healing and workload balancing.\nCruise Control\n- Fully automate the dynamic workload rebalance and self-healing of a Kafka cluster.\nBurrow\n- Monitoring companion that provides consumer lag checking as a service without the need for specifying thresholds.\nChaperone\n- An audit system that monitors the completeness and latency of data stream.\nSematext\nintegration for\nKafka monitoring\nthat collects and charts 200+ Kafka metrics\nXinfra Monitor\n- A framework that monitors and exposes metrics showing availability and performance of Kafka clusters and mirrored pipelines.\nAWS Integration\nAutomated AWS deployment\nKafka -> S3 Mirroring tool\nfrom Pinterest.\nAlternative\nKafka->S3 Mirroring\ntool\nLogging\nsyslog (1M)\nsyslog producer\n: A producer that supports both raw data and protobuf with meta data for deep analytics usage.\nsyslog-ng (\nhttps://syslog-ng.org/\n) is one of the most widely used open source log collection tools, capable of filtering, classifying, parsing log data and forwarding it to a wide variety of destinations. Kafka is a first-class destination in the syslog-ng tool; details on the integration can be found at\nhttps://czanik.blogs.balabit.com/2015/11/kafka-and-syslog-ng/\n.\nklogd\n- A python syslog publisher\nklogd2\n- A java syslog publisher\nTail2Kafka\n- A simple log tailing utility\nFluentd plugin\n- Integration with\nFluentd\nRemote log viewer\nLogstash integration\n- Integration with\nLogstash\nand\nFluentd\nSyslog Collector\nwritten in Go\nKlogger\n- A simple proxy service for Kafka.\nfuse-kafka\n: A file system logging agent based on Kafka\nomkafka\n: Another syslog integration, this one in C and uses librdkafka library\nlogkafka\n- Collect logs and send lines to Apache Kafka\nFilebeat Kafka Module\n- Collect and ship Kafka logs to Elasticsearch (\ndocs\n)\nFlume - Kafka plugins\nFlume Kafka Plugin\n- Integration with\nFlume\nKafka as a sink and source in Flume\n- Integration with\nFlume\nMetrics\nMozilla Metrics Service\n- A Kafka and Protocol Buffers based metrics and logging system\nGanglia Integration\nSematext\nintegration for\nKafka monitoring\nCoda Hale Metric Reporter to Kafka\nkafka-dropwizard-reporter\n-\nRegister built-in Kafka client and stream metrics to Dropwizard Metrics\nMetricbeat Kafka Module\n- Capture and ship Kafka\nconsumergroup\nand\npartition\nmetrics to Elasticsearch (\ndocs\n)\nPacking and Deployment\nRPM packaging\nDebian packaging\nhttps://github.com/tomdz/kafka-deb-packaging\nPuppet Integration\nhttps://github.com/miguno/puppet-kafka\nhttps://github.com/whisklabs/puppet-kafka\nDropwizard packaging\nKafka Camel Integration\nhttps://github.com/ipolyzos/camel-kafka\nhttps://github.com/BreizhBeans/camel-kafka\nMisc.\nKafka Websocket\n- A proxy that interoperates with websockets for delivering Kafka data to browsers.\nKafkaCat\n- A native, command line producer and consumer.\nKafka Mirror\n- An alternative to the built-in mirroring tool\nRuby Demo App\nApache Camel Integration\nInfobright integration\nRiemann Consumer of Metrics\nstormkafkamom\n– curses-based tool which displays state of\nApache Storm\nbased Kafka consumers (Kafka 0.7 only).\nuReplicator\n- Provides the ability to replicate across Kafka clusters in other data centers\nMirus\n- A tool for distributed, high-volume replication between Apache Kafka clusters based on Kafka Connect\nlibbeat\n- All Elastic Beats (\nMetricbeat\n,\nFilebeat\n, etc) have Kafka outputs",
  "url": "https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem",
  "space": "KAFKA",
  "labels": [],
  "last_modified": null,
  "source_type": "confluence"
}