{
  "id": "confluence_display_KAFKA_Kafka+Controller+Internals",
  "title": "Kafka Controller Internals - Apache Kafka - Apache Software Foundation",
  "content": "In a Kafka cluster, one of the brokers serves as the controller, which is responsible for managing the states of partitions and replicas and for performing administrative tasks like reassigning partitions. The following describes the states of partitions and replicas, and the kind of operations going through the controller.\nPartitionStateChange:\nValid states are:\nNonExistentPartition: This state indicates that the partition was either never created or was created and then\ndeleted.\nNewPartition: After creation, the partition is in the NewPartition state. In this state, the partition should have replicas assigned to it, but no leader/isr yet.\nOnlinePartition: Once a leader is elected for a partition, it is in the OnlinePartition state.\nOfflinePartition: If, after successful leader election, the leader for partition dies, then the partition moves to the OfflinePartition state.\nValid state transitions are:\nNonExistentPartition -> NewPartition\nload assigned replicas from ZK to controller cache\nNewPartition -> OnlinePartition\nassign first live replica as the leader and all live replicas as the isr; write leader and isr to ZK\nfor this partition, send LeaderAndIsr request to every live replica and UpdateMetadata request to every live broker\nOnlinePartition,OfflinePartition -> OnlinePartition\nselect new leader and isr for this partition and a set of replicas to receive the LeaderAndIsr request, and write leader and isr to ZK\nOfflinePartitionLeaderSelector: new leader = a live replica (preferably in isr); new isr = live isr if not empty or just the new leader if otherwise; receiving replicas = live assigned replicas\nReassignedPartitionLeaderSelector: new leader = a live reassigned replica; new isr = current isr; receiving replicas = reassigned replicas\nPreferredReplicaPartitionLeaderSelector: new leader = first assigned replica (if in isr); new isr = current isr; receiving replicas = assigned replicas\nControlledShutdownLeaderSelector: new leader = replica in isr that's not being shutdown; new isr = current isr - shutdown replica; receiving replicas = live assigned replicas\nfor this partition, send LeaderAndIsr request to every receiving replica and UpdateMetadata request to every live broker\nNewPartition,OnlinePartition -> OfflinePartition\nnothing other than marking partition state as Offline\nOfflinePartition -> NonExistentPartition\nnothing other than marking the partition state as NonExistentPartition\nReplicaStateChange:\nValid states are:\nNewReplica: When replicas are created during topic creation or partition reassignment. In this state, a\nreplica can only get become follower state change request.\nOnlineReplica: Once a replica is started and part of the assigned replicas for its partition, it is in this\nstate. In this state, it can get either become leader or become follower state change requests.\nOfflineReplica : If a replica dies, it moves to this state. This happens when the broker hosting the replica\nis down.\nNonExistentReplica: If a replica is deleted, it is moved to this state.\nValid state transitions are:\nNonExistentReplica --> NewReplica\nsend LeaderAndIsr request with current leader and isr to the new replica and UpdateMetadata request for the partition to every live broker\nNewReplica-> OnlineReplica\nadd the new replica to the assigned replica list if needed\nOnlineReplica,OfflineReplica -> OnlineReplica\nsend LeaderAndIsr request with current leader and isr to the new replica and UpdateMetadata request for the partition to every live broker\nNewReplica,OnlineReplica -> OfflineReplica\nsend StopReplicaRequest to the replica (w/o deletion)\nremove this replica from the isr and send LeaderAndIsr request (with new isr) to the leader replica and UpdateMetadata request for the partition to every live broker.\nOfflineReplica -> NonExistentReplica\nsend StopReplicaRequest to the replica (with deletion)\nKafkaController Operations:\nonNewTopicCreation:\ncall onNewPartitionCreation\nonNewPartitionCreation:\nnew partitions -> NewPartition\nall replicas of new partitions -> NewReplica\nnew partitions -> OnlinePartition\nall replicas of new partitions -> OnlineReplica\nonBrokerFailure:\npartitions w/o leader -> OfflinePartition\npartitions in OfflinePartition and NewPartition -> OnlinePartition (with OfflinePartitionLeaderSelector)\neach replica on the failed broker -> OfflineReplica\nonBrokerStartup:\nsend UpdateMetadata requests for all partitions to newly started brokers\nreplicas on the newly started broker -> OnlineReplica\npartitions in OfflinePartition and NewPartition -> OnlinePartition (with OfflinePartitionLeaderSelector)\nfor partitions with replicas on newly started brokers, call onPartitionReassignment to complete any outstanding partition reassignment\nonPartitionReassignment: (OAR: old assigned replicas; RAR: new re-assigned replicas when reassignment completes)\nupdate assigned replica list with OAR + RAR replicas\nsend LeaderAndIsr request to every replica in OAR + RAR (with AR as OAR + RAR)\nreplicas in RAR - OAR -> NewReplica\nwait until replicas in RAR join isr\nreplicas in RAR -> OnlineReplica\nset AR to RAR in memory\nsend LeaderAndIsr request with a potential new leader (if current leader not in RAR) and a new assigned replica list (using RAR) and same isr to every broker in RAR\nreplicas in OAR - RAR -> Offline (force those replicas out of isr)\nreplicas in OAR - RAR -> NonExistentReplica (force those replicas to be deleted)\nupdate assigned replica list to RAR in ZK\nupdate the /admin/reassign_partitions path in ZK to remove this partition\nafter electing leader, the replicas and isr information changes, so resend the update metadata request to every broker\nFor example, if OAR = {1, 2, 3} and RAR = {4,5,6}, the values in the assigned replica (AR) and leader/isr path in ZK may go through the following transition.\nAR                  leader/isr\n{1,2,3}            1/{1,2,3}           (initial state)\n{1,2,3,4,5,6}   1/{1,2,3}           (step 2)\n{1,2,3,4,5,6}   1/{1,2,3,4,5,6}  (step 4)\n{1,2,3,4,5,6}   4/{1,2,3,4,5,6}  (step 7)\n{1,2,3,4,5,6}   4/{4,5,6}           (step 8)\n{4,5,6}            4/{4,5,6}           (step 10)\nNote that we have to update AR in ZK with RAR last since it's the only place where we store the OAR persistently. This way, if the controller crashes before that step, we can still recover.\nonControllerFailover:\nreplicaStateMachine.startup():\ninitialize each replica to either OfflineReplica or OnlineReplica\neach replica -> OnlineReplica (force LeaderAndIsr request to be sent to every replica)\npartitionStateMachine.startup():\ninitialize each partition to either NewPartition, OfflinePartition or OnlinePartition\neach OfflinePartition and NewPartition -> OnlinePartition (force leader election)\nresume partition reassignment, if any\nresume preferred leader election, if any\nonPreferredReplicaElection:\naffected partitions -> OnlinePartition (with PreferredReplicaPartitionLeaderSelector)\nshutdownBroker:\neach partition whose leader is on shutdown broker -> OnlinePartition (ControlledShutdownPartitionLeaderSelector)\neach replica on shutdown broker that is follower, send StopReplica request (w/o deletion)\neach replica on shutdown broker that is follower -> OfflineReplica (to force shutdown replica out of the isr)",
  "url": "https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Controller+Internals",
  "space": "KAFKA",
  "labels": [],
  "last_modified": null,
  "source_type": "confluence"
}