{
  "id": "confluence_display_KAFKA_Performance+testing",
  "title": "Performance testing - Apache Kafka - Apache Software Foundation",
  "content": "It would be worthwhile to automate our performance testing to act as a generic integration test suite.\nThe goal of this would be to do basic performance analysis and correctness testing in a distributed environment.\nRequired Metrics\nClient Side Measurements\nThroughput\nResponse Time/Latency\nTimeouts\nConsumer lag\nCommon Stats\nVmstat - Context Switch, User CPU utilization %, System CPU utilization %, Total CPU utilization %\nIostat - Reads/sec, Writes/sec, KiloBytes read/sec, KiloBytes write/sec, Average number of transactions waiting, Average number of active transactions, Average response time of transactions, Percent of time waiting for service, Percent of time disk is busy\nPrstat - Virtual memory size of each java process, RSS size of each process, Total CPU utilization of each process\nGC Log Analysis\nFootprint (Maximal amount of memory allocated)\nFreed Memory (Total amount of memory that has been freed)\nFreed Memory/min (Amount of memory that has been freed per minute)\nTotal Time (Time data was collected for)\nAcc Pauses (Sum of all pauses due to GC)\nThroughput (Time percentage the application was NOT busy with GC)\nFull GC Performance (Performance of full GC collections. Full GC collections are marked so in the gc logs.)\nGC Performance (Performance of minor collections. These are collections that are not full according to the definition above.)\nCMS counts and frequency (Number of CMS collections and their frequency)\nCMS failure count and frequency (CMS failure metrics)\nServer side metrics\nThroughput and response time breakdown for each request at the LogManager, RequestPurgatory level\nISR membership churn aggregate and per partition\nNumber of expirations in the request purgatory\nLeader election rate aggregate and per partition\nLeader election latency aggregate and per partition\nHigh watermark change aggregate and per partition\nReplica lag time and bytes aggregate and per partition\nReplica fetch throughput and response time aggregate and breakdown at the LogManager, RequestPurgatory level\nLog analysis\nExceptions in logs, their frequency and types of exception\nWarnings in logs, their frequency and types of warnings\nMiscellaneous\nCapture all the server machine profiles before tests are being executed (Such as disk space, number of CPUS etc)\nCapture all configurations for each run\nPhase I: Perf Tools\nThe goal of this phase is just to create tools to help run perf tests. We already have some of these so this will primarily just be about expanding and augmenting these.\nkafka-producer-perf-test.sh - We will add a csv option to this to dump incremental statistics in csv format for consumption by automated tools.\nkafka-consumer-perf-test.sh - Likewise we will add a csv option here.\njmx-dump.sh - This will just poll the kafka and zookeeper jmx stats every 30 seconds or so and output them as csv.\ndstat - This is the existing perf tool to get read/write/fs stats\ndraw-performance-graphs.r - This will be an R script to draw relevant graphs given a bunch of csv files from the above tools. The output of this script will be a bunch of png files that can be combined with some html to act as a perf report.\nHere are the graphs that would be good to see:\nLatency histogram for producer\nMB/sec and messages/sec produced\nMB/sec and messages/sec consumed\nFlush time\nErrors (should not be any)\nConsumer cache hit ratio (both the bytes and count, specifically 1 - #physical_reads / #requests and 1 - physical_bytes_read / bytes_read)\nWrite merge ratio (num_physical_writes/num_produce_requests and avg_request_size/avg_physical_write_size)\nCPU, network, io, etc\nPhase II: Automation\nThis phase is about automating the deployment and running of the performance tests. At the end of this phase we want to have a script that pulls from svn every night, runs a set of performance scenarios, and produces reporting on these.\nWe need the following helper scripts for this:\nkafka-deploy-kafka.sh - This script will take a set of hosts and deploy kafka to each of them.\nkafka-start-cluster.sh - This will start the kafka broker on the list of hosts\nkafka-stop-cluster - Stops cluster\nThe tests will be divided up into scenarios. Each scenario is a directory which contains the following:\nbroker config\nproducer config\nconsumer config\nproducer perf test command\nconsumer perf test command\nenv file that contain # brokers, # producers, and # consumers\nThe output of the scenario will be a directory which contains the following:\nProducer perf csvs\nConsumer perf csvs\ndstat csvs\njmx csvs\nenv file\nScenarios to test:\nProducer throughput with no consumers. We should cover the following cases:\nVary the number of topics\nVary the async batch size\nVary the flush size\nVary the message size\nConsumer throughput with no producer\nVary the message size\nVary the number of topics\nSingle producer/consumer pair\nCold consumption (i.e. not in cache)\nActive consumption (i.e. consumer caught up to producer)\nVary the number of topics\nMultiple consumers for one topic\nWe should add a script to take two scenarios and produce a summary/diff of them, i.e. what go worse and what got better. We can use this to track things over time. We can also rsync these up to a public location as a service to open source developers.\nPhase III: Correctness\nThe correctness testing can be very straight-forward, all we want to validate is that every message produced gets consumed. This could be as simple as logging out a simple message id in the consumer and comparing it to the produced value.\nSimplest idea is just to have each producer produce a set of known messages (say sequential integers in some unique range). Then have consumers validate that all integers were consumed (no gaps) and record the number of duplicates (if any).\nIdeally we would repeat this scenario and script in broker failures (kills), server pauses (simulated), etc.\n0.8 Performance testing\nProducer throughput\nMessage size : ~1K Production Data\nThroughput in MB/s\nKafka Version\n0.7\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\n0.8\nReplication Factor\nn/a\n1\n1\n1\n1\n1\n1\n1\n1\n1\n2\n2\n2\n2\n2\n2\n2\n2\n2\nAcks\nn/a\n-1\n1\n0\n-1\n1\n0\n-1\n1\n0\n-1\n1\n0\n-1\n1\n0\n-1\n1\n0\nCompression\nUncomp\nUncomp\nUncomp\nUncomp\nGzip\nGzip\nGzip\nSnappy\nSnappy\nSnappy\nUncomp\nUncomp\nUncomp\nGzip\nGzip\nGzip\nSnappy\nSnappy\nSnappy\nProducer threads\nBatch size\n1\n1\n29.57\n1.66\n1.69\n19.48\n0.94\n0.97\n3.51\n1.53\n1.46\n11.40\n0.56\n1.61\n23.52\n0.35\n0.91\n3.70\n0.56\n1.45\n10.83\n2\n1\n45.35\n3.31\n3.11\n23.82\n1.80\n1.72\n3.87\n2.30\n2.96\n11.65\n1.27\n2.79\n20.59\n0.66\n1.39\n3.86\n1.07\n2.19\n11.39\n5\n1\n58.53\n5.24\n5.49\n20.26\n2.59\n2.86\n3.35\n4.02\n4.48\n13.36\n1.79\n4.76\n21.29\n1.16\n2.49\n3.06\n1.93\n3.98\n10.49\n10\n1\n50.23\n8.20\n8.59\n19.65\n3.17\n2.77\n2.87\n7.35\n7.39\n10.51\n2.90\n7.97\n19.44\n1.85\n2.68\n3.05\n3.27\n7.24\n12.01\n1\n50\n49.15\n17.95\n18.88\n77.43\n7.93\n7.66\n26.88\n15.42\n15.44\n62.33\n10.57\n15.76\n57.85\n4.79\n7.50\n28.61\n10.31\n13.98\n66.15\n2\n50\n84.24\n34.94\n33.41\n82.67\n14.88\n15.25\n30.13\n29.77\n26.47\n71.18\n17.26\n27.26\n78.50\n9.53\n14.29\n30.11\n16.82\n26.10\n90.98\n5\n50\n102.44\n64.38\n62.82\n89.66\n17.56\n18.23\n19.47\n57.54\n58.58\n71.71\n26.02\n47.69\n86.62\n12.48\n17.39\n31.54\n33.13\n54.18\n74.96\n10\n50\n103.02\n61.06\n64.57\n86.48\n18.45\n17.24\n20.38\n59.59\n58.44\n69.34\n28.08\n59.80\n91.62\n18.68\n17.90\n20.02\n35.62\n62.03\n72.02\n1\n100\n49.76\n23.69\n23.56\n75.71\n8.93\n9.04\n28.69\n21.73\n21.79\n70.55\n12.69\n21.61\n52.12\n5.86\n8.85\n27.49\n13.48\n21.04\n66.70\n2\n100\n84.75\n42.85\n40.46\n84.72\n18.48\n16.90\n31.69\n42.61\n38.07\n85.78\n22.54\n35.81\n74.53\n11.16\n17.18\n35.86\n25.63\n37.95\n106.99\n5\n100\n92.78\n67.65\n67.89\n87.24\n21.93\n19.78\n21.40\n67.22\n65.94\n87.98\n26.93\n57.77\n86.46\n15.20\n18.92\n25.35\n37.40\n75.18\n83.91\n10\n100\n100.23\n67.53\n68.40\n87.99\n19.82\n20.80\n21.38\n69.64\n68.49\n81.88\n31.36\n63.19\n88.68\n17.39\n18.96\n21.56\n43.26\n72.14\n84.89",
  "url": "https://cwiki.apache.org/confluence/display/KAFKA/Performance+testing",
  "space": "KAFKA",
  "labels": [],
  "last_modified": null,
  "source_type": "confluence"
}