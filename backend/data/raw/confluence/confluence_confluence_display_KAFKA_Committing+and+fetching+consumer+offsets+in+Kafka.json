{
  "id": "confluence_display_KAFKA_Committing+and+fetching+consumer+offsets+in+Kafka",
  "title": "Committing and fetching consumer offsets in Kafka - Apache Kafka - Apache Software Foundation",
  "content": "In Kafka releases through 0.8.1.1, consumers commit their offsets to ZooKeeper. ZooKeeper does not scale extremely well (especially for writes) when there are a large number of offsets (i.e.,\nconsumer-count * partition-count\n). Fortunately, Kafka now provides an ideal mechanism for storing consumer offsets. Consumers can commit their offsets in Kafka by writing them to a durable (replicated) and highly available topic. Consumers can fetch offsets by reading from this topic (although we provide an in-memory offsets cache for faster access). i.e., offset commits are regular producer requests (which are inexpensive) and offset fetches are fast memory look ups.\nThe official Kafka documentation describes how the feature works and how to migrate offsets from ZooKeeper to Kafka. This wiki provides sample code that shows how to use the new Kafka-based offset storage mechanism.\nStep 1: Discover and connect to the offset manager for a consumer group by issuing a consumer metadata request to any broker\nimport kafka.api.*;\nimport kafka.cluster.Broker;\nimport kafka.common.OffsetAndMetadata;\nimport kafka.common.OffsetMetadataAndError;\nimport kafka.common.TopicAndPartition;\nimport kafka.javaapi.ConsumerMetadataResponse;\nimport kafka.javaapi.OffsetCommitRequest;\nimport kafka.javaapi.OffsetCommitResponse;\nimport kafka.javaapi.OffsetFetchRequest;\nimport kafka.javaapi.OffsetFetchResponse;\nimport kafka.network.BlockingChannel;\nimport java.util.*;\n...\ntry {\nBlockingChannel channel = new BlockingChannel(\"localhost\", 9092,\nBlockingChannel.UseDefaultBufferSize(),\nBlockingChannel.UseDefaultBufferSize(),\n5000 /* read timeout in millis */);\nchannel.connect();\nfinal String MY_GROUP = \"demoGroup\";\nfinal String MY_CLIENTID = \"demoClientId\";\nint correlationId = 0;\nfinal TopicAndPartition testPartition0 = new TopicAndPartition(\"demoTopic\", 0);\nfinal TopicAndPartition testPartition1 = new TopicAndPartition(\"demoTopic\", 1);\nchannel.send(new ConsumerMetadataRequest(MY_GROUP, ConsumerMetadataRequest.CurrentVersion(), correlationId++, MY_CLIENTID));\nConsumerMetadataResponse metadataResponse = ConsumerMetadataResponse.readFrom(channel.receive().buffer());\nif (metadataResponse.errorCode() == ErrorMapping.NoError()) {\nBroker offsetManager = metadataResponse.coordinator();\n// if the coordinator is different, from the above channel's host then reconnect\nchannel.disconnect();\nchannel = new BlockingChannel(offsetManager.host(), offsetManager.port(),\nBlockingChannel.UseDefaultBufferSize(),\nBlockingChannel.UseDefaultBufferSize(),\n5000 /* read timeout in millis */);\nchannel.connect();\n} else {\n// retry (after backoff)\n}\n}\ncatch (IOException e) {\n// retry the query (after backoff)\n}\nStep 2: Issue the OffsetCommitRequest or OffsetFetchRequest to the offset manager\n// How to commit offsets\nlong now = System.currentTimeMillis();\nMap<TopicAndPartition, OffsetAndMetadata> offsets = new LinkedHashMap<TopicAndPartition, OffsetAndMetadata>();\noffsets.put(testPartition0, new OffsetAndMetadata(100L, \"associated metadata\", now));\noffsets.put(testPartition1, new OffsetAndMetadata(200L, \"more metadata\", now));\nOffsetCommitRequest commitRequest = new OffsetCommitRequest(\nMY_GROUP,\noffsets,\ncorrelationId++,\nMY_CLIENTID,\n(short) 1 /* version */); // version 1 and above commit to Kafka, version 0 commits to ZooKeeper\ntry {\nchannel.send(commitRequest.underlying());\nOffsetCommitResponse commitResponse = OffsetCommitResponse.readFrom(channel.receive().buffer());\nif (commitResponse.hasError()) {\nfor (partitionErrorCode: commitResponse.errors().values()) {\nif (partitionErrorCode == ErrorMapping.OffsetMetadataTooLargeCode()) {\n// You must reduce the size of the metadata if you wish to retry\n} else if (partitionErrorCode == ErrorMapping.NotCoordinatorForConsumerCode() || partitionErrorCode == ErrorMapping.ConsumerCoordinatorNotAvailableCode()) {\nchannel.disconnect();\n// Go to step 1 (offset manager has moved) and then retry the commit to the new offset manager\n} else {\n// log and retry the commit\n}\n}\n}\n}\ncatch (IOException ioe) {\nchannel.disconnect();\n// Go to step 1 and then retry the commit\n}\n// How to fetch offsets\nList<TopicAndPartition> partitions = new ArrayList<TopicAndPartition>();\npartitions.add(testPartition0);\nOffsetFetchRequest fetchRequest = new OffsetFetchRequest(\nMY_GROUP,\npartitions,\n(short) 1 /* version */, // version 1 and above fetch from Kafka, version 0 fetches from ZooKeeper\ncorrelationId,\nMY_CLIENTID);\ntry {\nchannel.send(fetchRequest.underlying());\nOffsetFetchResponse fetchResponse = OffsetFetchResponse.readFrom(channel.receive().buffer());\nOffsetMetadataAndError result = fetchResponse.offsets().get(testPartition0);\nshort offsetFetchErrorCode = result.error();\nif (offsetFetchErrorCode == ErrorMapping.NotCoordinatorForConsumerCode()) {\nchannel.disconnect();\n// Go to step 1 and retry the offset fetch\n} else if (errorCode == ErrorMapping.OffsetsLoadInProgress()) {\n// retry the offset fetch (after backoff)\n} else {\nlong retrievedOffset = result.offset();\nString retrievedMetadata = result.metadata();\n}\n}\ncatch (IOException e) {\nchannel.disconnect();\n// Go to step 1 and then retry offset fetch after backoff\n}",
  "url": "https://cwiki.apache.org/confluence/display/KAFKA/Committing+and+fetching+consumer+offsets+in+Kafka",
  "space": "KAFKA",
  "labels": [],
  "last_modified": null,
  "source_type": "confluence"
}