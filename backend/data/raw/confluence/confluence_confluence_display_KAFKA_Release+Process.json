{
  "id": "confluence_display_KAFKA_Release+Process",
  "title": "Release Process - Apache Kafka - Apache Software Foundation",
  "content": "This document describes how to release Apache Kafka from trunk.\nIt is a work in progress and should be refined by the\nRelease Manager\n(RM) as they come across aspects of the release process not yet documented here.\nNOTE: For the purpose of illustration, this document assumes that the version being released is 0.10.0.0 and the following development version will become 0.10.1.0.\nPrerequisites\nTo act as the Release Manager (RM) you need at least Committer permissions.\nSend an email to\ndev@kafka.apache.org\noffering to act as the Release Manager (RM). Look for previous emails with \"I'd like to volunteer for the release manager\". Sample format for a bug fix release is available below.\nHey folks,\nI'd like to volunteer to be the release manager for a bug fix release of the {{3.5 CHANGE ME!}}. This will be the first bug fix release and will be version {{3.5.1 CHANGE ME!}}.\nIf no one has any objections, I will send out a release plan on {{DD-MM-YYYY}} that includes a list of all of the fixes we are targeting for {{3.5.1 CHANGE ME!}} along with a timeline.\nThanks!\nPrepare release plan in the wiki, notifying the community the overall plan and goals for the release (For example:\nRelease Plan 0.10.0\n)\nGo over JIRA for the release and make sure that blockers are marked as blockers and non-blockers are non-blockers. This JIRA filter may be handy:\nproject = KAFKA AND fixVersion = 0.10.0.0 AND resolution = Unresolved AND priority = blocker ORDER BY due ASC, priority DESC, created ASC\nIt is important that between the time that the release plan is voted to the time when the release branch is created, no experimental or potentially destabilizing work is checked into the trunk. While it is acceptable to introduce major changes, they must be thoroughly reviewed and have good test coverage to ensure that the release branch does not start off being unstable. If necessary the RM can discuss if certain issues should be fixed on the trunk in this time, and if so what is the gating criteria for accepting them.\nRM must have gpg keys with the public key publicly available to validate the authenticity of the Apache Kafka release: I\nf you haven't set up gpg key, set up one using 4096 bit RSA (\nhttp://www.apache.org/dev/release-signing.html\n). Make sure that your public key is uploaded to one of the public servers (\nhttp://www.apache.org/dev/release-signing.html#keyserver\n).\nOnce added, you will have to ask a PMC member to update the KEYS file in\nhttps://dist.apache.org/repos/dist/release/kafka/KEYS\n. Feel free to create a thread in the mailing list.\nFor major releases, make sure docs/documentation.html is referring to the next release and links and update docs/upgrade.html with upgrade instructions for next release.\nFor a bugfix release, make sure to at least bump the version number in the\n\"Upgrading to ...\"\nheader in docs/upgrade.html\nIf this is a major or minor release #, it's a good idea to make this change now. If you end up doing it after cutting branches, be sure the commit lands on both trunk and your release branch. Note that this\nmust\nbe done before generating any artifacts because these docs are part of the content that gets voted on.\nTo setup the release script, follow\nhttps://github.com/apache/kafka/tree/trunk/release#readme\nEnsure you have configured SSH to pick up your key when connecting to apache.org domains. In ~/.ssh/config, add:\nHost *.apache.org\nIdentityFile ~/.ssh/<apache-ssh-key>\nMake sure you have the\nMaven CLI\ninstalled. It may be easier to install it via a package manager e.g.\nbrew install maven\nYou will need to upload your maven credentials and\nsignatory credentials\nfor the release script by editing your `\n~/.gradle/gradle.properties\n` with:\n~/.gradle/gradle.properties\nmavenUrl=https://repository.apache.org/service/local/staging/deploy/maven2\nmavenUsername=your-apache-id\nmavenPassword=your-apache-passwd\nsigning.keyId=your-gpgkeyId # <- needs to be the 8-letter key ID, which are the last 8 characters from the full key ID\nsigning.password=your-gpg-passphrase\nsigning.secretKeyRingFile=/Users/your-id/.gnupg/secring.gpg\nIf you don't already have a secret key ring under ~/.gnupg (which will be the case with GPG 2.1 and beyond), you will need to manually create it with `\ngpg --export-secret-keys -o ~/.gnupg/secring.gpg`.\nObviously, be careful not to publicly upload your passwords. You should be editing the `gradle.properties` file under your home directory, not the one in Kafka itself.\nMake sure your `~/.m2/settings.xml` is configured for pgp signing and uploading to the apache release maven:\n~/.m2/settings.xml\n<settings xmlns=\"http://maven.apache.org/SETTINGS/1.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\nxsi:schemaLocation=\"http://maven.apache.org/SETTINGS/1.0.0 https://maven.apache.org/xsd/settings-1.0.0.xsd\">\n<servers>\n<server>\n<id>apache.releases.https</id>\n<username>your-apache-id</username>\n<password>your-apache-passwd</password>\n</server>\n<server>\n<id>your-gpgkeyId</id>\n<passphrase>your-gpg-passphrase</passphrase>\n</server>\n</servers>\n<profiles>\n<profile>\n<id>gpg-signing</id>\n<properties>\n<gpg.keyname>your-gpgkeyId</gpg.keyname>\n<gpg.passphraseServerId>your-gpgkeyId</gpg.passphraseServerId>\n</properties>\n</profile>\n</profiles>\n</settings>\nYou may also need to update some gnupgp configs:\necho \"allow-loopback-pinentry\" >> ~/.gnupg/gpg-agent.conf\necho \"use-agent\" >> ~/.gnupg/gpg.conf\necho \"pinentry-mode loopback\" >> ~/.gnupg/gpg.conf\necho RELOADAGENT | gpg-connect-agent\nCut Branches\nSkip this section if you are releasing a bug fix version (e.g. 2.2.1).\nMake sure you are working with a clean repo (i.e. identical to upstream - no changes in progress). If needed clone a fresh copy\ngit checkout trunk\nCheck that current HEAD points to commit on which you want to base new  release branch. Checkout particular commit if not.\ngit branch 0.10.0\ngit push origin 0.10.0\nModify the version in trunk to bump to the next one (eg. \"0.10.1.0-SNAPSHOT\") in the following files:\ngradle.properties\ncommitter-tools/kafka-merge-pr.py\nstreams/quickstart/java/pom.xml\nstreams/quickstart/java/src/main/resources/archetype-resources/pom.xml\nstreams/quickstart/pom.xml\ntests/kafkatest/__init__.py\ntests/kafkatest/version.py (do not add the new release version, it will only be added after the release is completed)\n.github/workflows/ci.yml\nCommit and push to trunk in apache.\nCheck that the branch was correctly propagated to Apache using the webui:\nhttps://gitbox.apache.org/repos/asf?p=kafka.git\nSend email announcing the new branch:\nTo: dev@kafka.apache.org\nSubject: New release branch 0.10.0\nHello Kafka developers and friends,\nAs promised, we now have a release branch for 0.10.0 release (with 0.10.0.0\nas the version).\nTrunk has been bumped to 0.10.1.0-SNAPSHOT.\nI'll be going over the JIRAs to move every non-blocker from this release to\nthe next release.\nFrom this point, most changes should go to trunk.\n*Blockers (existing and new that we discover while testing the release)\nwill be double-committed. *Please discuss with your reviewer whether your\nPR should go to trunk or to trunk+release so they can merge accordingly.\n*Please help us test the release! *\nThanks!\n$RM\nMonitor Tests\nIn between the branch cut and the RC cut, it's good to set up and keep an eye on the tests.\nAt the time of RC publishing, you will be asked to ensure you get a green run of integration tests & system tests. Due to flakes, this isn't always possible - so it's necessary to triage the tests & recognize what are flakes.\nThe earlier you do this, the easier it'll be later - hence this paragraph suggests you set them up now after the branch cut & start monitoring.\nThe link for unit/integration tests: `\nhttps://ci-builds.apache.org/job/Kafka/job/kafka/job/{MAJOR_RELEASE_VERSION}/\n` - e.g\nhttps://ci-builds.apache.org/job/Kafka/job/kafka/job/3.7/\nSystem tests:\nhttps://confluent-open-source-kafka-system-test-results.s3-us-west-2.amazonaws.com/{dev_branch}/<BUILD_NUMBER>/report.html\nNotable, this is hosted by Confluent.\nIf you, the RM, do not work for Confluent - contact someone from the company to set up the branch.\nIf you, the RM, do work for Confluent - set up the branch following the internal instructions in the wiki.\nCreate Release Artifacts\nFor version < 4.0.0, Verify the LICENSE file by running\npython3 ./committer-tools/verify_license.py\nfrom the project root directory. This is done in the CI from 4.0.0\nSet environment variable `\nPUSH_REMOTE_NAME`\nto the remote you want to push to, e.g.,\nexport PUSH_REMOTE_NAME=origin\n(default is\napache-github\n).\nRun the `release.py` script in the \"release\" folder of the kafka repository and follow the instructions.\nThis script will created a hidden directory called .release_work_dir. Don't delete this as you may need the contents later (for example the kafka-stream-x.x.x-test.jar)\nTroubleshooting:\nIf any step fails, make sure you have everything set up as described in the Prerequisites section and are using the correct passphrase for each config. When in doubt, remove or comment out anything in your settings that is not specifically needed for the release – for example, alternate profiles or unrelated servers, mirrors, etc in your\n`\n~/.m2/settings.xml\n` or `\n~/.gradle/gradle.properties\n`\nMake sure you're running the script with Python3: sadly Python versions are not well managed especially on Macs, so you may want to explicitly invoke it with:\npython3 release.py\nTry setting an explicit path for both Java8 and Java17, rather than relying on your JAVA_HOME since this may be modified in the background by other applications (such as IDEs)\nCreate JVM Apache Kafka Docker Artifacts (For versions >= 3.7.0)\nOnce you have executed release.py script, you'll be able to generate an RC docker image.\nThis\ndocument\ncovers details of each workflow. Refer to this for detailed examples and better understanding.\nIn Github Actions of Apache Kafka repository (\nhere\n) you'll find\nDocker Build Test Workflow\n.\nClick on run workflow and select the RC branch for the branch that this workflow needs to run.\nProvide the image type. Since you are creating an RC image for\napache/kafka\n- the image type you want is\njvm\n.\nProvide the url to the RC kafka binary tarball (scala 2.13 version) - e.g `https://dist.apache.org/repos/dist/dev/kafka/\n{rc_tag}\n/\nkafka_2.13-3.7.0.tgz\n`. This url will be used to generate the docker image.\nRun workflow and wait for it to finish. Once it finishes go back to the actions page and click on the workflow again. You'll find the uploaded artifacts. In case of jvm image type, they will be:\nreport_jvm.html\n(the docker image test report)\nscan_report_jvm.txt\n(the docker image cve report).\nShare the links to the pipelines and the above artifacts with the community in the RC voting email thread.\nNext - create the RC docker image in apache/kafka. Go to the Github action\nBuild and Push Release Candidate Docker Image\n.\nHere image type is \"jvm\" and kafka url will be same as provided in previous workflow.\nIn addition - add the docker hub image name that needs to be pushed.\nIt will be apache/kafka:{rc_tag}. Here\nrc_tag\nis comprised of release version and rc version. For example\napache/kafka:3.7.0-rc0\n, can be the first RC docker image for 3.7.0 release.\nEnsure that the RC docker image is visible on\ndocker hub\n.\nShare the docker image with the community in the RC voting email thread\nCreate GraalVM Based Native Apache Kafka Docker Artifact (For versions >= 3.8.0)\nOnce you have executed release.py script, you'll be able to generate an RC docker image.\nThis\ndocument\ncovers details of each workflow. Refer to this for detailed examples and better understanding.\nIn Github Actions of Apache Kafka repository (\nhere\n) you'll find\nDocker Build Test Workflow\n.\nClick on run workflow and select the RC branch for the branch that this workflow needs to run.\nProvide the image type. Since you are creating an RC image for\napache/kafka-native\n- the image type you want is\nnative\n.\nProvide the url to the RC kafka binary tarball (scala 2.13 version) - e.g `\nhttps://dist.apache.org/repos/dist/dev/kafka\n/{rc_tag}/kafka_2.13-3.8.0.tgz\n`. This url will be used to generate the docker image.\nRun workflow and wait for it to finish. Once it finishes go back to the actions page and click on the workflow again. You'll find the uploaded artifacts. In case of native image type, they will be:\nreport_native.html\n(the docker image test report)\nscan_report_native.txt\n(the docker image cve report).\nShare the link to the pipeline and the above artifacts with the community in the RC voting email thread.\nNext - create the RC docker image in apache/kafka-native. Go to the Github action\nBuild and Push Release Candidate Docker Image\n.\nHere image type and kafka url will be same as provided in previous workflow.\nIn addition - add the docker hub image name that needs to be pushed.\nIt will be apache/kafka-native:{rc_tag}. Here\nrc_tag\nis comprised of release version and rc version. For example\napache/kafka-native:3.8.0-rc0\n, can be the first RC docker image for 3.8.0 release.\nEnsure that the RC docker image is visible on\ndocker hub\n.\nShare the docker image with the community in the RC voting email thread\nWebsite update process\nNote: Unlike the Kafka sources (\nkafka repo\n), the content of the Apache Kafka website\nkafka.apache.org\nis backed by a separate git repository (\nkafka-site repo\n). Today, any changes to the content and docs must be kept manually in sync between the two repositories.\nWe should improve the release script to include these steps. In the meantime, for new releases:\ngit clone git@github.com:apache/kafka-site.git\ngit checkout asf-site\nUpdate the website content including docs:\nGenerate the website content on your kafka project, on the release tag (\nhttps://github.com/apache/kafka?tab=readme-ov-file#building-a-binary-release-gzipped-tar-ball\n)\nThe gradle target\nreleaseTarGz\ngenerates the Kafka website content including the Kafka documentation (with the exception of a few pages like\nproject-security.html\n, which are only tracked in the kafka-site repository). This build target also auto-generates the configuration docs of the Kafka broker/producer/consumer/etc. from their respective Java sources. The build output is stored in\n./core/build/distributions/kafka_2.13-2.8.0-site-docs.tgz\n.\nCopy the folder generated on the first step to the kafka-site (ex. folder\n28/\nextracted from\n./core/build/distributions/kafka_2.13-2.8.0-site-docs.tgz)\nUpdate the javadocs:\nCreate the release Javadocs with the gradle target\naggregatedJavadoc (`./gradlew aggregatedJavadoc`) on JDK 17\n, with output under\n./build/docs/javadoc/\n. (\nhttps://github.com/apache/kafka?tab=readme-ov-file#build-aggregated-javadoc\n)\nCopy the\njavadoc\nfolder to\n28/\n(i.e., the full path is\n28/javadoc/\n). If this is bug fix release, do this after the vote has passed to avoid showing an unreleased version number in the published javadocs.\nNote that this will upload the javadocs with a version named\n{RELEASE_VERSION}-SNAPSHOT\n. Once you have an RC cut with a git tag, check out that git tag and re-generate the javadocs. That way it will not have the\n-SNAPSHOT\nsuffix anymore\nCommit & push\nBlog Post\nFor minor and major releases, consider writing a blog. Since the Apache blogs platform is now sunset, we've added a\nblog section\nto the Kafka website. Unfortunately this requires writing it in HTML, see the\nblog.html\nfile in kafka-site.\nIt's nice to thank as many people as we can identify.  Please use \"\nFind all contributors\n\" script to generate the list of contributors.\nConsider incorporating any suggestions from the dev thread until release is announced\nAnnounce the RC\nSend an email announcing the release candidate.\nIf need to roll a new RC\nGo to\nhttps://repository.apache.org/#stagingRepositories\n, find the uploaded artifacts and drop it.\nRevert the \"Bump version to <VERSION>\" commit and push that to the release branch\nGo back to the beginning\n- don't forget to bump the RC number.\nUpdate the Collaborators List\nWhile waiting for the vote to pass, this is a good time to\nupdate the Collaborators\n(see\nhttps://github.com/apache/kafka-site/pull/510\nfor reference until the site update is published).\nThe process is documented in\nhttps://github.com/apache/kafka/blob/trunk/committer-tools/README.md#refresh-collaborators\n(\nKAFKA-19041\n-\nGetting issue details...\nSTATUS\nwill try to automate it)\nAfter the vote passes\nRemember:\nat least 3 days\n, 3 +1 from PMC members (committers are not enough!) and no -1.\nSend a vote closing email:\nTo: dev@kafka.apache.org, kafka-clients@googlegroups.com, users@kafka.apache.org\nSubject: [RESULTS] [VOTE] Release Kafka version 0.10.0.0\nThis vote passes with 7 +1 votes (3 bindings) and no 0 or -1 votes.\n+1 votes\nPMC Members:\n* $Name\n* $Name\n* $Name\nCommitters:\n* $Name\n* $Name\nCommunity:\n* $Name\n* $Name\n0 votes\n* No votes\n-1 votes\n* No votes\nVote thread:\nhttp://markmail.org/message/faioizetvcils2zo\nI'll continue with the release process and the release announcement will follow in the next few days.\n$RM\nCreate a new tag for the release, on the same commit as the voted rc tag and push it:\nUse \"git show 0.10.0.0-rc6\" to find the commit hash of the tag\ngit tag -a 0.10.0.0 <commit hash>\nWhen asked to provide a message for the new tag, to preserve uniformity in release tags, add:\nApache Kafka <version number> release.\nFor example:\nApache Kafka 0.10.0.0 release\nRun \"git show 0.10.0.0\" and confirm that the tag points to the correct commit hash.\ngit push origin 0.10.0.0\nMerge the last version change / rc tag into the release branch and bump the version to 0.10.0.1-SNAPSHOT\ngit checkout 0.10.0\ngit merge 0.10.0.0-rc6\nUpdate version on the branch to 0.10.0.1-SNAPSHOT in the following places:\ncommitter-tools/kafka-merge-pr.py\ngradle.properties\nstreams/quickstart/java/pom.xml\nstreams/quickstart/java/src/main/resources/archetype-resources/pom.xml\nstreams/quickstart/pom.xml\ntests/kafkatest/__init__.py (note: this version name can't follow the -SNAPSHOT convention due to python version naming restrictions, instead update it to 0.10.0.1.dev0)\ntests/kafkatest/version.py\nRun \"git status\" and \"git diff\" and make sure that only the files above have changed with the intended changes. (For example, there's no\n.release_work_dir/\nfrom a previous RC generation).\ngit commit -a (the commit message could be \"MINOR: Update 3.2 branch version to 3.2.1-SNAPSHOT\")\ngit push origin 0.10.0\nU\npload all artifacts, release notes, and docs (can be found in the .release_work_dir created by the release.py script) to\nhttps://dist.apache.org/repos/dist/release/kafka\n(a SVN repo, using Apache committer id/passwd).\nNote that only PMC members can upload to the `release` directory. If the RM is not in the PMC, ask a PMC member to move them from\nhttps://dist.apache.org/repos/dist/dev/kafka\nthe release directory.\n# Set your env variable for apache username\nAPACHE_USERNAME=<apache_username>\n# Create the directory for release in release repo\nsvn mkdir --username $APACHE_USERNAME -m \"Making directory for 0.10.0.0\" https://dist.apache.org/repos/dist/release/kafka/0.10.0.0\n# Checkout the directory for the new release\nsvn co --username $APACHE_USERNAME https://dist.apache.org/repos/dist/release/kafka/0.10.0.0 kafka-release-0-10-0-0\n# Copy the artifacts from dev repo to local\nsvn co --username $APACHE_USERNAME https://dist.apache.org/repos/dist/dev/kafka/0.10.0.0-rc0 kafka-dev-0-10-0-0\n# Move files from one folder into another\nmv kafka-dev-0-10-0-0/* kafka-release-0-10-0-0\n# Add files to SVN and commit\ncd kafka-release-0-10-0-0\nsvn --username $APACHE_USERNAME add *\nsvn commit --username $APACHE_USERNAME -m \"Release 0.10.0.0\"\n# Update the PGP KEYS\ncd\nsvn co --username $APACHE_USERNAME  --depth empty https://dist.apache.org/repos/dist/release/kafka/ kafka-pgp-0-10-0-0\ncd kafka-pgp-0-10-0-0\nsvn update KEYS\nwget http://kafka.apache.org/KEYS\nmv KEYS.1 KEYS\nsvn commit -m \"Update PGP keys\"\nMake sure the KEYS file in the svn repo includes the committer who signed the release.\nThe KEYS must be in\nhttps://dist.apache.org/repos/dist/release/kafka/KEYS\nand not just in\nhttp://kafka.apache.org/KEYS\n.\nGo to\nhttps://repository.apache.org/#stagingRepositories\n, find the uploaded artifacts and release them (this will push the artifacts to maven central). You will be asked to provide a description on a pop-up menu that will allow you to add\nApache Kafka 0.10.0.0\n(in previous descriptions you'd normally have appended the RC identifier as well).\nWait for about a day for the artifacts to show up in apache mirror (\nreleases\n,\npublic group\n) and maven central (at\nmaven.org\n, an example: the\nkafka_2.13\npackage).\nRelease JVM based Apache Kafka Docker Image:-\nRun\nPromote Release Candidate Docker Image\ngithub action.\nHere the RC Docker image will be the rc docker image that got voted and approved. For example if\napache/kafka:3.7.0-rc1\ngot voted and approved, it will be the RC docker image that needs to be used.\nPromoted image will be the final release name. For 3.7.0 release it will be\napache/kafka:3.7.0\nRun the workflow and verify that the new docker image is visible on\ndocker hub\nIf this is the latest release, i.e. highest version available, then ensure that you also release for\nlatest\ntag. Which means you need to run the above pipeline again and use promoted image as\napache/kafka:latest\nRelease GraalVM based Native Apache Kafka Docker Image:-\nRun\nPromote Release Candidate Docker Image\ngithub action.\nHere the RC Docker image will be the rc docker image that got voted and approved. For example if\napache/kafka-native:3.8.0-rc1\ngot voted and approved, it will be the RC docker image that needs to be used.\nPromoted image will be the final release name. For 3.8.0 release it will be\napache/kafka-native:3.8.0\nRun the workflow and verify that the new docker image is visible on\ndocker hub\nIf this is the latest release, i.e. highest version available, then ensure that you also release for\nlatest\ntag. Which means you need to run the above pipeline again and use promoted image as\napache/kafka-native:latest\nUpdate the supported_image_tag field in the\ndocker_scan\nGitHub action. Ex.\nUpdate the website:\ngit clone\nhttps://github.com/apache/kafka-site\ngit checkout asf-site\nVerify that\ndocumentation.html\n(in kafka-site repo) is referring to the correct release and links.\nVerify that\ndocs/documentation.html\n(in kafka repo) is similarly set up correctly.\nIf it's a feature release:\nUpdate files (e.g. documentation.html, protocol.html, quickstart.html, intro.html) to include the link for the new version (e.g. 0100/documentation.html). The full list of files can be found by:\ngit grep \"should always link the latest\"\n| grep -v '^[0-9]'\nThe command grep -v '^[0-9]' excludes per-release files (e.g. ./10/documentation/streams/upgrade-guide.html)\nChange these files to link to the current one.\n<!--#include virtual=\"/36/introduction.html\" -->\nto\n<!--#include virtual=\"/37/introduction.html\" -->\nVerify that related html files (excluding per-release files) have been updated to use the new release version by doing\ngit grep -Irn -A1 \"should always link the latest\" | grep -v '^[0-9]'\nand checking that the new feature version is used.\nUpdate files (e.g documentation.html, streams/quickstart.html) from the previous release (e.g current release is 3.7 so update files in the /36 folder) to change\n'<!--//#include virtual=\"'...\nto\n'<!--#include virtual=\"...\n.  You can find the files by running\ngit grep '<!--//#include virtual='\nfrom the directory of the previous feature release.  This\nkafka-site PR\nis an example of the changes that need to be made.\nUpdate downloads.html to include the new download links from mirrors and change last release to use archive. Also add a paragraph with a brief feature introduction for the release.\ncf\nhttps://infra.apache.org/release-download-pages.html\nRemove the previous version from the list of \"Supported Releases\" in the downloads page, and move it to the \"Archived Releases\" section. Update the links to use \"archive.apache.org\" when appropriate. Ex. remove 4.1.0 from supported list when releasing 4.1.1 (\nPR\n) .\ngit commit -am \"..\"\ngit push origin asf-site\nMake sure the docs for the previous version are updated to display the \"You're viewing documentation for an older version of Kafka\" banner. This means un-commenting the banner out in two places: the previous version's branch of the kafka repo, and the previous version's directory in the kafka-site repo. See this commit for an example of which line displays this banner\nSend out an announcement email.\nThe announcement email should be sent to\nannounce@apache.org\n,\nusers@kafka.apache.org\n,\ndev@kafka.apache.org\n, and\nkafka-clients@googlegroups.com\nYou need to use your apache email address to send out the email\n(otherwise, it won't be delivered to\nannounce@apache.org\n).\nIf you use gmail, you can configure it to send outbound mail from your apache address. Go to Settings → Accounts and Import → Send mail as: , and use the config:\nServer:\nmail-relay.apache.org\nPort: 587 (STARTTLS), 465 (SSL) User/Pass: {Your LDAP credentials}\nFor other mail clients, see\nhttps://infra.apache.org/committer-email.html\nYou need to be subscribed to `\nkafka-clients@googlegroups.com\n` with your apache email address – otherwise it bounces back. Just send a message from your apache email to\nkafka-clients+subscribe@googlegroups.com\nand click `Join` in the confirmation email\nMake sure to send the email as plain text, if there is any html (including basic hyperlinks) the email will bounce from\nannounce@apache.org\n. For gmail, removing formatting might not be enough. Make sure you've selected the option \"Plain text mode\".\nDouble check that all the links in the email and on the downloads page work.\nGenerate the release email:\nRun  `release/release.py release-email` script in the root of the kafka repository and follow the instructions to generate the announcement email template for the release to the mailing list.\nCheck and update the Scala versions, if necessary, in the release email.\nAlso include the kafka website blog link to the\nannouncement email\nExample:\n\"\nAn overview of the release and its notable changes can be found in the\nrelease blog post:\nhttps://kafka.apache.org/blog#apache_kafka_370_release_announcement\n\"\nAfter release\nIn trunk update the following files with the current release number. This is needed for a feature as well as a bug-fix release (\ncommit example\n)\nKAFKA-REPO-DIR/gradle/dependencies.gradle\nKAFKA-REPO-DIR/tests/docker/Dockerfile\nKAFKA-REPO-DIR/tests/kafkatest/version.py\nKAFKA-REPO-DIR/vagrant/base.sh\nUpload the new release and kafka-streams-x.x.x-test.jar (can be found in the .release_work_dir created by the release.py script) to the S3 bucket \"kafka-packages\".  This is a S3 bucket owned by Confluent. If the RM is a committer from Confluent then follow the internal documentation for getting credentials. If the RM is not a committer from Confluent, please ask a committer from Confluent to do this for you. The wiki document is called\n\"Uploading the Apache Kafka release to the kafka-packages S3 bucket\".\nUse the AWS console to upload the files in the bucket or the CLI if you have appropriate keys. Update these commands to use the current release version. For example:\naws s3 cp .release_work_dir/<rc-version>/kafka_2.12-3.0.0.tgz\ns3://kafka-packages\naws s3 cp .release_work_dir/<rc-version>/kafka_2.13-3.0.0.tgz\ns3://kafka-packages\naws s3 cp .release_work_dir/kafka/streams/build/libs/kafka-streams-3.0.0-test.jar\ns3://kafka-packages\nYou could find it at\nhttps://repository.apache.org/content/groups/public/org/apache/kafka/kafka-streams/<version>/\nMake sure to update the permissions on AWS S3 so they are readable by everyone\n$ aws s3api put-object-acl --bucket kafka-packages --key kafka_2.13-3.0.0.tgz --acl public-read\n$ aws s3api put-object-acl --bucket kafka-packages --key kafka_2.12-3.0.0.tgz --acl public-read\n$ aws s3api put-object-acl --bucket kafka-packages --key kafka-streams-3.0.0-test.jar --acl public-read\nOnce done, check that they're uploaded in\nhttps://kafka-packages.s3.us-west-2.amazonaws.com/\nMark the version as released in Kafka JIRA (from JIRA administration panel, select versions and scroll mouse towards the end of the line for the particular version. From the dropdown list, select release and set the date).\nOnce the release is announced, the PMC member who committed the release artifacts to the SVN dist repository should add the release data to\nhttps://reporter.apache.org/addrelease.html?kafka\n(they will get a notification asking them to do this after the svn commit).\nPMC member should double check if older releases should be archived (cf.\nhttp://www.apache.org/legal/release-policy.html#when-to-archive\n). This includes changing the relevant download links in the\nsite's `download.html`\nto use the archive link.\nCf.\nKAFKA-6222\n-\nGetting issue details...\nSTATUS\nand\nKAFKA-6223\n-\nGetting issue details...\nSTATUS\nFor feature releases, file a JIRA for updating compatibility/upgrade system tests to test the newly released version. Example PRs:\nBroker and clients:\nhttps://github.com/apache/kafka/pull/12210\nStreams:\nhttps://github.com/apache/kafka/pull/19239\nUpdate\nhttps://en.wikipedia.org/wiki/Apache_Kafka\nentry with new release information (and maybe give it an overall read to see if everything is still up-to-date or needs improvement)\nFor feature releases, publish the blog post previously shared with the dev list.\nUseful Commands\nFind all contributors for a release\n# The commands below assume that new version is 3.5.1 and last version is 3.5.\n## set variables\nCURRENT_RELEASE_TAG=3.5.1\nOLD_RELEASE_TAG=3.5.0\n## get list of contributors (commit authors and co-authors) sorted in alphabetical order and separated by comma\ngit shortlog -sn --group=author --group=trailer:co-authored-by --group=trailer:Reviewers --no-merges ${OLD_RELEASE_TAG}..${CURRENT_RELEASE_TAG} | cut -f2 | sort --ignore-case | uniq | sed -e ':a' -e '$!N;s/\\n/, /;ta' -e 's/,$//' -e 's/%$//'\n## get count of list of unique contributors\ngit shortlog -sn --group=author --group=trailer:co-authored-by --group=trailer:Reviewers --no-merges ${OLD_RELEASE_TAG}..${CURRENT_RELEASE_TAG} | cut -f2 | sort --ignore-case | uniq | wc -l",
  "url": "https://cwiki.apache.org/confluence/display/KAFKA/Release+Process",
  "space": "KAFKA",
  "labels": [],
  "last_modified": null,
  "source_type": "confluence"
}