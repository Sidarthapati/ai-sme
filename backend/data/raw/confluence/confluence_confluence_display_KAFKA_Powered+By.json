{
  "id": "confluence_display_KAFKA_Powered+By",
  "title": "Powered By - Apache Kafka - Apache Software Foundation",
  "content": "Want to appear on this page? Send a quick description of your organization and usage to the mailing list or to @apachekafka or @jaykreps on twitter and we'll add you.\nCompanies\nLinkedIn\n- Apache Kafka is used at LinkedIn for activity stream data and operational metrics. This powers various products like LinkedIn Newsfeed, LinkedIn Today in addition to our offline analytics systems like Hadoop.\nYahoo\n- See\nthis\n.\nTwitter\n- As part of their Storm stream processing infrastructure, e.g.\nthis\nand\nthis\n.\nNetflix\n- Real-time monitoring and event-processing\npipeline\n.\nSquare\n- We use Kafka as a bus to move all systems events through our various datacenters. This includes metrics, logs, custom events etc. On the consumer side, we output into Splunk, Graphite, Esper-like real-time alerting.\nSpotify\n- Kafka is used at Spotify as part of their\nlog delivery system\n.\nPinterest\n- Kafka is used with\nSecor\nas part of their\nlog collection pipeline\n.\nUber\nGoldman Sachs\nTumblr\n- See\nthis\nPayPal\n- See\nthis\n.\nBox\n-\nAt Box, Kafka is used for the production analytics pipeline & real time monitoring infrastructure. We are planning to use Kafka for some of the new products & features\nAirbnb\n-\nUsed in our event pipeline, exception tracking & more to come.\nMozilla\n- Kafka will soon be replacing part of our current production system to collect performance and usage data from the end-users browser for projects like Telemetry, Test Pilot, etc. Downstream consumers usually persist to either HDFS or HBase.\nCisco\n- Cisco is using Kafka as part of their OpenSOC (Security Operations Center). More detail\nhere\n.\nEtsy\n- See\nthis article\n.\nTagged\n- Apache Kafka drives our new pub sub system which delivers real-time events for users in our latest game - Deckadence. It will soon be used in a host of new use cases including group chat and back end stats and log collection.\nFoursquare\n- Kafka powers online to online messaging, and online to offline messaging at Foursquare. We integrate with monitoring, production systems, and our offline infrastructure, including hadoop.\nStumbleUpon\n- Data collection platform for analytics.\nCoursera\n- At Coursera, Kafka powers education at scale, serving as the data pipeline for realtime learning analytics/dashboards.\nShopify\n- A\nccess logs, A/B testing events, domain events (\"a checkout happened\", etc.), metrics,\ndelivery to HDFS, and customer reporting. W\ne are now focusing on consumers: analytics, support tools, and fraud analysis\n.\nCerner\n- Kafka is used with HBase and Storm as described\nhere\n.\nOracle\n-\nOracle provides native connectivity to Kafka from its Enterprise Service Bus product called OSB (Oracle Service Bus) which allows developers to leverage OSB built-in mediation capabilities to implement staged data pipelines.\nOracle Golden Gate\n-  GoldenGate offers a comprehensive solution that streams transactional data from various sources into various big data targets including Kafka in real-time, enabling organizations to build fault -tolerant, highly reliable, and extensible analytical applications.\nCloudFlare\n-\nCloudFlare uses Kafka for our log processing and analytics pipeline, collecting hundreds of billions of events/day data from a thousands of servers.\nMate1.com Inc.\n- Apache kafka is used at Mate1 as our main event bus that powers our news and activity feeds, automated review systems, and will soon power real time notifications and log distribution.\nBoundary\n- Apache Kafka aggregates high-flow message streams into a unified distributed pubsub service, brokering the data for other internal systems as part of Boundary's real-time network analytics infrastructure.\nAncestry.com\n- Kafka is used as the\nevent log processing pipeline\nfor delivering better personalized product and service to our customers.\nDataSift\n- Apache Kafka is used at DataSift as a collector of monitoring events and to track user's consumption of data streams in real time.\nhttp://highscalability.com/blog/2011/11/29/datasift-architecture-realtime-datamining-at-120000-tweets-p.html\nSpongecell\n-\nWe use Kafka to run our entire analytics and monitoring pipeline driving both real-time and ETL applications for our customers.\nWooga\n- We use Kafka to aggregate and process tracking data from all our facebook games (which are hosted at various providers) in a central location.\nAddThis\n- Apache Kafka is used at AddThis to collect events generated by our data network and broker that data to our analytics clusters and real-time web analytics platform.\nUrban Airship\n- At Urban Airship we use Kafka to buffer incoming data points from mobile devices for processing by our analytics infrastructure.\nMetamarkets\n-\nWe use Kafka to ingest real-time event data, stream it to Storm and\nHadoop, and then serve it from our Druid cluster to feed our interactive\nanalytics dashboards. We've also built\nconnectors for directly\ningesting events\nfrom Kafka into Druid.\nSimple\n- We use Kafka at Simple for log aggregation and to power our analytics infrastructure.\nGnip\n- Kafka is used in their twitter ingestion and processing pipeline.\nLoggly\n- Loggly is the world's most popular cloud-based log management. Our cloud-based log management service helps DevOps and technical teams make sense of the the massive quantity of logs. Kafka is used as part of our\nlog collection and processing infrastructure\n.\nRichRelevance\n- Real-time tracking event pipeline.\nSocialTwist\n- We use Kafka internally as part of our reliable email queueing system.\nCountandra\n- We use a hierarchical distributed counting engine, uses Kafka as a primary speedy interface as well as routing events for cascading counting\nFlyHajj.com\n- We use Kafka to collect all metrics and events generated by the users of the website.\nuSwitch\n- See\nthis blog\n.\nInfoChimps\n- Kafka is part of the\nInfoChimps real-time data platform\n.\nVisual Revenue\n- We use Kafka as a distributed queue in front of our web traffic stream processing infrastructure (Storm).\nOolya\n- Kafka is used as the primary high speed message queue to power Storm and our real-time analytics/event ingestion pipelines.\nDatadog\n- Kafka brokers data to most systems in our metrics and events ingestion pipeline. Different modules contribute and consume data from it, for streaming CEP (homegrown), persistence (at different \"temperatures\" in Redis, ElasticSearch, Cassandra, S3), or batch analysis (Hadoop).\nVisualDNA\nWe use Kafka 1. as an infrastructure that helps us bring continuously the tracking events from various datacenters into our central hadoop cluster for offline processing, 2. as a propagation path for data integration, 3. as a real-time platform for future inference and recommendation engines\nSematext\n- in\nSPM\n(performance monitoring + alerting), Kafka is used for metrics collection and feeds SPM's in-memory data aggregation (OLAP cube creation) as well as our CEP/Alerts servers (see also:\nSPM for Kafka performance monitoring\n). In\nSA (search analytics)\nKafka is used in search and click stream collection before being aggregated and persisted. In\nLogsene (log analytics)\nKafka is used to pass logs and other events from front-end receivers to the persistent backend.\nWize Commerce\n- At Wize Commerce (previously, NexTag), Kafka is used as a distributed queue in front of Storm based processing for search index generation. We plan to also use it for collecting user generated data on our web tier, landing the data into various data sinks like Hadoop, HBase, etc.\nQuixey\n- At Quixey, The Search Engine for Apps, Kafka is an integral part of our eventing, logging and messaging infrastructure.\nLinkSmart\n- Kafka is used at LinkSmart as an event stream feeding Hadoop and custom real time systems.\nLucidWorks Big Data\n- We use Kafka for syncing LucidWorks Search (Solr) with incoming data from Hadoop and also for sending LucidWorks Search logs back to Hadoop for analysis.\nCloud Physics\n- Kafka is powering our high-flow event pipeline that aggregates over 1.2 billion metric series from 1000+ data centers for near-to-real time data center operational analytics and modeling\nGraylog2\n- Graylog2 is a free and open source log management and data analysis system. It's using Kafka as default transport for Graylog2 Radio. The use case is described\nhere\n.\nYieldbot\n- Yieldbot\nuses kafka for real-time events, camus for batch loading, and mirrormakers for x-region replication.\nLivePerson\n-\nUsing Kafka as the main data bus for all real time events.\nRetention Science\n- C\nlick stream ingestion and processing.\nStrava\n-\nPowers our analytics pipeline, activity feeds denorm and several other production services.\nOutbrain\n- We use\nKafka in production for real time log collection and processing, and for cross-DC cache propagation.\nSwiftKey\n- We use Apache Kafka for analytics event processing.\nYeller\n- Yeller uses Kafka to process large streams of incoming exception data for it's customers. Rate limiting, throttling and batching are all built on top of Kafka.\nEmerging Threats\n- Emerging threats uses Kafka\nin our event pipeline to process billions of malware events for search indices, alerting systems, etc.\nHotels.com\n-\nHotels.com uses Kafka as pipeline to collect real time events from multiple sources and for sending data to HDFS.\nHelprace\n-\nKafka is used as a distributed high speed\nmessage queue in our help\ndesk software as well as our real-time event data\naggregation and analytics.\nExponential\nis using Kafka in production to power the\nevents ingestion pipeline for real time analytics and log feed consumption.\nLivefyre\n-\nuses Kafka for the real time\nnotifications, analytics pipeline and as the primary mechanism for general\npub/sub.\nExoscale\n- uses Kafka in production.\nCityzen Data\n- uses Kafka as well, we provide a platform for\ncollecting, storing and analyzing machine data.\nCriteo\n- use Kafka in production\nfor over a year for stream processing and log transfer (over 2M messages/s and growing)\nThe Wikimedia Foundation\n-\nuses Kafka as a log transport for analytics data from production webservers and applications.  This data is consumed into Hadoop using Camus and to other processors of analytics data.\nOVH\n- uses Kafka in production for over a year now using it for event bus, data pipeline for antiddos and more to come.\nHelpshift\nproduces billions of events with Kafka\nthrough an erlang based producer\nekaf\nthat\nsupports 8.0, and consumes topics primarily with storm and clojure.\nParsely\n- Kafka is used for all\ndata integration of\nanalytics event data\n.\nVividCortex\n-\nVividCortex uses Kafka in our SaaS MySQL performance management platform to reliably ingest high-volume 1-second timeseries data.\nTrivago\n- Trivago uses Kafka for stream processing in Storm as well as processing of application logs.\nAnts.vn\n-\nuse Kafka in production for stream processing and log transfer (over 5B messages/month and growing)\nIFTTT\n- W\ne use Kafka to ingest real-time log and tracking data for\nanalytics, dashboards, and m\nachine learning.\nHomeadvisor\n-\nWe use Kafka for logging and async event processing, among other uses.\nSkyscanner\n-\nthe world's travel search engine, uses Kafka for real-time log and event ingestion. It is the integration point for of all stream-processing and data transportation services.\nIBM Message Hub\n- The Message Hub service in our Bluemix PaaS offers Kafka-based messaging in a multi-tenant, pay-as-you-go public cloud. It's intended to provide messaging services for microservices, event-driven processing and streaming data in to analytics systems.\niPinYou\nis the largest DSP in China which has its HQ in Beijing and offices in Shanghai, Guangzhou, Silicon Valley and Seattle. Kafka clusters are the central data hub in iPinYou. All kinds of Internet display advertising data, such as bid/no-bid, impression, click, advertiser, conversion and etc., are collected as primary data streams into Kafka brokers in real time, by LogAggregator (a substitute for Apache Flume, which is implemented in C/C++ by iPinYou, has customized functionality, better performance, lower resource-consuming).\nMailChimp\n- Kafka powers MailChimp’s data pipeline that in turn powers\nMailChimp Pro\n, as well as an increasing number of other product features. You can read some of the details\nhere\n.",
  "url": "https://cwiki.apache.org/confluence/display/KAFKA/Powered+By",
  "space": "KAFKA",
  "labels": [],
  "last_modified": null,
  "source_type": "confluence"
}