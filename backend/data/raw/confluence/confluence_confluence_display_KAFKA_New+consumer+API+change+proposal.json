{
  "id": "confluence_display_KAFKA_New+consumer+API+change+proposal",
  "title": "New consumer API change proposal - Apache Kafka - Apache Software Foundation",
  "content": "API and user requirement analysis\nThe chart above analyzes the new consumer API requirements by looking at the requirements that user might have for each request. We are trying to use this chart to exhaustively list\nAll the functions consumer can possibly achieve.\nAll the potential user requirements\nThe goal is to have a clean and intuitive APIs design with good reasoning for each user requirement (each grid in the above chart).\nThreading Model and Sync/Async Semantics\nCurrently new consumer follows a single threaded model. While it provides simplicity by saving some synchronization efforts, it is also enforces user to care about the things that they don't need to care about. Several examples are:\nWhen user try to commit offsets asynchronously, without calling a poll(), offset won't be committed.\nIf user does not call poll() frequently enough, broker will consider the consumer dead. If user set session timeout to be larger, the failure detection will be also longer.\ncallbacks will not fire.\nWe fixed some problems in KAFKA-2123, which introduced a task queue and will temporarily reuse the caller thread for an \"execution thread\" to run against the queue. But it does not solve the fundamental issue which is user have to essentially provide a dedicated thread keep calling poll even if they actually don't want to consume data. So although new consumer is claimed to be single threaded, it is very likely most user have to write their own wrapper with multiple threads.\nAsync semantic also becomes confusing with the single-threaded model. We are now enforcing user to do something after they fire an async call, which seems to defeat one important purpose of async - user lose the freedom of doing something else after fire an async call. From user point of view, it is as if they are still blocked on that call because they have to keep calling poll().\nThe main benefit of single threaded model is that we can detect client failure when they stop consuming data. We want to change the threading model a bit so it can still have this benefit but solve the issues we mentioned above.\nProposed Solution\nAPI Proposal\npublic interface Consumer<K, V> extends Closeable {\n/**\n* Return the topic partition the consumer is currently subscribing to.\n*/\nSet<TopicPartition> subscriptions();\n/**\n* Subscribe to a specified topics. This method is for user who uses\n* Kafka based group management. This is a blocking call and will return\n* when consumer successfully subscribed to the topic. Exception will be thrown\n* when subscription fails.\n*/\nvoid subscribe(String... topics);\n/**\n* Subscribe to a partition explicitly. This method is for users who want to\n* have self group management. This is a non blocking call and will take effect\n* when user do the next poll().\n*/\nvoid subscribe(TopicPartition... partitions);\n/**\n* Similar to subscribe(String... topics), this method is for users who uses\n* Kafka based group management. It is a blocking call and will return\n* when consumer successfully unsubscribed from the topics. Exception will be\n* thrown when subscription fails.\n*/\nvoid unsubscribe(String... topics);\n/**\n* Unsubscribe from a partition explicitly. This method is for users who want\n* to have self group management. This is a non blocking call and will take\n* effect when user do the next poll().\n*/\nvoid unsubscribe(TopicPartition... partitions);\n/**\n* This method will try to get data from Kafka brokers. It will block for at most\n* timeout if there is no data available, and will return immediately when there\n* are fetched messages.\n*/\nConsumerRecords<K, V> poll(long timeout);\n/**\n* Commit offset for all the partitions this consumer is consuming from. The committed\n* offsets will be the offsets after last poll(). This function is a non-blocking method.\n* If user wants to commit offsets synchronously, user can call commit().get().\n* If user wants to commit offsets asynchronously, user can use the callback.\n*/\nFuture<Map<TopicPartition, Long>> commit(ConsumerCommitCallback callback);\n/**\n* Similar to commit(ConsumerCommitCallback), except this methods allows user to commit specified\n* offsets with optional metadata.\n*/\nFuture<Map<TopicPartition, Long>> commit(Map<TopicPartition, Long> offsets, ConsumerCommitCallback callback);\n/**\n* Temporarily stop consuming from the specified partitions.\n* This is a non-blocking call and will take effect from the next poll()\n*/\nvoid pause(TopicPartition... partitions);\n/**\n* Resume consumption from partitions previously called on pause().\n* This is a non-blocking call and will take effect from the next poll().\n*/\nvoid resume(TopicPartition... partitions);\n/**\n* Seek to a specified offset for a partition. This is a non-blocking call and will take effect\n* from the next poll().\n*/\nvoid seek(TopicPartition partition, long offset);\n/**\n* Seek to the earliest available offsets of the partitions.\n* This method is a non-blocking call and will only take effect from the next poll().\n*/\nvoid seekToBeginning(TopicPartition... partitions);\n/**\n* Seek to the latest offsets of the partitions.\n* Similar to seekToBeginning(TopicPartition...), this is a non-blocking call that will take effect\n* after the next poll().\n*/\nvoid seekToEnd(TopicPartition... partitions);\n/**\n* Return the current offset for the partition this consumer is subscribing to.\n* Exception will be thrown when partition is not in subscriptions.\n*/\nlong position(TopicPartition partition);\n/**\n* Return the committed offsets of a subscribed partition.\n* This is a synchronous call.\n*/\nOffsetAndMetadata committed(TopicPartition partition);\n/**\n* Return the latest offset appended to the log before the specified time.\n* This is a blocking call.\n* If time=-1, the method returns the earliest offset.\n* If time=-2, the method returns the latest offset.\n* Implementation wise, the latest offset can be acquired from the LEO piggybacked\n* in fetch response. So we don't need to talk to broker unless the last fetch response\n* is certain time ago(e.g. 1 second). For the partition the consumer is not consuming from,\n* we still need to talk to broker.\n*/\nOffsetAndMetadata offsetByTime(TopicPartition partition, long time)\n/**\n* Return the metrics.\n*/\nMap<MetricName, ? extends Metric> metrics();\n/**\n* Return the partition information of a topic.\n* This is a synchronous call.\n*/\nList<PartitionInfo> partitionsFor(String topic);\n/**\n* Return all the topic partition information in the cluster.\n* This is a synchronous call.\n*/\nMap<TopicPartition, List<PartitionInfo>> listTopics();\n/**\n* @see KafkaConsumer#close()\n*/\nvoid close();\n}\nThreading-Model Proposal\nThe major gaining of using a single-threaded model is to associate the consumer liveliness with the actual data fetching. The downside of this issue is that the current threading model is sort of \"hijacking\" the user thread to act as an execution thread when user thread calls poll().\nWe want to propose a threading model very similar to what we are using in new producer which has been proven to be welcomed by users. At the same time, we will keep the benefit of single-threaded model with little efforts.\nThe major changes in this threading model are:\nAsynchronous calls will follow the convention and easy to implement.\npoll() becomes very intuitive - meaning user wants some data.\nTo solve the liveliness association with data fetching. We can let sender thread detect how long has it been since the user thread last called poll() - generating a DataFetchTask. If user thread hasn't been fetching for session.timeout, the sender thread can choose to stop heartbeat. This feature can be a boolean config to turn on/off, e.g.\nliveliness.detection.enabled\n. If it is turned on, the liveliness definition will be the same as current new consumer. If it is turned off, the liveliness definition will be the same as old high level consumer.\nSync or Async, that's a question....\nPersonally, I think a call should be sync if\nUser expects information back, or\nsubsequent action depends on the function call.\nOtherwise a method can be async.\nThe assumption is that if user called a method and try to get some information back, they will use that information for further actions. For methods that might have both use cases, we provide both sync/async interface, e.g. commit().\nThe proposed API follows this reasoning, but I'm not sure if they are correctly defined. So we can discuss about that if there are further concerns.\nWith the above threading model, implementation of sync or async will be clean.\nThrowing Exceptions Or Not?\nIn current implementation, consumer will try to handle exceptions if possible. For example, if user try to subscribe to a non-existing topic, the consumer will just wait until the topic to be existed. However, after talking to several users, they actually want to know if a topic does not exist. In that case, throwing exception might be better than handle that for user. Because if user wants to ignore it, they can always catch exception and retry, whereas if we handle it for user, some user who cares about non-existing topic might not know they subscribed to a wrong topic. The above interface followed this reasoning. However, arguably with some checking interface, it might be reasonable to say, if user cares about if a topic exists or not, they can always call listTopics() before subscribing. So I am also not sure if we should throw exceptions in that case or not.",
  "url": "https://cwiki.apache.org/confluence/display/KAFKA/New+consumer+API+change+proposal",
  "space": "KAFKA",
  "labels": [],
  "last_modified": null,
  "source_type": "confluence"
}