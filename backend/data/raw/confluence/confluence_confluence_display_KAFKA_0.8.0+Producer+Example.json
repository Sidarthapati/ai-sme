{
  "id": "confluence_display_KAFKA_0.8.0+Producer+Example",
  "title": "0.8.0 Producer Example - Apache Kafka - Apache Software Foundation",
  "content": "** PLEASE NOTE **\nThe recommended producer is from latest stable release using the new Java producer\nhttp://kafka.apache.org/082/javadoc/org/apache/kafka/clients/producer/KafkaProducer.html\nOnce you have confirmed you have a basic Kafka cluster setup (see\n0.8 Quick Start\n) it is time to write some code!\nProducers\nThe Producer class is used to create new messages for a specific Topic and optional Partition.\nIf using Java you need to include a few packages for the Producer and supporting classes:\nimport kafka.javaapi.producer.Producer;\nimport kafka.producer.KeyedMessage;\nimport kafka.producer.ProducerConfig;\nThe first step in your code is to define properties for how the Producer finds the cluster, serializes the messages and if appropriate directs the message to a specific Partition.\nThese properties are defined in the standard Java Properties object:\nProperties props = new Properties();\nprops.put(\"metadata.broker.list\", \"broker1:9092,broker2:9092\");\nprops.put(\"serializer.class\", \"kafka.serializer.StringEncoder\");\nprops.put(\"partitioner.class\", \"example.producer.SimplePartitioner\");\nprops.put(\"request.required.acks\", \"1\");\nProducerConfig config = new ProducerConfig(props);\nThe first property, “metadata.broker.list” defines where the Producer can find a one or more Brokers to determine the Leader for each topic. This does not need to be the full set of Brokers in your cluster but should include at least two in case the first Broker is not available. No need to worry about figuring out which Broker is the leader for the topic (and partition), the Producer knows how to connect to the Broker and ask for the meta data then connect to the correct Broker.\nThe second property “serializer.class” defines what Serializer to use when preparing the message for transmission to the Broker. In our example we use a simple String encoder provided as part of Kafka. Note that the encoder must accept the same type as defined in the KeyedMessage object in the next step.\nIt is possible to change the Serializer for the Key (see below) of the message by defining \"key.serializer.class\" appropriately. By default it is set to the same value as \"serializer.class\".\nThe third property  \"partitioner.class\" defines what class to use to determine which Partition in the Topic the message is to be sent to. This is optional, but for any non-trivial implementation you are going to want to implement a partitioning scheme. More about the implementation of this class later. If you include a value for the key but haven't defined a partitioner.class Kafka will use the default partitioner. If the key is null, then the Producer will assign the message to a random Partition.\nThe last property \"request.required.acks\" tells Kafka that you want your Producer to require an acknowledgement from the Broker that the message was received. Without this setting the Producer will 'fire and forget' possibly leading to data loss. Additional information can be found\nhere\nNext you define the Producer object itself:\nProducer<String, String> producer = new Producer<String, String>(config);\nNote that the Producer is a Java Generic and you need to tell it the type of two parameters. The first is the type of the Partition key, the second the type of the message. In this example they are both Strings, which also matches to what we defined in the Properties above.\nNow build your message:\nRandom rnd = new Random();\nlong runtime = new Date().getTime();\nString ip = “192.168.2.” + rnd.nextInt(255);\nString msg = runtime + “,www.example.com,” + ip;\nIn this example we are faking a message for a website visit by IP address. First part of the comma-separated message is the timestamp of the event, the second is the website and the third is the IP address of the requester. We use the Java Random class here to make the last octet of the IP vary so we can see how Partitioning works.\nFinally write the message to the Broker:\nKeyedMessage<String, String> data = new KeyedMessage<String, String>(\"page_visits\", ip, msg);\nproducer.send(data);\nThe “page_visits” is the Topic to write to. Here we are passing the IP as the partition key. Note that if you do not include a key, even if you've defined a partitioner class, Kafka will assign the message to a random partition.\nFull Source:\nimport java.util.*;\nimport kafka.javaapi.producer.Producer;\nimport kafka.producer.KeyedMessage;\nimport kafka.producer.ProducerConfig;\npublic class TestProducer {\npublic static void main(String[] args) {\nlong events = Long.parseLong(args[0]);\nRandom rnd = new Random();\nProperties props = new Properties();\nprops.put(\"metadata.broker.list\", \"broker1:9092,broker2:9092 \");\nprops.put(\"serializer.class\", \"kafka.serializer.StringEncoder\");\nprops.put(\"partitioner.class\", \"example.producer.SimplePartitioner\");\nprops.put(\"request.required.acks\", \"1\");\nProducerConfig config = new ProducerConfig(props);\nProducer<String, String> producer = new Producer<String, String>(config);\nfor (long nEvents = 0; nEvents < events; nEvents++) {\nlong runtime = new Date().getTime();\nString ip = “192.168.2.” + rnd.nextInt(255);\nString msg = runtime + “,www.example.com,” + ip;\nKeyedMessage<String, String> data = new KeyedMessage<String, String>(\"page_visits\", ip, msg);\nproducer.send(data);\n}\nproducer.close();\n}\n}\nPartitioning Code:\nimport kafka.producer.Partitioner;\nimport kafka.utils.VerifiableProperties;\npublic class SimplePartitioner implements Partitioner {\npublic SimplePartitioner (VerifiableProperties props) {\n}\npublic int partition(Object key, int a_numPartitions) {\nint partition = 0;\nString stringKey = (String) key;\nint offset = stringKey.lastIndexOf('.');\nif (offset > 0) {\npartition = Integer.parseInt( stringKey.substring(offset+1)) % a_numPartitions;\n}\nreturn partition;\n}\n}\nThe logic takes the key, which we expect to be the IP address, finds the last octet and does a modulo operation on the number of partitions defined within Kafka for the topic. The benefit of this partitioning logic is all web visits from the same source IP end up in the same Partition. Of course so do other IPs, but your consumer logic will need to know how to handle that.\nBefore running this, make sure you have created the Topic page_visits. From the command line:\nbin/kafka-create-topic.sh --topic page_visits --replica 3 --zookeeper localhost:2181 --partition 5\nMake sure you include a --partition option so you create more than one.\nNow compile and run your Producer and data will be written to Kafka.\nTo confirm you have data, use the command line tool to see what was written:\nbin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic page_visits --from-beginning\nMaven\n<dependency>\n<groupId>org.apache.kafka</groupId>\n<artifactId>kafka_2.9.2</artifactId>\n<version>0.8.1.1</version>\n<scope>compile</scope>\n<exclusions>\n<exclusion>\n<artifactId>jmxri</artifactId>\n<groupId>com.sun.jmx</groupId>\n</exclusion>\n<exclusion>\n<artifactId>jms</artifactId>\n<groupId>javax.jms</groupId>\n</exclusion>\n<exclusion>\n<artifactId>jmxtools</artifactId>\n<groupId>com.sun.jdmk</groupId>\n</exclusion>\n</exclusions>\n</dependency>",
  "url": "https://cwiki.apache.org/confluence/display/KAFKA/0.8.0+Producer+Example",
  "space": "KAFKA",
  "labels": [],
  "last_modified": null,
  "source_type": "confluence"
}