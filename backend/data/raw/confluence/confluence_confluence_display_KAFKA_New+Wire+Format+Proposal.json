{
  "id": "confluence_display_KAFKA_New+Wire+Format+Proposal",
  "title": "New Wire Format Proposal - Apache Kafka - Apache Software Foundation",
  "content": "This wiki contains some ideas on improving the Kafka wire format. This could be either a breaking change or introduced as new requests with the existing requests to be removed after one release. The goal would be to do some or all of the following:\nKnown Proposals\nDescription\nAPI\nNew Field\nRelated JIRA\nDiscussion\nAdd correlation id to all requests\nAll requests\ncorrelation_id:int32\nKAFKA-49\nA field to make it possible to multiplex requests over a single socket. This field would be set by the client and would be returned by the server with the response. This would allow a client to make multiple requests on a socket and receive responses asynchronously and know which response was for which request.\nReduce duplication in APIs\nProduceRequest\nMultiProducerRequest\nFetchRequest\nMultiFetchRequest\n-\n-\nCurrently we have both ProduceRequest and MultiProducerRequest and FetchRequest and MultiFetchRequest. The Multi*Request is just the single request version repeated N times. There are a few problems with this: (1) the ProduceRequest and FetchRequest are just special cases of the general Multi*Request format with no real benefit to them (the reason for their existence is largely historical), (2) having both means more API formats to maintain and evolve and test. We should get rid of the single topic/partition APIs and rename the existing Multi*Requests to ProduceRequest and FetchRequest to keep the naming clean.\nReduce repetition of topic name in Multi* APIs\nMultiProducerRequest\nMultiFetchRequest\n-\n-\nCurrently the form of the APIs for the Multi* requests looks something like this: [(topic, partition, messages), (topic, partition, messages), ...]. (Here square brackets denote a variable length list and parenthesis denote a tuple or record). This format is driven by the fact that the Multi* requests are really just a bunch of repeated single topic/partition ProducerRequests. This is  really inefficient, though, as a common case is that we are producing a  bunch of messages for different partitions under the same topic (i.e. if  we are doing the key-based partitioning). It would be better for the  format to be [(topic, [(partition, messages), ...], topic, [(partition,  messages), ...], ...]. This would mean that each topic name is only given  once per request no matter how many partitions within that partition are being produced to.\nSupport \"long poll\" fields in fetch request\n(Multi-)FetchRequest\nmax_wait:int32\nmin_size:int32\nKAFKA-48\nAdd two fields to the fetch request which cause the request to not immediately response. Currently fetch requests always immediately return, potentially with no data for the consumer. It is hence up to the consumer to continually poll for updates. This is not desirable. A better approach would be for the consumer request to block until either (1) min_bytes are available in total amongst all the topics being requests or (2) max_wait time in milliseconds has gone by. This would greatly simplify implementing a high-throughput, high-efficiency, low-latency consumer.\nAdd producer acknowledgement count and timeout\n(Multi-)ProduceRequest\nrequired_acks: int8\nreplication_timeout: int32\nKAFKA-49\nCurrently the produce requests are asynchronous with no acknowledgement from the broker. We should add an option to have the broker acknowledge. The orginal proposal was just to have a boolean \"acknowledgement needed\" but we also need a field to control the number of replicas to block on, so a generalization is to allow the required_acks to be an integer between 0 and the number of replicas. 0 yields the current async behavior whereas > 1 would mean that in addition to blocking on the master we also block on some number of replicas.\nThe replication timeout is the time in ms after which the broker will respond back with an error even if the required number of acknowledgements have not been sent.\nAdd offset to produce response\nProduceResponse\nmessage_set_offset: int64\nKAFKA-49\nAs discussed in KAFKA-49 it would be useful for the acknowledgement from the broker to include the offset at which the message set is available on the broker.\nSeparate request id and version\nAll requests\nversion_id: int16\nCurrently we have a single int32 that identifies both the api and the version of the api. This is slightly more confusing then splitting out the request id and the version id into two 16 bit fields. This isn't a huge win but it does make it more clear the intention when bumping the version number versus adding a new request entirely.\nAdd a client id\nAll requests\nclient_id: string\nCurrently we can only correlate client applications to server requests via the tcp connection. This is a pain. It would be good to have a shared logical id for each application so that we can track metrics by client, log it with errors, etc.\nAdd replica id to fetch request\nFetchRequest\nreplica_id: int32\nThis replica id allows the broker to count the fetch as an acknowledgement for all previous offsets on the given partition. This should be set to -1 for fetch requests from non-replicas outside the cluster.\nOpen Questions\nCan we do a one-time incompatabile refactoring for this?\nPros: no need to keep the old stuff working while adding the new stuff\nCon: hard to roll out. Requires updating all clients in other langs at the same time.\nOne thought on this is that it is probably not too hard to make most of the above changes as new request types and map the old request types to the new. However if we are changing the request id and version id scheme then this will likely not be possible.\nIf we want to do a 0.7.1 release we will need to figure out a sequencing and branching strategy so that no backwards-incompatable changes block this.\nAny other fields need for replication or other use cases we know about?\nCurrently the multi-* responses give only a single error. I wonder if this is sufficient or do they potentially need more. For example if you send a produce request to the wrong partition we need to tell you the right partition, which would be different for each partition.\nRequest Details\nThis section gives the proposed format for the produce and fetch requests after all the above refactorings.\nTo aid understanding I will use the following notation:\nint8, int16, int32, and int64 will be integers of the given byte length\nstring is a int16 giving the size N of the string followed by N bytes of UTF-8 characters.\nmessage_set denotes the existing message set format\n[] denote a variable length list prefixed by a int16\n{} denote the fields of a record. These aren't stored they are just used for grouping.\n// denote comments\n<x> denotes that x is a type that will be defined seperately\nSo as an example a list of records each of which has a name and id field would be denoted by:\n[{id:int32, name:string},...]\nCommon fields\nThe following fields are common to all requests:\nRequest Fields\nfield\ntype\norder\ndescription\nsize\nint32\n1\nThe size of this request (not counting this 4 byte size). This is  mandatory and required by the network layer. It must be the first field in the request.\nrequest_type_id\nint16\n2\nAn id for the API being called (e.g. FetchRequest, ProduceRequest, etc.).\nversion_id\nint16\n3\nA version number for the request format. This number starts at 0 and increases every time a protocol change is made for this API.\ncorrelation_id\nint32\n4\nAn id that can be set by the client and will be returned untouched by the server in the response.\nclient_id\nstring\n5\nAn user-defined identifier for the client which is used for logging and   statistics purposes (e.g. to aggregate statistics across many client   machines in a cluster).\nResponse Fields\nfield\ntype\norder\ndescription\nsize\nint32\n1\nThe size of this request (not counting this 4 byte size). This is   mandatory and required by the network layer. It must be the first field  in the request.\ncorrelation_id\nint32\n2\nAn id that can be set by the client and will be returned untouched by the server in the response.\nversion_id\nint16\n3\nA version number that indicates the format of the response message\nerror\nint16\n4\nThe id of the (request-level) error, if any occurred.\nProduceRequest\n{\nsize: int32 // the size of this request\nrequest_type_id: int16 // the request id\nversion_id: int16 // the version of this request\ncorrelation_id: int32 // an id set by the client that will be returned untouched in the response\nclient_id: string // an optional non-machine-specific identifier for this client\nrequired_acks: int8 // the number of acknowledgements required from the brokers before a response can be made\nack_timeout: int32 // the time in ms to wait for acknowledgement from replicas\ndata: [<topic_data_struct>] // the data for each of the topics, defined below\n}\ntopic_data_struct =>\n{\ntopic: string // the topic name\npartition_data: [<partition_data_struct>] // the data for each partition in that topic, defined below\n}\npartition_data_struct =>\n{\npartition: int32 // the partition id\nmessages: message_set // the actual messages for that partition (same as existing)\n}\nProduceResponse\n{\nsize: int32 // the size of this response\ncorrelation_id: int32 // an id set by the client returned untouched in the response\nversion_id: int16 // the version of this responseÂ  error: int16 // the id of the error that occurred (if any)\nerrors: [int16] // per-partition errors, one for each message set sent (or all -1 if none)\noffsets: [int64] // the offsets for each off the message sets supplied, in the order given in the request\n}\nThe errors and offsets array MUST contain one entry for each message set given in the request an the order must match the order in the request. That is the Nth offset in the offset array corresponds to the Nth message set in the request.\nFetchRequest\n{\nsize: int32 // the size of this request\nrequest_type_id: int16 // the request id\ncorrelation_id: int32 // an id set by the client returned untouched in the response\nversion_id: int16 // the version of this request\nclient_id: string // an optional non-machine-specific identifier for this client\nreplica_id: int32 // the node id of the replica making the request or -1 if this client is not a replica\nmax_wait: int32 // the maximum time to wait for a \"full\" response to accumulate on the server\nmin_bytes: int32 // the minimum number of bytes accumulated to consider a response ready for sending\ntopic_offsets: [<offset_data>]\n}\noffset_data =>\n{\ntopic: string\npartitions: [int32]\noffsets: [int32]\n}\nFetchResponse\n{\nsize: int32 // the size of this response\ncorrelation_id: int32 // an id set by the client returned untouched in the response\nversion_id: int16 // the version of this response\nerror: int16 // global error for this request (if any)\ndata: [<topic_data_struct>] // the actual data requested (in the same format as defined for the produce request)\n}",
  "url": "https://cwiki.apache.org/confluence/display/KAFKA/New+Wire+Format+Proposal",
  "space": "KAFKA",
  "labels": [],
  "last_modified": null,
  "source_type": "confluence"
}