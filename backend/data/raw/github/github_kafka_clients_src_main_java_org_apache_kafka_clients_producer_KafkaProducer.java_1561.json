{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_producer_KafkaProducer.java_1561",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java",
  "content": "        Utils.closeQuietly(producerMetrics, \"producer metrics wrapper\", firstException);\n        Utils.closeQuietly(metrics, \"producer metrics\", firstException);\n        Utils.closeQuietly(keySerializerPlugin, \"producer keySerializer\", firstException);\n        Utils.closeQuietly(valueSerializerPlugin, \"producer valueSerializer\", firstException);\n        Utils.closeQuietly(partitionerPlugin, \"producer partitioner\", firstException);\n        clientTelemetryReporter.ifPresent(reporter -> Utils.closeQuietly(reporter, \"producer telemetry reporter\", firstException));\n        AppInfoParser.unregisterAppInfo(JMX_PREFIX, clientId, metrics);\n        Throwable exception = firstException.get();\n        if (exception != null && !swallowException) {\n            if (exception instanceof InterruptException) {\n                throw (InterruptException) exception;\n            }\n            throw new KafkaException(\"Failed to close kafka producer\", exception);\n        }\n        log.debug(\"Kafka producer has been closed\");\n    }\n\n    /**\n     * computes partition for given record.\n     * if the record has partition returns the value otherwise\n     * if custom partitioner is specified, call it to compute partition\n     * otherwise try to calculate partition based on key.\n     * If there is no key or key should be ignored return\n     * RecordMetadata.UNKNOWN_PARTITION to indicate any partition\n     * can be used (the partition is then calculated by built-in\n     * partitioning logic).\n     */\n    private int partition(ProducerRecord<K, V> record, byte[] serializedKey, byte[] serializedValue, Cluster cluster) {\n        if (record.partition() != null)\n            return record.partition();\n\n        if (partitionerPlugin.get() != null) {\n            int customPartition = partitionerPlugin.get().partition(\n                record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster);\n            if (customPartition < 0) {\n                throw new IllegalArgumentException(String.format(\n                    \"The partitioner generated an invalid partition number: %d. Partition number should always be non-negative.\", customPartition));\n            }\n            return customPartition;\n        }\n\n        if (serializedKey != null && !partitionerIgnoreKeys) {\n            // hash the keyBytes to choose a partition\n            return BuiltInPartitioner.partitionForKey(serializedKey, cluster.partitionsForTopic(record.topic()).size());\n        } else {\n            return RecordMetadata.UNKNOWN_PARTITION;\n        }\n    }\n\n    private void throwIfInvalidGroupMetadata(ConsumerGroupMetadata groupMetadata) {\n        if (groupMetadata == null) {\n            throw new IllegalArgumentException(\"Consumer group metadata could not be null\");\n        } else if (groupMetadata.generationId() > 0\n            && JoinGroupRequest.UNKNOWN_MEMBER_ID.equals(groupMetadata.memberId())) {\n            throw new IllegalArgumentException(\"Passed in group metadata \" + groupMetadata + \" has generationId > 0 but the member.id is unknown\");\n        }\n    }\n\n    private void throwIfNoTransactionManager() {\n        if (transactionManager == null)\n            throw new IllegalStateException(\"Cannot use transactional methods without enabling transactions \" +\n                    \"by setting the \" + ProducerConfig.TRANSACTIONAL_ID_CONFIG + \" configuration property\");\n    }\n\n    // Visible for testing\n    String getClientId() {\n        return clientId;\n    }\n\n    private static class ClusterAndWaitTime {\n        final Cluster cluster;\n        final long waitedOnMetadataMs;\n        ClusterAndWaitTime(Cluster cluster, long waitedOnMetadataMs) {\n            this.cluster = cluster;\n            this.waitedOnMetadataMs = waitedOnMetadataMs;\n        }\n    }\n\n    private static class FutureFailure implements Future<RecordMetadata> {\n\n        private final ExecutionException exception;\n\n        public FutureFailure(Exception exception) {\n            this.exception = new ExecutionException(exception);\n        }\n\n        @Override\n        public boolean cancel(boolean interrupt) {\n            return false;\n        }\n\n        @Override\n        public RecordMetadata get() throws ExecutionException {\n            throw this.exception;\n        }\n\n        @Override\n        public RecordMetadata get(long timeout, TimeUnit unit) throws ExecutionException {\n            throw this.exception;\n        }\n\n        @Override\n        public boolean isCancelled() {\n            return false;\n        }\n\n        @Override\n        public boolean isDone() {\n            return true;\n        }\n\n    }\n\n    /**\n     * Callbacks that are called by the RecordAccumulator append functions:\n     *  - user callback\n     *  - interceptor callbacks\n     *  - partition callback\n     */\n    private class AppendCallbacks implements RecordAccumulator.AppendCallbacks {\n        private final Callback userCallback;\n        private final ProducerInterceptors<K, V> interceptors;\n        private final String topic;\n        private final Integer recordPartition;\n        private final String recordLogString;\n        private volatile int partition = RecordMetadata.UNKNOWN_PARTITION;\n        private volatile TopicPartition topicPartition;\n        private final Headers headers;\n\n        private AppendCallbacks(Callback userCallback, ProducerInterceptors<K, V> interceptors, ProducerRecord<K, V> record) {\n            this.userCallback = userCallback;\n            this.interceptors = interceptors;\n            // Extract record info as we don't want to keep a reference to the record during\n            // whole lifetime of the batch.\n            // We don't want to have an NPE here, because the interceptors would not be notified (see .doSend).\n            topic = record != null ? record.topic() : null;\n            if (record != null) {\n                headers = record.headers();\n            } else {\n                headers = new RecordHeaders();\n                ((RecordHeaders) headers).setReadOnly();\n            }\n            recordPartition = record != null ? record.partition() : null;\n            recordLogString = log.isTraceEnabled() && record != null ? record.toString() : \"\";\n        }\n\n        @Override\n        public void onCompletion(RecordMetadata metadata, Exception exception) {\n            if (metadata == null) {\n                metadata = new RecordMetadata(topicPartition(), -1, -1, RecordBatch.NO_TIMESTAMP, -1, -1);",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java#L1561-L1710",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 1561,
  "end_line": 1710,
  "last_modified": "2026-02-06T01:16:27.608270",
  "source_type": "github"
}