{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_admin_KafkaAdminClient.java_2341",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java",
  "content": "                if (exception != null) {\n                    completeAllExceptionally(topicFutures.values(), exception);\n                    return;\n                }\n\n                final long now = time.milliseconds();\n                Map<Integer, Node> nodeIdMap = nodes.stream().collect(Collectors.toMap(Node::id, node -> node));\n                runnable.call(\n                    generateDescribeTopicsCallWithDescribeTopicPartitionsApi(topicNamesList, topicFutures, nodeIdMap, options, now),\n                    now\n                );\n            });\n\n        return new HashMap<>(topicFutures);\n    }\n\n    private Map<Uuid, KafkaFuture<TopicDescription>> handleDescribeTopicsByIds(Collection<Uuid> topicIds, DescribeTopicsOptions options) {\n\n        final Map<Uuid, KafkaFutureImpl<TopicDescription>> topicFutures = new HashMap<>(topicIds.size());\n        final List<Uuid> topicIdsList = new ArrayList<>();\n        for (Uuid topicId : topicIds) {\n            if (topicIdIsUnrepresentable(topicId)) {\n                KafkaFutureImpl<TopicDescription> future = new KafkaFutureImpl<>();\n                future.completeExceptionally(new InvalidTopicException(\"The given topic id '\" +\n                    topicId + \"' cannot be represented in a request.\"));\n                topicFutures.put(topicId, future);\n            } else if (!topicFutures.containsKey(topicId)) {\n                topicFutures.put(topicId, new KafkaFutureImpl<>());\n                topicIdsList.add(topicId);\n            }\n        }\n        final long now = time.milliseconds();\n        Call call = new Call(\"describeTopicsWithIds\", calcDeadlineMs(now, options.timeoutMs()),\n            new LeastLoadedNodeProvider()) {\n\n            @Override\n            MetadataRequest.Builder createRequest(int timeoutMs) {\n                return new MetadataRequest.Builder(new MetadataRequestData()\n                    .setTopics(convertTopicIdsToMetadataRequestTopic(topicIdsList))\n                    .setAllowAutoTopicCreation(false)\n                    .setIncludeTopicAuthorizedOperations(options.includeAuthorizedOperations()));\n            }\n\n            @Override\n            void handleResponse(AbstractResponse abstractResponse) {\n                MetadataResponse response = (MetadataResponse) abstractResponse;\n                // Handle server responses for particular topics.\n                Cluster cluster = response.buildCluster();\n                Map<Uuid, Errors> errors = response.errorsByTopicId();\n                for (Map.Entry<Uuid, KafkaFutureImpl<TopicDescription>> entry : topicFutures.entrySet()) {\n                    Uuid topicId = entry.getKey();\n                    KafkaFutureImpl<TopicDescription> future = entry.getValue();\n\n                    String topicName = cluster.topicName(topicId);\n                    if (topicName == null) {\n                        future.completeExceptionally(new UnknownTopicIdException(\"TopicId \" + topicId + \" not found.\"));\n                        continue;\n                    }\n                    Errors topicError = errors.get(topicId);\n                    if (topicError != null) {\n                        future.completeExceptionally(topicError.exception());\n                        continue;\n                    }\n\n                    Integer authorizedOperations = response.topicAuthorizedOperations(topicName).get();\n                    TopicDescription topicDescription = getTopicDescriptionFromCluster(cluster, topicName, topicId, authorizedOperations);\n                    future.complete(topicDescription);\n                }\n            }\n\n            @Override\n            void handleFailure(Throwable throwable) {\n                completeAllExceptionally(topicFutures.values(), throwable);\n            }\n        };\n        if (!topicIdsList.isEmpty()) {\n            runnable.call(call, now);\n        }\n        return new HashMap<>(topicFutures);\n    }\n\n    private TopicDescription getTopicDescriptionFromDescribeTopicsResponseTopic(\n        DescribeTopicPartitionsResponseTopic topic,\n        Map<Integer, Node> nodes,\n        boolean includeAuthorizedOperations\n    ) {\n        List<DescribeTopicPartitionsResponsePartition> partitionInfos = topic.partitions();\n        List<TopicPartitionInfo> partitions = new ArrayList<>(partitionInfos.size());\n        for (DescribeTopicPartitionsResponsePartition partitionInfo : partitionInfos) {\n            partitions.add(DescribeTopicPartitionsResponse.partitionToTopicPartitionInfo(partitionInfo, nodes));\n        }\n        Set<AclOperation> authorisedOperations = includeAuthorizedOperations ? validAclOperations(topic.topicAuthorizedOperations()) : null;\n        return new TopicDescription(topic.name(), topic.isInternal(), partitions, authorisedOperations, topic.topicId());\n    }\n\n    private TopicDescription getTopicDescriptionFromCluster(Cluster cluster, String topicName, Uuid topicId,\n                                                            Integer authorizedOperations) {\n        boolean isInternal = cluster.internalTopics().contains(topicName);\n        List<PartitionInfo> partitionInfos = cluster.partitionsForTopic(topicName);\n        List<TopicPartitionInfo> partitions = new ArrayList<>(partitionInfos.size());\n        for (PartitionInfo partitionInfo : partitionInfos) {\n            TopicPartitionInfo topicPartitionInfo = new TopicPartitionInfo(\n                partitionInfo.partition(), leader(partitionInfo), Arrays.asList(partitionInfo.replicas()),\n                Arrays.asList(partitionInfo.inSyncReplicas()));\n            partitions.add(topicPartitionInfo);\n        }\n        partitions.sort(Comparator.comparingInt(TopicPartitionInfo::partition));\n        return new TopicDescription(topicName, isInternal, partitions, validAclOperations(authorizedOperations), topicId);\n    }\n\n    private Node leader(PartitionInfo partitionInfo) {\n        if (partitionInfo.leader() == null || partitionInfo.leader().id() == Node.noNode().id())\n            return null;\n        return partitionInfo.leader();\n    }\n\n    @Override\n    public DescribeClusterResult describeCluster(DescribeClusterOptions options) {\n        final KafkaFutureImpl<Collection<Node>> describeClusterFuture = new KafkaFutureImpl<>();\n        final KafkaFutureImpl<Node> controllerFuture = new KafkaFutureImpl<>();\n        final KafkaFutureImpl<String> clusterIdFuture = new KafkaFutureImpl<>();\n        final KafkaFutureImpl<Set<AclOperation>> authorizedOperationsFuture = new KafkaFutureImpl<>();\n\n        final long now = time.milliseconds();\n        runnable.call(new Call(\"listNodes\", calcDeadlineMs(now, options.timeoutMs()),\n            new LeastLoadedBrokerOrActiveKController()) {\n\n            private boolean useMetadataRequest = false;\n\n            @Override\n            AbstractRequest.Builder<?> createRequest(int timeoutMs) {\n                if (!useMetadataRequest) {\n                    if (metadataManager.usingBootstrapControllers() && options.includeFencedBrokers()) {\n                        throw new IllegalArgumentException(\"Cannot request fenced brokers from controller endpoint\");\n                    }\n                    return new DescribeClusterRequest.Builder(new DescribeClusterRequestData()\n                        .setIncludeClusterAuthorizedOperations(options.includeAuthorizedOperations())\n                        .setEndpointType(metadataManager.usingBootstrapControllers() ?\n                            EndpointType.CONTROLLER.id() : EndpointType.BROKER.id())\n                        .setIncludeFencedBrokers(options.includeFencedBrokers()));\n                } else {\n                    // Since this only requests node information, it's safe to pass true for allowAutoTopicCreation (and it\n                    // simplifies communication with older brokers)\n                    return new MetadataRequest.Builder(new MetadataRequestData()\n                        .setTopics(Collections.emptyList())\n                        .setAllowAutoTopicCreation(true)\n                        .setIncludeClusterAuthorizedOperations(\n                            options.includeAuthorizedOperations()));\n                }\n            }",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java#L2341-L2490",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 2341,
  "end_line": 2490,
  "last_modified": "2026-02-06T01:16:27.585045",
  "source_type": "github"
}