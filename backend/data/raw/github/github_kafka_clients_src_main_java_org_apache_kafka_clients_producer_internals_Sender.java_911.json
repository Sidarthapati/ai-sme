{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_producer_internals_Sender.java_911",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java",
  "content": "                tpData = new ProduceRequestData.TopicProduceData()\n                        .setTopicId(topicId).setName(tp.topic());\n                tpd.add(tpData);\n            }\n\n            tpData.partitionData().add(new ProduceRequestData.PartitionProduceData()\n                    .setIndex(tp.partition())\n                    .setRecords(records));\n            recordsByPartition.put(tp, batch);\n            batch.setInflight(true);\n        }\n\n        String transactionalId = null;\n        boolean useTransactionV1Version = false;\n        if (transactionManager != null && transactionManager.isTransactional()) {\n            transactionalId = transactionManager.transactionalId();\n            useTransactionV1Version = !transactionManager.isTransactionV2Enabled();\n        }\n\n        ProduceRequest.Builder requestBuilder = ProduceRequest.builder(\n                new ProduceRequestData()\n                        .setAcks(acks)\n                        .setTimeoutMs(timeout)\n                        .setTransactionalId(transactionalId)\n                        .setTopicData(tpd),\n                useTransactionV1Version\n        );\n        // Fetch topic names from metadata outside callback as topic ids may change during the callback\n        // for example if topic was recreated.\n        Map<Uuid, String> topicNames = metadata.topicNames();\n\n        RequestCompletionHandler callback = response -> handleProduceResponse(response, recordsByPartition, topicNames, time.milliseconds());\n\n        String nodeId = Integer.toString(destination);\n        ClientRequest clientRequest = client.newClientRequest(nodeId, requestBuilder, now, acks != 0,\n                requestTimeoutMs, callback);\n        client.send(clientRequest, now);\n        log.trace(\"Sent produce request to {}: {}\", nodeId, requestBuilder);\n    }\n\n    private Map<String, Uuid> topicIdsForBatches(List<ProducerBatch> batches) {\n        return batches.stream()\n                .collect(Collectors.toMap(\n                        b -> b.topicPartition.topic(),\n                        b -> metadata.topicIds().getOrDefault(b.topicPartition.topic(), Uuid.ZERO_UUID),\n                        (existing, replacement) -> replacement)\n                );\n    }\n\n    /**\n     * Wake up the selector associated with this send thread\n     */\n    public void wakeup() {\n        this.client.wakeup();\n    }\n\n    public static Sensor throttleTimeSensor(SenderMetricsRegistry metrics) {\n        Sensor produceThrottleTimeSensor = metrics.sensor(\"produce-throttle-time\");\n        produceThrottleTimeSensor.add(metrics.produceThrottleTimeAvg, new Avg());\n        produceThrottleTimeSensor.add(metrics.produceThrottleTimeMax, new Max());\n        return produceThrottleTimeSensor;\n    }\n\n    /**\n     * A collection of sensors for the sender\n     */\n    private static class SenderMetrics {\n        public final Sensor retrySensor;\n        public final Sensor errorSensor;\n        public final Sensor queueTimeSensor;\n        public final Sensor requestTimeSensor;\n        public final Sensor recordsPerRequestSensor;\n        public final Sensor batchSizeSensor;\n        public final Sensor compressionRateSensor;\n        public final Sensor maxRecordSizeSensor;\n        public final Sensor batchSplitSensor;\n        private final SenderMetricsRegistry metrics;\n        private final Time time;\n\n        public SenderMetrics(SenderMetricsRegistry metrics, Metadata metadata, KafkaClient client, Time time) {\n            this.metrics = metrics;\n            this.time = time;\n\n            this.batchSizeSensor = metrics.sensor(\"batch-size\");\n            this.batchSizeSensor.add(metrics.batchSizeAvg, new Avg());\n            this.batchSizeSensor.add(metrics.batchSizeMax, new Max());\n\n            this.compressionRateSensor = metrics.sensor(\"compression-rate\");\n            this.compressionRateSensor.add(metrics.compressionRateAvg, new Avg());\n\n            this.queueTimeSensor = metrics.sensor(\"queue-time\");\n            this.queueTimeSensor.add(metrics.recordQueueTimeAvg, new Avg());\n            this.queueTimeSensor.add(metrics.recordQueueTimeMax, new Max());\n\n            this.requestTimeSensor = metrics.sensor(\"request-time\");\n            this.requestTimeSensor.add(metrics.requestLatencyAvg, new Avg());\n            this.requestTimeSensor.add(metrics.requestLatencyMax, new Max());\n\n            this.recordsPerRequestSensor = metrics.sensor(\"records-per-request\");\n            this.recordsPerRequestSensor.add(new Meter(metrics.recordSendRate, metrics.recordSendTotal));\n            this.recordsPerRequestSensor.add(metrics.recordsPerRequestAvg, new Avg());\n\n            this.retrySensor = metrics.sensor(\"record-retries\");\n            this.retrySensor.add(new Meter(metrics.recordRetryRate, metrics.recordRetryTotal));\n\n            this.errorSensor = metrics.sensor(\"errors\");\n            this.errorSensor.add(new Meter(metrics.recordErrorRate, metrics.recordErrorTotal));\n\n            this.maxRecordSizeSensor = metrics.sensor(\"record-size\");\n            this.maxRecordSizeSensor.add(metrics.recordSizeMax, new Max());\n            this.maxRecordSizeSensor.add(metrics.recordSizeAvg, new Avg());\n\n            this.metrics.addMetric(metrics.requestsInFlight, (config, now) -> client.inFlightRequestCount());\n            this.metrics.addMetric(metrics.metadataAge,\n                (config, now) -> (now - metadata.lastSuccessfulUpdate()) / 1000.0);\n\n            this.batchSplitSensor = metrics.sensor(\"batch-split-rate\");\n            this.batchSplitSensor.add(new Meter(metrics.batchSplitRate, metrics.batchSplitTotal));\n        }\n\n        private void maybeRegisterTopicMetrics(String topic) {\n            // if one sensor of the metrics has been registered for the topic,\n            // then all other sensors should have been registered; and vice versa\n            String topicRecordsCountName = \"topic.\" + topic + \".records-per-batch\";\n            Sensor topicRecordCount = this.metrics.getSensor(topicRecordsCountName);\n            if (topicRecordCount == null) {\n                Map<String, String> metricTags = Collections.singletonMap(\"topic\", topic);\n\n                topicRecordCount = this.metrics.sensor(topicRecordsCountName);\n                MetricName rateMetricName = this.metrics.topicRecordSendRate(metricTags);\n                MetricName totalMetricName = this.metrics.topicRecordSendTotal(metricTags);\n                topicRecordCount.add(new Meter(rateMetricName, totalMetricName));\n\n                String topicByteRateName = \"topic.\" + topic + \".bytes\";\n                Sensor topicByteRate = this.metrics.sensor(topicByteRateName);\n                rateMetricName = this.metrics.topicByteRate(metricTags);\n                totalMetricName = this.metrics.topicByteTotal(metricTags);\n                topicByteRate.add(new Meter(rateMetricName, totalMetricName));\n\n                String topicCompressionRateName = \"topic.\" + topic + \".compression-rate\";\n                Sensor topicCompressionRate = this.metrics.sensor(topicCompressionRateName);\n                MetricName m = this.metrics.topicCompressionRate(metricTags);\n                topicCompressionRate.add(m, new Avg());\n\n                String topicRetryName = \"topic.\" + topic + \".record-retries\";\n                Sensor topicRetrySensor = this.metrics.sensor(topicRetryName);\n                rateMetricName = this.metrics.topicRecordRetryRate(metricTags);\n                totalMetricName = this.metrics.topicRecordRetryTotal(metricTags);\n                topicRetrySensor.add(new Meter(rateMetricName, totalMetricName));\n",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java#L911-L1060",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 911,
  "end_line": 1060,
  "last_modified": "2026-02-06T01:16:27.610196",
  "source_type": "github"
}