{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_producer_KafkaProducer.java_911",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java",
  "content": "     * @throws TimeoutException if the time taken for completing the transaction has surpassed <code>max.block.ms</code>\n     * @throws InterruptException if the thread is interrupted while blocked\n     */\n    @Override\n    public void completeTransaction(PreparedTxnState preparedTxnState) throws ProducerFencedException {\n        throwIfNoTransactionManager();\n        throwIfProducerClosed();\n        \n        if (!transactionManager.isPrepared()) {\n            throw new InvalidTxnStateException(\"Cannot complete transaction because no transaction has been prepared. \" +\n                \"Call prepareTransaction() first, or make sure initTransaction(true) was called.\");\n        }\n        \n        // Get the current prepared transaction state\n        ProducerIdAndEpoch currentProducerIdAndEpoch = transactionManager.preparedTransactionState();\n        PreparedTxnState currentPreparedState = new PreparedTxnState(currentProducerIdAndEpoch.producerId, currentProducerIdAndEpoch.epoch);\n        \n        // Compare the prepared transaction state token and commit or abort accordingly\n        if (currentPreparedState.equals(preparedTxnState)) {\n            commitTransaction();\n        } else {\n            abortTransaction();\n        }\n    }\n\n    /**\n     * Asynchronously send a record to a topic. Equivalent to <code>send(record, null)</code>.\n     * See {@link #send(ProducerRecord, Callback)} for details.\n     */\n    @Override\n    public Future<RecordMetadata> send(ProducerRecord<K, V> record) {\n        return send(record, null);\n    }\n\n    /**\n     * Asynchronously send a record to a topic and invoke the provided callback when the send has been acknowledged.\n     * <p>\n     * The send is asynchronous and this method will return immediately (except for rare cases described below)\n     * once the record has been stored in the buffer of records waiting to be sent.\n     * This allows sending many records in parallel without blocking to wait for the response after each one.\n     * Can block for the following cases: 1) For the first record being sent to \n     * the cluster by this client for the given topic. In this case it will block for up to {@code max.block.ms} milliseconds \n     * while waiting for topic's metadata if Kafka cluster is unreachable; 2) Allocating a buffer if buffer pool doesn't\n     * have any free buffers.\n     * <p>\n     * <b>Reducing first-send latency:</b> You can reduce the latency of the first send by preloading the metadata\n     * with {@link #partitionsFor(String)}. However, be aware that metadata cache will be cleared to free up resources after\n     * {@code metadata.max.idle.ms} of inactivity, so subsequent sends after a long idle period will still\n     * experience delays.\n     * <p>\n     * The result of the send is a {@link RecordMetadata} specifying the partition the record was sent to, the offset\n     * it was assigned and the timestamp of the record. If the producer is configured with acks = 0, the {@link RecordMetadata}\n     * will have offset = -1 because the producer does not wait for the acknowledgement from the broker.\n     * If {@link org.apache.kafka.common.record.TimestampType#CREATE_TIME CreateTime} is used by the topic, the timestamp\n     * will be the user provided timestamp or the record send time if the user did not specify a timestamp for the\n     * record. If {@link org.apache.kafka.common.record.TimestampType#LOG_APPEND_TIME LogAppendTime} is used for the\n     * topic, the timestamp will be the Kafka broker local time when the message is appended.\n     * <p>\n     * Since the send call is asynchronous it returns a {@link java.util.concurrent.Future Future} for the\n     * {@link RecordMetadata} that will be assigned to this record. Invoking {@link java.util.concurrent.Future#get()\n     * get()} on this future will block until the associated request completes and then return the metadata for the record\n     * or throw any exception that occurred while sending the record.\n     * <p>\n     * If you want to simulate a simple blocking call you can call the <code>get()</code> method immediately:\n     *\n     * <pre>\n     * {@code\n     * byte[] key = \"key\".getBytes();\n     * byte[] value = \"value\".getBytes();\n     * ProducerRecord<byte[],byte[]> record = new ProducerRecord<byte[],byte[]>(\"my-topic\", key, value)\n     * producer.send(record).get();\n     * }</pre>\n     * <p>\n     * Fully non-blocking usage can make use of the {@link Callback} parameter to provide a callback that\n     * will be invoked when the request is complete.\n     *\n     * <pre>\n     * {@code\n     * ProducerRecord<byte[],byte[]> record = new ProducerRecord<byte[],byte[]>(\"the-topic\", key, value);\n     * producer.send(myRecord,\n     *               new Callback() {\n     *                   public void onCompletion(RecordMetadata metadata, Exception e) {\n     *                       if(e != null) {\n     *                          e.printStackTrace();\n     *                       } else {\n     *                          System.out.println(\"The offset of the record we just sent is: \" + metadata.offset());\n     *                       }\n     *                   }\n     *               });\n     * }\n     * </pre>\n     *\n     * Callbacks for records being sent to the same partition are guaranteed to execute in order. That is, in the\n     * following example <code>callback1</code> is guaranteed to execute before <code>callback2</code>:\n     *\n     * <pre>\n     * {@code\n     * producer.send(new ProducerRecord<byte[],byte[]>(topic, partition, key1, value1), callback1);\n     * producer.send(new ProducerRecord<byte[],byte[]>(topic, partition, key2, value2), callback2);\n     * }\n     * </pre>\n     * <p>\n     * When used as part of a transaction, it is not necessary to define a callback or check the result of the future\n     * in order to detect errors from <code>send</code>. If any of the send calls failed with an irrecoverable error,\n     * the final {@link #commitTransaction()} call will fail and throw the exception from the last failed send. When\n     * this happens, your application should call {@link #abortTransaction()} to reset the state and continue to send\n     * data.\n     * </p>\n     * <p>\n     * Some transactional send errors cannot be resolved with a call to {@link #abortTransaction()}.  In particular,\n     * if a transactional send finishes with a {@link ProducerFencedException}, a {@link org.apache.kafka.common.errors.OutOfOrderSequenceException},\n     * a {@link org.apache.kafka.common.errors.UnsupportedVersionException}, or an\n     * {@link org.apache.kafka.common.errors.AuthorizationException}, then the only option left is to call {@link #close()}.\n     * Fatal errors cause the producer to enter a defunct state in which future API calls will continue to raise\n     * the same underlying error wrapped in a new {@link KafkaException}.\n     * </p>\n     * <p>\n     * It is a similar picture when idempotence is enabled, but no <code>transactional.id</code> has been configured.\n     * In this case, {@link org.apache.kafka.common.errors.UnsupportedVersionException} and\n     * {@link org.apache.kafka.common.errors.AuthorizationException} are considered fatal errors. However,\n     * {@link ProducerFencedException} does not need to be handled. Additionally, it is possible to continue\n     * sending after receiving an {@link org.apache.kafka.common.errors.OutOfOrderSequenceException}, but doing so\n     * can result in out of order delivery of pending messages. To ensure proper ordering, you should close the\n     * producer and create a new instance.\n     * </p>\n     * <p>\n     * If the message format of the destination topic is not upgraded to 0.11.0.0, idempotent and transactional\n     * produce requests will fail with an {@link org.apache.kafka.common.errors.UnsupportedForMessageFormatException}\n     * error. If this is encountered during a transaction, it is possible to abort and continue. But note that future\n     * sends to the same topic will continue receiving the same exception until the topic is upgraded.\n     * </p>\n     * <p>\n     * Note that callbacks will generally execute in the I/O thread of the producer and so should be reasonably fast or\n     * they will delay the sending of messages from other threads. If you want to execute blocking or computationally\n     * expensive callbacks it is recommended to use your own {@link java.util.concurrent.Executor} in the callback body\n     * to parallelize processing.\n     *\n     * @param record   The record to send. If the topic or the partition specified in it cannot be found\n     *                 in metadata within {@code max.block.ms}, the returned future will time out when retrieved.\n     * @param callback A user-supplied callback to execute when the record has been acknowledged by the server (null\n     *                 indicates no callback)\n     * @throws IllegalStateException  if a transactional.id has been configured and no transaction has been started, or\n     *                                when send is invoked after producer has been closed.\n     * @throws InterruptException     If the thread is interrupted while blocked\n     * @throws SerializationException If the key or value are not valid objects given the configured serializers\n     * @throws KafkaException         If a Kafka related error occurs that does not belong to the public API exceptions.\n     * @see #partitionsFor(String)\n     */\n    @Override\n    public Future<RecordMetadata> send(ProducerRecord<K, V> record, Callback callback) {",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java#L911-L1060",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 911,
  "end_line": 1060,
  "last_modified": "2026-02-06T01:16:27.608270",
  "source_type": "github"
}