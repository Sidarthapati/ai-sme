{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_producer_internals_Sender.java_521",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java",
  "content": "    private void maybeFindCoordinatorAndRetry(TransactionManager.TxnRequestHandler nextRequestHandler) {\n        if (nextRequestHandler.needsCoordinator()) {\n            transactionManager.lookupCoordinator(nextRequestHandler);\n        } else {\n            // For non-coordinator requests, sleep here to prevent a tight loop when no node is available\n            time.sleep(retryBackoffMs);\n            metadata.requestUpdate(false);\n        }\n\n        transactionManager.retry(nextRequestHandler);\n    }\n\n    private void maybeAbortBatches(RuntimeException exception) {\n        if (accumulator.hasIncomplete()) {\n            log.error(\"Aborting producer batches due to fatal error\", exception);\n            accumulator.abortBatches(exception);\n            inFlightBatches.clear();\n        }\n    }\n\n    /**\n     * Start closing the sender (won't actually complete until all data is sent out)\n     */\n    public void initiateClose() {\n        // Ensure accumulator is closed first to guarantee that no more appends are accepted after\n        // breaking from the sender loop. Otherwise, we may miss some callbacks when shutting down.\n        this.accumulator.close();\n        this.running = false;\n        this.wakeup();\n    }\n\n    /**\n     * Closes the sender without sending out any pending messages.\n     */\n    public void forceClose() {\n        this.forceClose = true;\n        initiateClose();\n    }\n\n    public boolean isRunning() {\n        return running;\n    }\n\n    private boolean awaitNodeReady(Node node, FindCoordinatorRequest.CoordinatorType coordinatorType) throws IOException {\n        if (NetworkClientUtils.awaitReady(client, node, time, requestTimeoutMs)) {\n            if (coordinatorType == FindCoordinatorRequest.CoordinatorType.TRANSACTION) {\n                // Indicate to the transaction manager that the coordinator is ready, allowing it to check ApiVersions\n                // This allows us to bump transactional epochs even if the coordinator is temporarily unavailable at\n                // the time when the abortable error is handled\n                transactionManager.handleCoordinatorReady();\n            }\n            return true;\n        }\n        return false;\n    }\n\n    /**\n     * Handle a produce response\n     */\n    private void handleProduceResponse(ClientResponse response, Map<TopicPartition, ProducerBatch> batches, Map<Uuid, String> topicNames, long now) {\n        RequestHeader requestHeader = response.requestHeader();\n        int correlationId = requestHeader.correlationId();\n        if (response.wasTimedOut()) {\n            log.trace(\"Cancelled request with header {} due to the last request to node {} timed out\",\n                requestHeader, response.destination());\n            for (ProducerBatch batch : batches.values())\n                completeBatch(batch, new ProduceResponse.PartitionResponse(Errors.REQUEST_TIMED_OUT, String.format(\"Disconnected from node %s due to timeout\", response.destination())),\n                        correlationId, now, null);\n        } else if (response.wasDisconnected()) {\n            log.trace(\"Cancelled request with header {} due to node {} being disconnected\",\n                requestHeader, response.destination());\n            for (ProducerBatch batch : batches.values())\n                completeBatch(batch, new ProduceResponse.PartitionResponse(Errors.NETWORK_EXCEPTION, String.format(\"Disconnected from node %s\", response.destination())),\n                        correlationId, now, null);\n        } else if (response.versionMismatch() != null) {\n            log.warn(\"Cancelled request {} due to a version mismatch with node {}\",\n                    response, response.destination(), response.versionMismatch());\n            for (ProducerBatch batch : batches.values())\n                completeBatch(batch, new ProduceResponse.PartitionResponse(Errors.UNSUPPORTED_VERSION), correlationId, now, null);\n        } else {\n            log.trace(\"Received produce response from node {} with correlation id {}\", response.destination(), correlationId);\n            // if we have a response, parse it\n            if (response.hasResponse()) {\n                // Sender should exercise PartitionProduceResponse rather than ProduceResponse.PartitionResponse\n                // https://issues.apache.org/jira/browse/KAFKA-10696\n                ProduceResponse produceResponse = (ProduceResponse) response.responseBody();\n                // This will be set by completeBatch.\n                Map<TopicPartition, Metadata.LeaderIdAndEpoch> partitionsWithUpdatedLeaderInfo = new HashMap<>();\n                produceResponse.data().responses().forEach(r -> r.partitionResponses().forEach(p -> {\n                    ProduceResponse.PartitionResponse partResp = new ProduceResponse.PartitionResponse(\n                            Errors.forCode(p.errorCode()),\n                            p.baseOffset(),\n                            p.logAppendTimeMs(),\n                            p.logStartOffset(),\n                            p.recordErrors()\n                                .stream()\n                                .map(e -> new ProduceResponse.RecordError(e.batchIndex(), e.batchIndexErrorMessage()))\n                                .collect(Collectors.toList()),\n                            p.errorMessage(),\n                            p.currentLeader());\n\n                    // Version 13 drops topic name, and supports topic id.\n                    // We need to find batch based on topic id and partition index only as\n                    // topic name in the response will be empty.\n                    // For older versions, topic id is zero, and we will find the batch based on the topic name.\n                    TopicPartition tp = (!r.topicId().equals(Uuid.ZERO_UUID) && topicNames.containsKey(r.topicId())) ?\n                            new TopicPartition(topicNames.get(r.topicId()), p.index()) :\n                            new TopicPartition(r.name(), p.index());\n\n                    ProducerBatch batch = batches.get(tp);\n                    if (batch == null) {\n                        throw new IllegalStateException(\"Can't find batch created for topic id \" + r.topicId() +\n                                \" topic name \" + r.name() + \" partition \" + p.index() + \" using \" + topicNames);\n                    }\n                    completeBatch(batch, partResp, correlationId, now, partitionsWithUpdatedLeaderInfo);\n                }));\n\n                if (!partitionsWithUpdatedLeaderInfo.isEmpty()) {\n                    List<Node> leaderNodes = produceResponse.data().nodeEndpoints().stream()\n                        .map(e -> new Node(e.nodeId(), e.host(), e.port(), e.rack()))\n                        .filter(e -> !e.equals(Node.noNode()))\n                        .collect(\n                            Collectors.toList());\n                    Set<TopicPartition> updatedPartitions = metadata.updatePartitionLeadership(partitionsWithUpdatedLeaderInfo, leaderNodes);\n                    if (log.isTraceEnabled()) {\n                        updatedPartitions.forEach(\n                            part -> log.debug(\"For {} leader was updated.\", part)\n                        );\n                    }\n                }\n\n                this.sensors.recordLatency(response.destination(), response.requestLatencyMs());\n            } else {\n                // this is the acks = 0 case, just complete all requests\n                for (ProducerBatch batch : batches.values()) {\n                    completeBatch(batch, new ProduceResponse.PartitionResponse(Errors.NONE), correlationId, now, null);\n                }\n            }\n        }\n    }\n\n    /**\n     * Complete or retry the given batch of records.\n     *\n     * @param batch The record batch\n     * @param response The produce response\n     * @param correlationId The correlation id for the request\n     * @param now The current POSIX timestamp in milliseconds\n     * @param partitionsWithUpdatedLeaderInfo This will be populated with partitions that have updated leader info.\n     */",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java#L521-L670",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 521,
  "end_line": 670,
  "last_modified": "2026-02-06T01:16:27.610196",
  "source_type": "github"
}