{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_producer_internals_TransactionManager.java_911",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java",
  "content": "                sequence == this.partitionsWithUnresolvedSequences.get(topicPartition);\n    }\n\n    synchronized TxnRequestHandler nextRequest(boolean hasIncompleteBatches) {\n        if (!newPartitionsInTransaction.isEmpty())\n            enqueueRequest(addPartitionsToTransactionHandler());\n\n        TxnRequestHandler nextRequestHandler = pendingRequests.peek();\n        if (nextRequestHandler == null)\n            return null;\n\n        // Do not send the EndTxn until all batches have been flushed\n        if (nextRequestHandler.isEndTxn() && hasIncompleteBatches)\n            return null;\n\n        pendingRequests.poll();\n        if (maybeTerminateRequestWithError(nextRequestHandler)) {\n            log.trace(\"Not sending transactional request {} because we are in an error state\",\n                    nextRequestHandler.requestBuilder());\n            return null;\n        }\n\n        if (nextRequestHandler.isEndTxn() && !transactionStarted) {\n            nextRequestHandler.result.done();\n            if (currentState != State.FATAL_ERROR) {\n                if (isTransactionV2Enabled) {\n                    log.debug(\"Not sending EndTxn for completed transaction since no send \" +\n                            \"or sendOffsetsToTransaction were triggered\");\n                } else {\n                    log.debug(\"Not sending EndTxn for completed transaction since no partitions \" +\n                            \"or offsets were successfully added\");\n                }\n                resetTransactionState();\n            }\n            nextRequestHandler = pendingRequests.poll();\n        }\n\n        if (nextRequestHandler != null)\n            log.trace(\"Request {} dequeued for sending\", nextRequestHandler.requestBuilder());\n\n        return nextRequestHandler;\n    }\n\n    synchronized void retry(TxnRequestHandler request) {\n        request.setRetry();\n        enqueueRequest(request);\n    }\n\n    synchronized void authenticationFailed(AuthenticationException e) {\n        for (TxnRequestHandler request : pendingRequests)\n            request.fatalError(e);\n    }\n\n    synchronized void failPendingRequests(RuntimeException exception) {\n        pendingRequests.forEach(handler ->\n                handler.abortableError(exception));\n    }\n\n    synchronized void close() {\n        KafkaException shutdownException = new KafkaException(\"The producer closed forcefully\");\n        pendingRequests.forEach(handler ->\n                handler.fatalError(shutdownException));\n        if (pendingTransition != null) {\n            pendingTransition.result.fail(shutdownException);\n        }\n    }\n\n    Node coordinator(FindCoordinatorRequest.CoordinatorType type) {\n        switch (type) {\n            case GROUP:\n                return consumerGroupCoordinator;\n            case TRANSACTION:\n                return transactionCoordinator;\n            default:\n                throw new IllegalStateException(\"Received an invalid coordinator type: \" + type);\n        }\n    }\n\n    void lookupCoordinator(TxnRequestHandler request) {\n        lookupCoordinator(request.coordinatorType(), request.coordinatorKey());\n    }\n\n    void setInFlightCorrelationId(int correlationId) {\n        inFlightRequestCorrelationId = correlationId;\n    }\n\n    private void clearInFlightCorrelationId() {\n        inFlightRequestCorrelationId = NO_INFLIGHT_REQUEST_CORRELATION_ID;\n    }\n\n    boolean hasInFlightRequest() {\n        return inFlightRequestCorrelationId != NO_INFLIGHT_REQUEST_CORRELATION_ID;\n    }\n\n    // visible for testing.\n    boolean hasFatalError() {\n        return currentState == State.FATAL_ERROR;\n    }\n\n    // visible for testing.\n    boolean hasAbortableError() {\n        return currentState == State.ABORTABLE_ERROR;\n    }\n\n    // visible for testing\n    public synchronized boolean transactionContainsPartition(TopicPartition topicPartition) {\n        return partitionsInTransaction.contains(topicPartition);\n    }\n\n    // visible for testing\n    synchronized boolean hasPendingOffsetCommits() {\n        return !pendingTxnOffsetCommits.isEmpty();\n    }\n\n    synchronized boolean hasPendingRequests() {\n        return !pendingRequests.isEmpty();\n    }\n\n    // visible for testing\n    synchronized boolean hasOngoingTransaction() {\n        // transactions are considered ongoing once started until completion or a fatal error\n        return currentState == State.IN_TRANSACTION || isCompleting() || hasAbortableError();\n    }\n\n    synchronized boolean canRetry(ProduceResponse.PartitionResponse response, ProducerBatch batch) {\n        Errors error = response.error;\n\n        // An UNKNOWN_PRODUCER_ID means that we have lost the producer state on the broker. Depending on the log start\n        // offset, we may want to retry these, as described for each case below. If none of those apply, then for the\n        // idempotent producer, we will locally bump the epoch and reset the sequence numbers of in-flight batches from\n        // sequence 0, then retry the failed batch, which should now succeed. For the transactional producer, allow the\n        // batch to fail. When processing the failed batch, we will transition to an abortable error and set a flag\n        // indicating that we need to bump the epoch (if supported by the broker).\n        if (error == Errors.UNKNOWN_PRODUCER_ID) {\n            if (response.logStartOffset == -1) {\n                // We don't know the log start offset with this response. We should just retry the request until we get it.\n                // The UNKNOWN_PRODUCER_ID error code was added along with the new ProduceResponse which includes the\n                // logStartOffset. So the '-1' sentinel is not for backward compatibility. Instead, it is possible for\n                // a broker to not know the logStartOffset at when it is returning the response because the partition\n                // may have moved away from the broker from the time the error was initially raised to the time the\n                // response was being constructed. In these cases, we should just retry the request: we are guaranteed\n                // to eventually get a logStartOffset once things settle down.\n                return true;\n            }\n\n            if (batch.sequenceHasBeenReset()) {\n                // When the first inflight batch fails due to the truncation case, then the sequences of all the other\n                // in flight batches would have been restarted from the beginning. However, when those responses\n                // come back from the broker, they would also come with an UNKNOWN_PRODUCER_ID error. In this case, we should not\n                // reset the sequence numbers to the beginning.",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java#L911-L1060",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 911,
  "end_line": 1060,
  "last_modified": "2026-02-06T01:16:27.610496",
  "source_type": "github"
}