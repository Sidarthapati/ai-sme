{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_NetworkClient.java_1171",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/NetworkClient.java",
  "content": "        return apiKey == ApiKeys.GET_TELEMETRY_SUBSCRIPTIONS || apiKey == ApiKeys.PUSH_TELEMETRY;\n    }\n\n    class DefaultMetadataUpdater implements MetadataUpdater {\n\n        /* the current cluster metadata */\n        private final Metadata metadata;\n\n        // Defined if there is a request in progress, null otherwise\n        private InProgressData inProgress;\n\n        /*\n         * The time in wall-clock milliseconds when we started attempts to fetch metadata. If empty,\n         * metadata has not been requested. This is the start time based on which rebootstrap is\n         * triggered if metadata is not obtained for the configured rebootstrap trigger interval.\n         * Set to Optional.of(0L) to force rebootstrap immediately.\n         */\n        private Optional<Long> metadataAttemptStartMs = Optional.empty();\n\n\n        DefaultMetadataUpdater(Metadata metadata) {\n            this.metadata = metadata;\n            this.inProgress = null;\n        }\n\n        @Override\n        public List<Node> fetchNodes() {\n            return metadata.fetch().nodes();\n        }\n\n        @Override\n        public boolean isUpdateDue(long now) {\n            return !hasFetchInProgress() && this.metadata.timeToNextUpdate(now) == 0;\n        }\n\n        private boolean hasFetchInProgress() {\n            return inProgress != null;\n        }\n\n        @Override\n        public long maybeUpdate(long now) {\n            // should we update our metadata?\n            long timeToNextMetadataUpdate = metadata.timeToNextUpdate(now);\n            long waitForMetadataFetch = hasFetchInProgress() ? defaultRequestTimeoutMs : 0;\n\n            long metadataTimeout = Math.max(timeToNextMetadataUpdate, waitForMetadataFetch);\n            if (metadataTimeout > 0) {\n                return metadataTimeout;\n            }\n\n            if (metadataAttemptStartMs.isEmpty())\n                metadataAttemptStartMs = Optional.of(now);\n\n            // Beware that the behavior of this method and the computation of timeouts for poll() are\n            // highly dependent on the behavior of leastLoadedNode.\n            LeastLoadedNode leastLoadedNode = leastLoadedNode(now);\n\n            // Rebootstrap if needed and configured.\n            if (metadataRecoveryStrategy == MetadataRecoveryStrategy.REBOOTSTRAP\n                    && !leastLoadedNode.hasNodeAvailableOrConnectionReady()) {\n                rebootstrap(now);\n\n                leastLoadedNode = leastLoadedNode(now);\n            }\n\n            if (leastLoadedNode.node() == null) {\n                log.debug(\"Give up sending metadata request since no node is available\");\n                return reconnectBackoffMs;\n            }\n\n            return maybeUpdate(now, leastLoadedNode.node());\n        }\n\n        @Override\n        public void handleServerDisconnect(long now, String destinationId, Optional<AuthenticationException> maybeFatalException) {\n            Cluster cluster = metadata.fetch();\n            // 'processDisconnection' generates warnings for misconfigured bootstrap server configuration\n            // resulting in 'Connection Refused' and misconfigured security resulting in authentication failures.\n            // The warning below handles the case where a connection to a broker was established, but was disconnected\n            // before metadata could be obtained.\n            if (cluster.isBootstrapConfigured()) {\n                int nodeId = Integer.parseInt(destinationId);\n                Node node = cluster.nodeById(nodeId);\n                if (node != null)\n                    log.warn(\"Bootstrap broker {} disconnected\", node);\n            }\n\n            // If we have a disconnect while an update is due, we treat it as a failed update\n            // so that we can backoff properly\n            if (isUpdateDue(now))\n                handleFailedRequest(now, Optional.empty());\n\n            maybeFatalException.ifPresent(metadata::fatalError);\n\n            // The disconnect may be the result of stale metadata, so request an update\n            metadata.requestUpdate(false);\n        }\n\n        @Override\n        public void handleFailedRequest(long now, Optional<KafkaException> maybeFatalException) {\n            maybeFatalException.ifPresent(metadata::fatalError);\n            metadata.failedUpdate(now);\n            inProgress = null;\n        }\n\n        @Override\n        public void handleSuccessfulResponse(RequestHeader requestHeader, long now, MetadataResponse response) {\n            // If any partition has leader with missing listeners, log up to ten of these partitions\n            // for diagnosing broker configuration issues.\n            // This could be a transient issue if listeners were added dynamically to brokers.\n            List<TopicPartition> missingListenerPartitions = response.topicMetadata().stream().flatMap(topicMetadata ->\n                topicMetadata.partitionMetadata().stream()\n                    .filter(partitionMetadata -> partitionMetadata.error == Errors.LISTENER_NOT_FOUND)\n                    .map(partitionMetadata -> new TopicPartition(topicMetadata.topic(), partitionMetadata.partition())))\n                .collect(Collectors.toList());\n            if (!missingListenerPartitions.isEmpty()) {\n                int count = missingListenerPartitions.size();\n                log.warn(\"{} partitions have leader brokers without a matching listener, including {}\",\n                        count, missingListenerPartitions.subList(0, Math.min(10, count)));\n            }\n\n            // Check if any topic's metadata failed to get updated\n            Map<String, Errors> errors = response.errors();\n            if (!errors.isEmpty())\n                log.warn(\"The metadata response from the cluster reported a recoverable issue with correlation id {} : {}\", requestHeader.correlationId(), errors);\n\n            if (metadataRecoveryStrategy == MetadataRecoveryStrategy.REBOOTSTRAP && response.topLevelError() == Errors.REBOOTSTRAP_REQUIRED) {\n                log.info(\"Rebootstrap requested by server.\");\n                initiateRebootstrap();\n            } else if (response.brokers().isEmpty()) {\n                // When talking to the startup phase of a broker, it is possible to receive an empty metadata set, which\n                // we should retry later.\n                log.trace(\"Ignoring empty metadata response with correlation id {}.\", requestHeader.correlationId());\n                this.metadata.failedUpdate(now);\n            } else {\n                this.metadata.update(inProgress.requestVersion, response, inProgress.isPartialUpdate, now);\n                metadataAttemptStartMs = Optional.empty();\n            }\n\n            inProgress = null;\n        }\n\n        @Override\n        public boolean needsRebootstrap(long now, long rebootstrapTriggerMs) {\n            return metadataAttemptStartMs.filter(startMs -> now - startMs > rebootstrapTriggerMs).isPresent();\n        }\n\n        @Override\n        public void rebootstrap(long now) {\n            metadata.rebootstrap();",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/NetworkClient.java#L1171-L1320",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/NetworkClient.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 1171,
  "end_line": 1320,
  "last_modified": "2026-02-06T01:16:27.578839",
  "source_type": "github"
}