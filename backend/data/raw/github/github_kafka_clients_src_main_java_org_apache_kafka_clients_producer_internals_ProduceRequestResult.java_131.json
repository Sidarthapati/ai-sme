{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_producer_internals_ProduceRequestResult.java_131",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/producer/internals/ProduceRequestResult.java",
  "content": "     */\n    public void awaitAllDependents() throws InterruptedException {\n        Queue<ProduceRequestResult> toWait = new ArrayDeque<>();\n        toWait.add(this);\n\n        while (!toWait.isEmpty()) {\n            ProduceRequestResult current = toWait.poll();\n\n            // first wait for THIS result's latch to be released\n            current.latch.await();\n\n            // add all dependent split batches to the queue.\n            // we synchronize to get a consistent snapshot, then release the lock\n            // before continuing but the actual waiting happens outside the lock.\n            synchronized (current.dependentResults) {\n                toWait.addAll(current.dependentResults);\n            }\n        }\n    }\n\n    /**\n     * The base offset for the request (the first offset in the record set)\n     */\n    public long baseOffset() {\n        return baseOffset;\n    }\n\n    /**\n     * Return true if log append time is being used for this topic\n     */\n    public boolean hasLogAppendTime() {\n        return logAppendTime != RecordBatch.NO_TIMESTAMP;\n    }\n\n    /**\n     * The log append time or -1 if CreateTime is being used\n     */\n    public long logAppendTime() {\n        return logAppendTime;\n    }\n\n    /**\n     * The error thrown (generally on the server) while processing this request\n     */\n    public RuntimeException error(int batchIndex) {\n        if (errorsByIndex == null) {\n            return null;\n        } else {\n            return errorsByIndex.apply(batchIndex);\n        }\n    }\n\n    /**\n     * The topic and partition to which the record was appended\n     */\n    public TopicPartition topicPartition() {\n        return topicPartition;\n    }\n\n    /**\n     * Has the request completed?\n     *\n     * This method only checks if THIS request has completed and not its dependent results.\n     * When a batch is split into multiple batches, the dependent split batches are tracked\n     * separately. Individual record futures handle waiting for their respective split\n     * batch via {@link FutureRecordMetadata#chain(FutureRecordMetadata)}, which updates the\n     * {@code nextRecordMetadata} pointer to follow the correct split batch.\n     *\n     * For flush() semantics that require waiting for all dependent results, use\n     * {@link #awaitAllDependents()}.\n     */\n    public boolean completed() {\n        return this.latch.getCount() == 0L;\n    }\n}\n",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/ProduceRequestResult.java#L131-L206",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/ProduceRequestResult.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 131,
  "end_line": 206,
  "last_modified": "2026-02-06T01:16:27.609602",
  "source_type": "github"
}