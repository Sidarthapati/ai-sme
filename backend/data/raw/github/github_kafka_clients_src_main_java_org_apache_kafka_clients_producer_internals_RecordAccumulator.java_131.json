{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_producer_internals_RecordAccumulator.java_131",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/producer/internals/RecordAccumulator.java",
  "content": "        this.appendsInProgress = new AtomicInteger(0);\n        this.batchSize = batchSize;\n        this.compression = compression;\n        this.lingerMs = lingerMs;\n        this.retryBackoff = new ExponentialBackoff(retryBackoffMs,\n                CommonClientConfigs.RETRY_BACKOFF_EXP_BASE,\n                retryBackoffMaxMs,\n                CommonClientConfigs.RETRY_BACKOFF_JITTER);\n        this.deliveryTimeoutMs = deliveryTimeoutMs;\n        this.enableAdaptivePartitioning = partitionerConfig.enableAdaptivePartitioning;\n        this.partitionAvailabilityTimeoutMs = partitionerConfig.partitionAvailabilityTimeoutMs;\n        this.free = bufferPool;\n        this.incomplete = new IncompleteBatches();\n        this.muted = new HashSet<>();\n        this.time = time;\n        nodesDrainIndex = new HashMap<>();\n        this.transactionManager = transactionManager;\n        registerMetrics(metrics, metricGrpName);\n    }\n\n    /**\n     * Create a new record accumulator with default partitioner config\n     *\n     * @param logContext The log context used for logging\n     * @param batchSize The size to use when allocating {@link MemoryRecords} instances\n     * @param compression The compression codec for the records\n     * @param lingerMs An artificial delay time to add before declaring a records instance that isn't full ready for\n     *        sending. This allows time for more records to arrive. Setting a non-zero lingerMs will trade off some\n     *        latency for potentially better throughput due to more batching (and hence fewer, larger requests).\n     * @param retryBackoffMs An artificial delay time to retry the produce request upon receiving an error. This avoids\n     *        exhausting all retries in a short period of time.\n     * @param retryBackoffMaxMs The upper bound of the retry backoff time.\n     * @param deliveryTimeoutMs An upper bound on the time to report success or failure on record delivery\n     * @param metrics The metrics\n     * @param metricGrpName The metric group name\n     * @param time The time instance to use\n     * @param transactionManager The shared transaction state object which tracks producer IDs, epochs, and sequence\n     *                           numbers per partition.\n     * @param bufferPool The buffer pool\n     */\n    public RecordAccumulator(LogContext logContext,\n                             int batchSize,\n                             Compression compression,\n                             int lingerMs,\n                             long retryBackoffMs,\n                             long retryBackoffMaxMs,\n                             int deliveryTimeoutMs,\n                             Metrics metrics,\n                             String metricGrpName,\n                             Time time,\n                             TransactionManager transactionManager,\n                             BufferPool bufferPool) {\n        this(logContext,\n            batchSize,\n            compression,\n            lingerMs,\n            retryBackoffMs,\n            retryBackoffMaxMs,\n            deliveryTimeoutMs,\n            new PartitionerConfig(),\n            metrics,\n            metricGrpName,\n            time,\n            transactionManager,\n            bufferPool);\n    }\n\n    private void registerMetrics(Metrics metrics, String metricGrpName) {\n        metrics.addMetric(\n            metrics.metricName(\"waiting-threads\", metricGrpName,\n                \"The number of user threads blocked waiting for buffer memory to enqueue their records\"),\n            (config, now) -> free.queued());\n\n        metrics.addMetric(\n            metrics.metricName(\"buffer-total-bytes\", metricGrpName,\n                \"The maximum amount of buffer memory the client can use (whether or not it is currently used).\"),\n            (config, now) -> free.totalMemory());\n\n        metrics.addMetric(\n            metrics.metricName(\"buffer-available-bytes\", metricGrpName,\n                \"The total amount of buffer memory that is not being used (either unallocated or in the free list).\"),\n            (config, now) -> free.availableMemory());\n    }\n\n    private void setPartition(AppendCallbacks callbacks, int partition) {\n        if (callbacks != null)\n            callbacks.setPartition(partition);\n    }\n\n    /**\n     * Check if partition concurrently changed, or we need to complete previously disabled partition change.\n     *\n     * @param topic The topic\n     * @param topicInfo The topic info\n     * @param partitionInfo The built-in partitioner's partition info\n     * @param deque The partition queue\n     * @param nowMs The current time, in milliseconds\n     * @param cluster THe cluster metadata\n     * @return 'true' if partition changed and we need to get new partition info and retry,\n     *         'false' otherwise\n     */\n    private boolean partitionChanged(String topic,\n                                     TopicInfo topicInfo,\n                                     BuiltInPartitioner.StickyPartitionInfo partitionInfo,\n                                     Deque<ProducerBatch> deque, long nowMs,\n                                     Cluster cluster) {\n        if (topicInfo.builtInPartitioner.isPartitionChanged(partitionInfo)) {\n            log.trace(\"Partition {} for topic {} switched by a concurrent append, retrying\",\n                    partitionInfo.partition(), topic);\n            return true;\n        }\n\n        // We might have disabled partition switch if the queue had incomplete batches.\n        // Check if all batches are full now and switch .\n        if (allBatchesFull(deque)) {\n            topicInfo.builtInPartitioner.updatePartitionInfo(partitionInfo, 0, cluster, true);\n            if (topicInfo.builtInPartitioner.isPartitionChanged(partitionInfo)) {\n                log.trace(\"Completed previously disabled switch for topic {} partition {}, retrying\",\n                        topic, partitionInfo.partition());\n                return true;\n            }\n        }\n\n        return false;\n    }\n\n    /**\n     * Add a record to the accumulator, return the append result\n     * <p>\n     * The append result will contain the future metadata, and flag for whether the appended batch is full or a new batch is created\n     * <p>\n     *\n     * @param topic The topic to which this record is being sent\n     * @param partition The partition to which this record is being sent or RecordMetadata.UNKNOWN_PARTITION\n     *                  if any partition could be used\n     * @param timestamp The timestamp of the record\n     * @param key The key for the record\n     * @param value The value for the record\n     * @param headers the Headers for the record\n     * @param callbacks The callbacks to execute\n     * @param maxTimeToBlock The maximum time in milliseconds to block for buffer memory to be available\n     * @param nowMs The current time, in milliseconds\n     * @param cluster The cluster metadata\n     */\n    public RecordAppendResult append(String topic,\n                                     int partition,\n                                     long timestamp,\n                                     byte[] key,\n                                     byte[] value,\n                                     Header[] headers,",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/RecordAccumulator.java#L131-L280",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/RecordAccumulator.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 131,
  "end_line": 280,
  "last_modified": "2026-02-06T01:16:27.610051",
  "source_type": "github"
}