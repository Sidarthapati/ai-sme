{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_producer_internals_Sender.java_651",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java",
  "content": "\n                this.sensors.recordLatency(response.destination(), response.requestLatencyMs());\n            } else {\n                // this is the acks = 0 case, just complete all requests\n                for (ProducerBatch batch : batches.values()) {\n                    completeBatch(batch, new ProduceResponse.PartitionResponse(Errors.NONE), correlationId, now, null);\n                }\n            }\n        }\n    }\n\n    /**\n     * Complete or retry the given batch of records.\n     *\n     * @param batch The record batch\n     * @param response The produce response\n     * @param correlationId The correlation id for the request\n     * @param now The current POSIX timestamp in milliseconds\n     * @param partitionsWithUpdatedLeaderInfo This will be populated with partitions that have updated leader info.\n     */\n    private void completeBatch(ProducerBatch batch, ProduceResponse.PartitionResponse response, long correlationId,\n                               long now, Map<TopicPartition, Metadata.LeaderIdAndEpoch> partitionsWithUpdatedLeaderInfo) {\n        batch.setInflight(false);\n        Errors error = response.error;\n\n        if (error == Errors.MESSAGE_TOO_LARGE && batch.recordCount > 1 && !batch.isDone() &&\n                (batch.magic() >= RecordBatch.MAGIC_VALUE_V2 || batch.isCompressed())) {\n            // If the batch is too large, we split the batch and send the split batches again. We do not decrement\n            // the retry attempts in this case.\n            log.warn(\n                \"Got error produce response in correlation id {} on topic-partition {}, splitting and retrying ({} attempts left). Error: {}\",\n                correlationId,\n                batch.topicPartition,\n                this.retries - batch.attempts(),\n                formatErrMsg(response));\n            if (transactionManager != null)\n                transactionManager.removeInFlightBatch(batch);\n            this.accumulator.splitAndReenqueue(batch);\n            maybeRemoveAndDeallocateBatch(batch);\n            this.sensors.recordBatchSplit();\n        } else if (error != Errors.NONE) {\n            if (canRetry(batch, response, now)) {\n                log.warn(\n                    \"Got error produce response with correlation id {} on topic-partition {}, retrying ({} attempts left). Error: {}\",\n                    correlationId,\n                    batch.topicPartition,\n                    this.retries - batch.attempts() - 1,\n                    formatErrMsg(response));\n                reenqueueBatch(batch, now);\n            } else if (error == Errors.DUPLICATE_SEQUENCE_NUMBER) {\n                // If we have received a duplicate sequence error, it means that the sequence number has advanced beyond\n                // the sequence of the current batch, and we haven't retained batch metadata on the broker to return\n                // the correct offset and timestamp.\n                //\n                // The only thing we can do is to return success to the user and not return a valid offset and timestamp.\n                completeBatch(batch, response);\n            } else {\n                // tell the user the result of their request. We only adjust sequence numbers if the batch didn't exhaust\n                // its retries -- if it did, we don't know whether the sequence number was accepted or not, and\n                // thus it is not safe to reassign the sequence.\n                failBatch(batch, response, batch.attempts() < this.retries, true);\n            }\n            if (error.exception() instanceof InvalidMetadataException) {\n                if (error.exception() instanceof UnknownTopicOrPartitionException) {\n                    log.warn(\"Received unknown topic or partition error in produce request on partition {}. The \" +\n                            \"topic-partition may not exist or the user may not have Describe access to it\",\n                        batch.topicPartition);\n                } else {\n                    log.warn(\"Received invalid metadata error in produce request on partition {} due to {} Going \" +\n                            \"to request metadata update now\", batch.topicPartition, error.exception(response.errorMessage).toString());\n                }\n                if (error.exception() instanceof NotLeaderOrFollowerException || error.exception() instanceof FencedLeaderEpochException) {\n                    log.debug(\"For {}, received error {}, with leaderIdAndEpoch {}\", batch.topicPartition, error, response.currentLeader);\n                    if (partitionsWithUpdatedLeaderInfo != null\n                        && (response.currentLeader.leaderId() != -1 && response.currentLeader.leaderEpoch() != -1)) {\n                        partitionsWithUpdatedLeaderInfo.put(batch.topicPartition, new Metadata.LeaderIdAndEpoch(\n                            Optional.of(response.currentLeader.leaderId()), Optional.of(response.currentLeader.leaderEpoch())));\n                    }\n                }\n                metadata.requestUpdate(false);\n            }\n        } else {\n            completeBatch(batch, response);\n        }\n\n        // Unmute the completed partition.\n        if (guaranteeMessageOrder)\n            this.accumulator.unmutePartition(batch.topicPartition);\n    }\n\n    /**\n     * Format the error from a {@link ProduceResponse.PartitionResponse} in a user-friendly string\n     * e.g \"NETWORK_EXCEPTION. Error Message: Disconnected from node 0\"\n     */\n    private String formatErrMsg(ProduceResponse.PartitionResponse response) {\n        String errorMessageSuffix = (response.errorMessage == null || response.errorMessage.isEmpty()) ?\n                \"\" : String.format(\". Error Message: %s\", response.errorMessage);\n        return String.format(\"%s%s\", response.error, errorMessageSuffix);\n    }\n\n    private void reenqueueBatch(ProducerBatch batch, long currentTimeMs) {\n        this.accumulator.reenqueue(batch, currentTimeMs);\n        maybeRemoveFromInflightBatches(batch);\n        this.sensors.recordRetries(batch.topicPartition.topic(), batch.recordCount);\n    }\n\n    private void completeBatch(ProducerBatch batch, ProduceResponse.PartitionResponse response) {\n        if (transactionManager != null) {\n            transactionManager.handleCompletedBatch(batch, response);\n        }\n\n        if (batch.complete(response.baseOffset, response.logAppendTime)) {\n            maybeRemoveAndDeallocateBatch(batch);\n        } else {\n            // Always safe to call deallocate because the batch keeps track of whether or not it was deallocated yet\n            this.accumulator.deallocate(batch);\n        }\n    }\n\n    private void failBatch(ProducerBatch batch,\n                           ProduceResponse.PartitionResponse response,\n                           boolean adjustSequenceNumbers,\n                           boolean deallocateBatch) {\n        final RuntimeException topLevelException;\n        if (response.error == Errors.TOPIC_AUTHORIZATION_FAILED)\n            topLevelException = new TopicAuthorizationException(Collections.singleton(batch.topicPartition.topic()));\n        else if (response.error == Errors.CLUSTER_AUTHORIZATION_FAILED)\n            topLevelException = new ClusterAuthorizationException(\"The producer is not authorized to do idempotent sends\");\n        else\n            topLevelException = response.error.exception(response.errorMessage);\n\n        if (response.recordErrors == null || response.recordErrors.isEmpty()) {\n            failBatch(batch, topLevelException, adjustSequenceNumbers, deallocateBatch);\n        } else {\n            Map<Integer, RuntimeException> recordErrorMap = new HashMap<>(response.recordErrors.size());\n            for (ProduceResponse.RecordError recordError : response.recordErrors) {\n                // The API leaves us with some awkwardness interpreting the errors in the response.\n                // We cannot differentiate between different error cases (such as INVALID_TIMESTAMP)\n                // from the single error code at the partition level, so instead we use INVALID_RECORD\n                // for all failed records and rely on the message to distinguish the cases.\n                final String errorMessage;\n                if (recordError.message != null) {\n                    errorMessage = recordError.message;\n                } else if (response.errorMessage != null) {\n                    errorMessage = response.errorMessage;\n                } else {\n                    errorMessage = response.error.message();\n                }\n\n                // If the batch contained only a single record error, then we can unambiguously",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java#L651-L800",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 651,
  "end_line": 800,
  "last_modified": "2026-02-06T01:16:27.610196",
  "source_type": "github"
}