{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_Metadata.java_1",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/Metadata.java",
  "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements. See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License. You may obtain a copy of the License at\n *\n *    http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.kafka.clients;\n\nimport org.apache.kafka.common.Cluster;\nimport org.apache.kafka.common.ClusterResourceListener;\nimport org.apache.kafka.common.KafkaException;\nimport org.apache.kafka.common.Node;\nimport org.apache.kafka.common.TopicPartition;\nimport org.apache.kafka.common.Uuid;\nimport org.apache.kafka.common.errors.InvalidMetadataException;\nimport org.apache.kafka.common.errors.InvalidTopicException;\nimport org.apache.kafka.common.errors.TopicAuthorizationException;\nimport org.apache.kafka.common.internals.ClusterResourceListeners;\nimport org.apache.kafka.common.protocol.Errors;\nimport org.apache.kafka.common.requests.MetadataRequest;\nimport org.apache.kafka.common.requests.MetadataResponse;\nimport org.apache.kafka.common.requests.MetadataResponse.PartitionMetadata;\nimport org.apache.kafka.common.utils.ExponentialBackoff;\nimport org.apache.kafka.common.utils.LogContext;\n\nimport org.slf4j.Logger;\n\nimport java.io.Closeable;\nimport java.net.InetSocketAddress;\nimport java.util.ArrayList;\nimport java.util.Collections;\nimport java.util.HashMap;\nimport java.util.HashSet;\nimport java.util.List;\nimport java.util.Map;\nimport java.util.Map.Entry;\nimport java.util.Objects;\nimport java.util.Optional;\nimport java.util.Set;\nimport java.util.function.Supplier;\nimport java.util.stream.Collectors;\n\nimport static org.apache.kafka.common.record.RecordBatch.NO_PARTITION_LEADER_EPOCH;\n\n/**\n * A class encapsulating some of the logic around metadata.\n * <p>\n * This class is shared by the client thread (for partitioning) and the background sender thread.\n *\n * Metadata is maintained for only a subset of topics, which can be added to over time. When we request metadata for a\n * topic we don't have any metadata for it will trigger a metadata update.\n * <p>\n * If topic expiry is enabled for the metadata, any topic that has not been used within the expiry interval\n * is removed from the metadata refresh set after an update. Consumers disable topic expiry since they explicitly\n * manage topics while producers rely on topic expiry to limit the refresh set.\n */\npublic class Metadata implements Closeable {\n    private final Logger log;\n    private final ExponentialBackoff refreshBackoff;\n    private final long metadataExpireMs;\n    private int updateVersion;  // bumped on every metadata response\n    private int requestVersion; // bumped on every new topic addition\n    private long lastRefreshMs;\n    private long lastSuccessfulRefreshMs;\n    private long attempts;\n    private KafkaException fatalException;\n    private Set<String> invalidTopics;\n    private Set<String> unauthorizedTopics;\n    private volatile MetadataSnapshot metadataSnapshot = MetadataSnapshot.empty();\n    private boolean needFullUpdate;\n    private boolean needPartialUpdate;\n    private long equivalentResponseCount;\n    private final ClusterResourceListeners clusterResourceListeners;\n    private boolean isClosed;\n    private final Map<TopicPartition, Integer> lastSeenLeaderEpochs;\n    /** Addresses with which the metadata was originally bootstrapped. */\n    private List<InetSocketAddress> bootstrapAddresses;\n\n    /**\n     * Create a new Metadata instance\n     *\n     * @param refreshBackoffMs         The minimum amount of time that must expire between metadata refreshes to avoid busy\n     *                                 polling\n     * @param refreshBackoffMaxMs      The maximum amount of time to wait between metadata refreshes\n     * @param metadataExpireMs         The maximum amount of time that metadata can be retained without refresh\n     * @param logContext               Log context corresponding to the containing client\n     * @param clusterResourceListeners List of ClusterResourceListeners which will receive metadata updates.\n     */\n    public Metadata(long refreshBackoffMs,\n                    long refreshBackoffMaxMs,\n                    long metadataExpireMs,\n                    LogContext logContext,\n                    ClusterResourceListeners clusterResourceListeners) {\n        this.log = logContext.logger(Metadata.class);\n        this.refreshBackoff = new ExponentialBackoff(\n            refreshBackoffMs,\n            CommonClientConfigs.RETRY_BACKOFF_EXP_BASE,\n            refreshBackoffMaxMs,\n            CommonClientConfigs.RETRY_BACKOFF_JITTER);\n        this.metadataExpireMs = metadataExpireMs;\n        this.lastRefreshMs = 0L;\n        this.lastSuccessfulRefreshMs = 0L;\n        this.attempts = 0L;\n        this.requestVersion = 0;\n        this.updateVersion = 0;\n        this.needFullUpdate = false;\n        this.needPartialUpdate = false;\n        this.equivalentResponseCount = 0;\n        this.clusterResourceListeners = clusterResourceListeners;\n        this.isClosed = false;\n        this.lastSeenLeaderEpochs = new HashMap<>();\n        this.invalidTopics = Collections.emptySet();\n        this.unauthorizedTopics = Collections.emptySet();\n    }\n\n    /**\n     * Get the current cluster info without blocking\n     */\n    public Cluster fetch() {\n        return metadataSnapshot.cluster();\n    }\n\n    /**\n     * Get the current metadata cache.\n     */\n    public MetadataSnapshot fetchMetadataSnapshot() {\n        return metadataSnapshot;\n    }\n\n    /**\n     * Return the next time when the current cluster info can be updated (i.e., backoff time has elapsed).\n     * There are two calculations for backing off based on how many attempts to retrieve metadata have been made\n     * since the last successful response, and how many equivalent metadata responses have been received.\n     * The second of these allows backing off when there are errors to do with stale metadata, even though the\n     * metadata responses are clean.\n     * <p>\n     * This can be used to check whether it's worth requesting an update in the knowledge that it will\n     * not be delayed if this method returns 0.\n     *\n     * @param nowMs current time in ms",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/Metadata.java#L1-L150",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/Metadata.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 1,
  "end_line": 150,
  "last_modified": "2026-02-06T01:16:27.578514",
  "source_type": "github"
}