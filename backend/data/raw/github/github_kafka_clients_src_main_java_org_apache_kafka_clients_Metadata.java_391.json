{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_Metadata.java_391",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/Metadata.java",
  "content": "        for (Entry<TopicPartition, Metadata.LeaderIdAndEpoch> partitionLeader: partitionLeaders.entrySet()) {\n            TopicPartition partition = partitionLeader.getKey();\n            Metadata.LeaderAndEpoch currentLeader = currentLeader(partition);\n            Metadata.LeaderIdAndEpoch newLeader = partitionLeader.getValue();\n            if (newLeader.epoch.isEmpty() || newLeader.leaderId.isEmpty()) {\n                log.debug(\"For {}, incoming leader information is incomplete {}\", partition, newLeader);\n                continue;\n            }\n            if (currentLeader.epoch.isPresent() && newLeader.epoch.get() <= currentLeader.epoch.get()) {\n                log.debug(\"For {}, incoming leader({}) is not-newer than the one in the existing metadata {}, so ignoring.\", partition, newLeader, currentLeader);\n                continue;\n            }\n            if (!newNodes.containsKey(newLeader.leaderId.get())) {\n                log.debug(\"For {}, incoming leader({}), the corresponding node information for node-id {} is missing, so ignoring.\", partition, newLeader, newLeader.leaderId.get());\n                continue;\n            }\n            if (this.metadataSnapshot.partitionMetadata(partition).isEmpty()) {\n                log.debug(\"For {}, incoming leader({}), partition metadata is no longer cached, ignoring.\", partition, newLeader);\n                continue;\n            }\n\n            MetadataResponse.PartitionMetadata existingMetadata = this.metadataSnapshot.partitionMetadata(partition).get();\n            MetadataResponse.PartitionMetadata updatedMetadata = new MetadataResponse.PartitionMetadata(\n                existingMetadata.error,\n                partition,\n                newLeader.leaderId,\n                newLeader.epoch,\n                existingMetadata.replicaIds,\n                existingMetadata.inSyncReplicaIds,\n                existingMetadata.offlineReplicaIds\n            );\n            updatePartitionMetadata.add(updatedMetadata);\n\n            lastSeenLeaderEpochs.put(partition, newLeader.epoch.get());\n        }\n\n        if (updatePartitionMetadata.isEmpty()) {\n            log.debug(\"No relevant metadata updates.\");\n            return new HashSet<>();\n        }\n\n        Set<String> updatedTopics = updatePartitionMetadata.stream().map(MetadataResponse.PartitionMetadata::topic).collect(Collectors.toSet());\n\n        // Get topic-ids for updated topics from existing topic-ids.\n        Map<String, Uuid> existingTopicIds = this.metadataSnapshot.topicIds();\n        Map<String, Uuid> topicIdsForUpdatedTopics = updatedTopics.stream()\n            .filter(existingTopicIds::containsKey)\n            .collect(Collectors.toMap(e -> e, existingTopicIds::get));\n\n        if (log.isDebugEnabled()) {\n            updatePartitionMetadata.forEach(\n                partMetadata -> log.debug(\"For {} updating leader information, updated metadata is {}.\", partMetadata.topicPartition, partMetadata)\n            );\n        }\n\n        // Fetch responses can include partition level leader changes, when this happens, we perform a partial\n        // metadata update, by keeping the unchanged partition and update the changed partitions.\n        this.metadataSnapshot = metadataSnapshot.mergeWith(\n            metadataSnapshot.clusterResource().clusterId(),\n            newNodes,\n            updatePartitionMetadata,\n            Collections.emptySet(), Collections.emptySet(), Collections.emptySet(),\n            metadataSnapshot.cluster().controller(),\n            topicIdsForUpdatedTopics,\n            (topic, isInternal) -> true);\n        clusterResourceListeners.onUpdate(metadataSnapshot.clusterResource());\n\n        return updatePartitionMetadata.stream()\n            .map(metadata -> metadata.topicPartition)\n            .collect(Collectors.toSet());\n    }\n\n    private void maybeSetMetadataError(Cluster cluster) {\n        clearRecoverableErrors();\n        checkInvalidTopics(cluster);\n        checkUnauthorizedTopics(cluster);\n    }\n\n    private void checkInvalidTopics(Cluster cluster) {\n        if (!cluster.invalidTopics().isEmpty()) {\n            log.error(\"Metadata response reported invalid topics {}\", cluster.invalidTopics());\n            invalidTopics = new HashSet<>(cluster.invalidTopics());\n        }\n    }\n\n    private void checkUnauthorizedTopics(Cluster cluster) {\n        if (!cluster.unauthorizedTopics().isEmpty()) {\n            log.error(\"Topic authorization failed for topics {}\", cluster.unauthorizedTopics());\n            unauthorizedTopics = new HashSet<>(cluster.unauthorizedTopics());\n        }\n    }\n\n    /**\n     * Transform a MetadataResponse into a new MetadataCache instance.\n     */\n    private MetadataSnapshot handleMetadataResponse(MetadataResponse metadataResponse, boolean isPartialUpdate, long nowMs) {\n        // All encountered topics.\n        Set<String> topics = new HashSet<>();\n\n        // Retained topics to be passed to the metadata cache.\n        Set<String> internalTopics = new HashSet<>();\n        Set<String> unauthorizedTopics = new HashSet<>();\n        Set<String> invalidTopics = new HashSet<>();\n\n        List<MetadataResponse.PartitionMetadata> partitions = new ArrayList<>();\n        Map<String, Uuid> topicIds = new HashMap<>();\n        Map<String, Uuid> oldTopicIds = metadataSnapshot.topicIds();\n        for (MetadataResponse.TopicMetadata metadata : metadataResponse.topicMetadata()) {\n            String topicName = metadata.topic();\n            Uuid topicId = metadata.topicId();\n            topics.add(topicName);\n            // We can only reason about topic ID changes when both IDs are valid, so keep oldId null unless the new metadata contains a topic ID\n            Uuid oldTopicId = null;\n            if (!Uuid.ZERO_UUID.equals(topicId)) {\n                topicIds.put(topicName, topicId);\n                oldTopicId = oldTopicIds.get(topicName);\n            } else {\n                topicId = null;\n            }\n\n            if (!retainTopic(topicName, topicId, metadata.isInternal(), nowMs))\n                continue;\n\n            if (metadata.isInternal())\n                internalTopics.add(topicName);\n\n            if (metadata.error() == Errors.NONE) {\n                for (MetadataResponse.PartitionMetadata partitionMetadata : metadata.partitionMetadata()) {\n                    // Even if the partition's metadata includes an error, we need to handle\n                    // the update to catch new epochs\n                    updateLatestMetadata(partitionMetadata, metadataResponse.hasReliableLeaderEpochs(), topicId, oldTopicId)\n                        .ifPresent(partitions::add);\n\n                    if (partitionMetadata.error.exception() instanceof InvalidMetadataException) {\n                        log.debug(\"Requesting metadata update for partition {} due to error {}\",\n                                partitionMetadata.topicPartition, partitionMetadata.error);\n                        requestUpdate(false);\n                    }\n                }\n            } else {\n                if (metadata.error().exception() instanceof InvalidMetadataException) {\n                    log.debug(\"Requesting metadata update for topic {} due to error {}\", topicName, metadata.error());\n                    requestUpdate(false);\n                }\n\n                if (metadata.error() == Errors.INVALID_TOPIC_EXCEPTION)\n                    invalidTopics.add(topicName);\n                else if (metadata.error() == Errors.TOPIC_AUTHORIZATION_FAILED)\n                    unauthorizedTopics.add(topicName);\n            }",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/Metadata.java#L391-L540",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/Metadata.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 391,
  "end_line": 540,
  "last_modified": "2026-02-06T01:16:27.578514",
  "source_type": "github"
}