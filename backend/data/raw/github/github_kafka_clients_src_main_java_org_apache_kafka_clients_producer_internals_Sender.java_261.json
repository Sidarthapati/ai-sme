{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_producer_internals_Sender.java_261",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java",
  "content": "            } catch (Exception e) {\n                log.error(\"Uncaught error in kafka producer I/O thread: \", e);\n            }\n        }\n\n        // Abort the transaction if any commit or abort didn't go through the transaction manager's queue\n        while (!forceClose && transactionManager != null && transactionManager.hasOngoingTransaction()) {\n            if (!transactionManager.isCompleting()) {\n                log.info(\"Aborting incomplete transaction due to shutdown\");\n                try {\n                    // It is possible for the transaction manager to throw errors when aborting. Catch these\n                    // so as not to interfere with the rest of the shutdown logic.\n                    transactionManager.beginAbort();\n                } catch (Exception e) {\n                    log.error(\"Error in kafka producer I/O thread while aborting transaction when during closing: \", e);\n                    // Force close in case the transactionManager is in error states.\n                    forceClose = true;\n                }\n            }\n            try {\n                runOnce();\n            } catch (Exception e) {\n                log.error(\"Uncaught error in kafka producer I/O thread: \", e);\n            }\n        }\n\n        if (forceClose) {\n            // We need to fail all the incomplete transactional requests and batches and wake up the threads waiting on\n            // the futures.\n            if (transactionManager != null) {\n                log.debug(\"Aborting incomplete transactional requests due to forced shutdown\");\n                transactionManager.close();\n            }\n            log.debug(\"Aborting incomplete batches due to forced shutdown\");\n            this.accumulator.abortIncompleteBatches();\n        }\n        try {\n            this.client.close();\n        } catch (Exception e) {\n            log.error(\"Failed to close network client\", e);\n        }\n\n        log.debug(\"Shutdown of Kafka producer I/O thread has completed.\");\n    }\n\n    /**\n     * Run a single iteration of sending\n     *\n     */\n    void runOnce() {\n        if (transactionManager != null) {\n            try {\n                transactionManager.maybeResolveSequences();\n\n                RuntimeException lastError = transactionManager.lastError();\n\n                // do not continue sending if the transaction manager is in a failed state\n                if (transactionManager.hasFatalError()) {\n                    if (lastError != null)\n                        maybeAbortBatches(lastError);\n                    client.poll(retryBackoffMs, time.milliseconds());\n                    return;\n                }\n\n                if (transactionManager.hasAbortableError() && shouldHandleAuthorizationError(lastError)) {\n                    return;\n                }\n\n                // Check whether we need a new producerId. If so, we will enqueue an InitProducerId\n                // request which will be sent below\n                transactionManager.bumpIdempotentEpochAndResetIdIfNeeded();\n\n                if (maybeSendAndPollTransactionalRequest()) {\n                    return;\n                }\n            } catch (AuthenticationException e) {\n                // This is already logged as error, but propagated here to perform any clean ups.\n                log.trace(\"Authentication exception while processing transactional request\", e);\n                transactionManager.authenticationFailed(e);\n            }\n        }\n\n        long currentTimeMs = time.milliseconds();\n        long pollTimeout = sendProducerData(currentTimeMs);\n        client.poll(pollTimeout, currentTimeMs);\n    }\n\n    // We handle {@code TransactionalIdAuthorizationException} and {@code ClusterAuthorizationException} by first\n    // failing the inflight requests, then transition the state to UNINITIALIZED so that the user doesn't need to\n    // instantiate the producer again.\n    private boolean shouldHandleAuthorizationError(RuntimeException exception) {\n        if (exception instanceof TransactionalIdAuthorizationException ||\n                        exception instanceof ClusterAuthorizationException) {\n            transactionManager.failPendingRequests(new AuthenticationException(exception));\n            maybeAbortBatches(exception);\n            transactionManager.transitionToUninitialized(exception);\n            return true;\n        }\n        return false;\n    }\n\n    private void failExpiredBatches(List<ProducerBatch> expiredBatches, long now, boolean deallocateBuffer) {\n        // Reset the producer id if an expired batch has previously been sent to the broker. Also update the metrics\n        // for expired batches. see the documentation of @TransactionState.resetIdempotentProducerId to understand why\n        // we need to reset the producer id here.\n        if (!expiredBatches.isEmpty())\n            log.trace(\"Expired {} batches in accumulator\", expiredBatches.size());\n        for (ProducerBatch expiredBatch : expiredBatches) {\n            String errorMessage = \"Expiring \" + expiredBatch.recordCount + \" record(s) for \" + expiredBatch.topicPartition\n                + \":\" + (now - expiredBatch.createdMs) + \" ms has passed since batch creation. \"\n                + \"The request has not been sent, or no server response has been received yet.\";\n            failBatch(expiredBatch, new TimeoutException(errorMessage), false, deallocateBuffer);\n            if (transactionManager != null && expiredBatch.inRetry()) {\n                // This ensures that no new batches are drained until the current in flight batches are fully resolved.\n                transactionManager.markSequenceUnresolved(expiredBatch);\n            }\n        }\n    }\n\n    private long sendProducerData(long now) {\n        MetadataSnapshot metadataSnapshot = metadata.fetchMetadataSnapshot();\n        // get the list of partitions with data ready to send\n        RecordAccumulator.ReadyCheckResult result = this.accumulator.ready(metadataSnapshot, now);\n\n        // if there are any partitions whose leaders are not known yet, force metadata update\n        if (!result.unknownLeaderTopics.isEmpty()) {\n            // The set of topics with unknown leader contains topics with leader election pending as well as\n            // topics which may have expired. Add the topic again to metadata to ensure it is included\n            // and request metadata update, since there are messages to send to the topic.\n            for (String topic : result.unknownLeaderTopics)\n                this.metadata.add(topic, now);\n\n            log.debug(\"Requesting metadata update due to unknown leader topics from the batched records: {}\",\n                result.unknownLeaderTopics);\n            this.metadata.requestUpdate(false);\n        }\n\n        // remove any nodes we aren't ready to send to\n        Iterator<Node> iter = result.readyNodes.iterator();\n        long notReadyTimeout = Long.MAX_VALUE;\n        while (iter.hasNext()) {\n            Node node = iter.next();\n            if (!this.client.ready(node, now)) {\n                // Update just the readyTimeMs of the latency stats, so that it moves forward\n                // every time the batch is ready (then the difference between readyTimeMs and\n                // drainTimeMs would represent how long data is waiting for the node).\n                this.accumulator.updateNodeLatencyStats(node.id(), now, false);\n                iter.remove();\n                notReadyTimeout = Math.min(notReadyTimeout, this.client.pollDelayMs(node, now));\n            } else {",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java#L261-L410",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 261,
  "end_line": 410,
  "last_modified": "2026-02-06T01:16:27.610196",
  "source_type": "github"
}