{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_admin_KafkaAdminClient.java_4551",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java",
  "content": "                return new ApiVersionsRequest.Builder();\n            }\n\n            @Override\n            void handleResponse(AbstractResponse response) {\n                final ApiVersionsResponse apiVersionsResponse = (ApiVersionsResponse) response;\n                if (apiVersionsResponse.data().errorCode() == Errors.NONE.code()) {\n                    future.complete(createFeatureMetadata(apiVersionsResponse));\n                } else {\n                    future.completeExceptionally(Errors.forCode(apiVersionsResponse.data().errorCode()).exception());\n                }\n            }\n\n            @Override\n            void handleFailure(Throwable throwable) {\n                completeAllExceptionally(Collections.singletonList(future), throwable);\n            }\n        };\n\n        runnable.call(call, now);\n        return new DescribeFeaturesResult(future);\n    }\n\n    @Override\n    public UpdateFeaturesResult updateFeatures(final Map<String, FeatureUpdate> featureUpdates,\n                                               final UpdateFeaturesOptions options) {\n        if (featureUpdates.isEmpty()) {\n            throw new IllegalArgumentException(\"Feature updates can not be null or empty.\");\n        }\n\n        final Map<String, KafkaFutureImpl<Void>> updateFutures = new HashMap<>();\n        for (final Map.Entry<String, FeatureUpdate> entry : featureUpdates.entrySet()) {\n            final String feature = entry.getKey();\n            if (Utils.isBlank(feature)) {\n                throw new IllegalArgumentException(\"Provided feature can not be empty.\");\n            }\n            updateFutures.put(entry.getKey(), new KafkaFutureImpl<>());\n        }\n\n        final long now = time.milliseconds();\n        final Call call = new Call(\"updateFeatures\", calcDeadlineMs(now, options.timeoutMs()),\n            new ControllerNodeProvider(true)) {\n\n            @Override\n            UpdateFeaturesRequest.Builder createRequest(int timeoutMs) {\n                final UpdateFeaturesRequestData.FeatureUpdateKeyCollection featureUpdatesRequestData\n                    = new UpdateFeaturesRequestData.FeatureUpdateKeyCollection();\n                for (Map.Entry<String, FeatureUpdate> entry : featureUpdates.entrySet()) {\n                    final String feature = entry.getKey();\n                    final FeatureUpdate update = entry.getValue();\n                    final UpdateFeaturesRequestData.FeatureUpdateKey requestItem =\n                        new UpdateFeaturesRequestData.FeatureUpdateKey();\n                    requestItem.setFeature(feature);\n                    requestItem.setMaxVersionLevel(update.maxVersionLevel());\n                    requestItem.setUpgradeType(update.upgradeType().code());\n                    featureUpdatesRequestData.add(requestItem);\n                }\n                return new UpdateFeaturesRequest.Builder(\n                    new UpdateFeaturesRequestData()\n                        .setTimeoutMs(timeoutMs)\n                        .setValidateOnly(options.validateOnly())\n                        .setFeatureUpdates(featureUpdatesRequestData));\n            }\n\n            @Override\n            void handleResponse(AbstractResponse abstractResponse) {\n                final UpdateFeaturesResponse response =\n                    (UpdateFeaturesResponse) abstractResponse;\n\n                ApiError topLevelError = response.topLevelError();\n                switch (topLevelError.error()) {\n                    case NONE:\n                        // For V2 and above, None responses will just have a top level NONE error -- mark all the futures as completed.\n                        if (response.data().results().isEmpty()) {\n                            for (final KafkaFutureImpl<Void> future : updateFutures.values()) {\n                                future.complete(null);\n                            }\n                        } else {\n                            for (final UpdatableFeatureResult result : response.data().results()) {\n                                final KafkaFutureImpl<Void> future = updateFutures.get(result.feature());\n                                if (future == null) {\n                                    log.warn(\"Server response mentioned unknown feature {}\", result.feature());\n                                } else {\n                                    final Errors error = Errors.forCode(result.errorCode());\n                                    if (error == Errors.NONE) {\n                                        future.complete(null);\n                                    } else {\n                                        future.completeExceptionally(error.exception(result.errorMessage()));\n                                    }\n                                }\n                            }\n                            // The server should send back a response for every feature, but we do a sanity check anyway.\n                            completeUnrealizedFutures(updateFutures.entrySet().stream(),\n                                feature -> \"The controller response did not contain a result for feature \" + feature);\n                        }\n                        break;\n                    case NOT_CONTROLLER:\n                        handleNotControllerError(topLevelError.error());\n                        break;\n                    default:\n                        for (final Map.Entry<String, KafkaFutureImpl<Void>> entry : updateFutures.entrySet()) {\n                            entry.getValue().completeExceptionally(topLevelError.exception());\n                        }\n                        break;\n                }\n            }\n\n            @Override\n            void handleFailure(Throwable throwable) {\n                completeAllExceptionally(updateFutures.values(), throwable);\n            }\n        };\n\n        runnable.call(call, now);\n        return new UpdateFeaturesResult(new HashMap<>(updateFutures));\n    }\n\n    @Override\n    public DescribeMetadataQuorumResult describeMetadataQuorum(DescribeMetadataQuorumOptions options) {\n        NodeProvider provider = new LeastLoadedBrokerOrActiveKController();\n\n        final KafkaFutureImpl<QuorumInfo> future = new KafkaFutureImpl<>();\n        final long now = time.milliseconds();\n        final Call call = new Call(\n            \"describeMetadataQuorum\", calcDeadlineMs(now, options.timeoutMs()), provider) {\n\n            private QuorumInfo.ReplicaState translateReplicaState(DescribeQuorumResponseData.ReplicaState replica) {\n                return new QuorumInfo.ReplicaState(\n                    replica.replicaId(),\n                    replica.replicaDirectoryId() == null ? Uuid.ZERO_UUID : replica.replicaDirectoryId(),\n                    replica.logEndOffset(),\n                    replica.lastFetchTimestamp() == -1 ? OptionalLong.empty() : OptionalLong.of(replica.lastFetchTimestamp()),\n                    replica.lastCaughtUpTimestamp() == -1 ? OptionalLong.empty() : OptionalLong.of(replica.lastCaughtUpTimestamp()));\n            }\n\n            private QuorumInfo createQuorumResult(final DescribeQuorumResponseData.PartitionData partition, DescribeQuorumResponseData.NodeCollection nodeCollection) {\n                List<QuorumInfo.ReplicaState> voters = partition.currentVoters().stream()\n                    .map(this::translateReplicaState)\n                    .collect(Collectors.toList());\n\n                List<QuorumInfo.ReplicaState> observers = partition.observers().stream()\n                    .map(this::translateReplicaState)\n                    .collect(Collectors.toList());\n\n                Map<Integer, QuorumInfo.Node> nodes = nodeCollection.stream().map(n -> {\n                    List<RaftVoterEndpoint> endpoints = n.listeners().stream()\n                        .map(l -> new RaftVoterEndpoint(l.name(), l.host(), l.port()))\n                        .collect(Collectors.toList());\n\n                    return new QuorumInfo.Node(n.nodeId(), endpoints);",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java#L4551-L4700",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 4551,
  "end_line": 4700,
  "last_modified": "2026-02-06T01:16:27.585045",
  "source_type": "github"
}