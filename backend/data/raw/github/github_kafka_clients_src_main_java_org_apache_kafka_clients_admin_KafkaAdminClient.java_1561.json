{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_admin_KafkaAdminClient.java_1561",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java",
  "content": "            }\n            boolean accepted = false;\n            synchronized (this) {\n                if (!closing) {\n                    newCalls.add(call);\n                    accepted = true;\n                }\n            }\n            if (accepted) {\n                client.wakeup(); // wake the thread if it is in poll()\n            } else {\n                log.debug(\"The AdminClient thread has exited. Timing out {}.\", call);\n                call.handleTimeoutFailure(time.milliseconds(),\n                    new TimeoutException(\"The AdminClient thread has exited.\"));\n            }\n        }\n\n        /**\n         * Initiate a new call.\n         * <p>\n         * This will fail if the AdminClient is scheduled to shut down.\n         *\n         * @param call The new call object.\n         * @param now  The current time in milliseconds.\n         */\n        void call(Call call, long now) {\n            if (hardShutdownTimeMs.get() != INVALID_SHUTDOWN_TIME) {\n                log.debug(\"Cannot accept new call {} when AdminClient is closing.\", call);\n                call.handleFailure(new IllegalStateException(\"Cannot accept new calls when AdminClient is closing.\"));\n            } else if (metadataManager.usingBootstrapControllers() &&\n                (!call.nodeProvider.supportsUseControllers())) {\n                call.fail(now, new UnsupportedEndpointTypeException(\"This Admin API is not \" +\n                    \"yet supported when communicating directly with the controller quorum.\"));\n            } else {\n                enqueue(call, now);\n            }\n        }\n\n        /**\n         * Create a new metadata call.\n         */\n        private Call makeMetadataCall(long now) {\n            if (metadataManager.usingBootstrapControllers()) {\n                return makeControllerMetadataCall(now);\n            } else {\n                return makeBrokerMetadataCall(now);\n            }\n        }\n\n        private Call makeControllerMetadataCall(long now) {\n            // Use DescribeCluster here, as specified by KIP-919.\n            return new Call(true, \"describeCluster\", calcDeadlineMs(now, requestTimeoutMs),\n                new MetadataUpdateNodeIdProvider()) {\n                @Override\n                public DescribeClusterRequest.Builder createRequest(int timeoutMs) {\n                    return new DescribeClusterRequest.Builder(new DescribeClusterRequestData()\n                        .setIncludeClusterAuthorizedOperations(false)\n                        .setEndpointType(EndpointType.CONTROLLER.id()));\n                }\n\n                @Override\n                public void handleResponse(AbstractResponse abstractResponse) {\n                    DescribeClusterResponse response = (DescribeClusterResponse) abstractResponse;\n                    Cluster cluster;\n                    try {\n                        cluster = parseDescribeClusterResponse(response.data());\n                    } catch (ApiException e) {\n                        handleFailure(e);\n                        return;\n                    }\n                    long now = time.milliseconds();\n                    metadataManager.update(cluster, now);\n\n                    // Unassign all unsent requests after a metadata refresh to allow for a new\n                    // destination to be selected from the new metadata\n                    unassignUnsentCalls(node -> true);\n                }\n\n                @Override\n                boolean handleUnsupportedVersionException(final UnsupportedVersionException e) {\n                    metadataManager.updateFailed(e);\n                    return false;\n                }\n\n                @Override\n                public void handleFailure(Throwable e) {\n                    metadataManager.updateFailed(e);\n                }\n            };\n        }\n\n        private Call makeBrokerMetadataCall(long now) {\n            // We use MetadataRequest here so that we can continue to support brokers that are too\n            // old to handle DescribeCluster.\n            return new Call(true, \"fetchMetadata\", calcDeadlineMs(now, requestTimeoutMs),\n                new MetadataUpdateNodeIdProvider()) {\n                @Override\n                public MetadataRequest.Builder createRequest(int timeoutMs) {\n                    // Since this only requests node information, it's safe to pass true\n                    // for allowAutoTopicCreation (and it simplifies communication with\n                    // older brokers)\n                    return new MetadataRequest.Builder(new MetadataRequestData()\n                        .setTopics(Collections.emptyList())\n                        .setAllowAutoTopicCreation(true));\n                }\n\n                @Override\n                public void handleResponse(AbstractResponse abstractResponse) {\n                    MetadataResponse response = (MetadataResponse) abstractResponse;\n                    long now = time.milliseconds();\n\n                    if (response.topLevelError() == Errors.REBOOTSTRAP_REQUIRED)\n                        metadataManager.initiateRebootstrap();\n                    else\n                        metadataManager.update(response.buildCluster(), now);\n\n                    // Unassign all unsent requests after a metadata refresh to allow for a new\n                    // destination to be selected from the new metadata\n                    unassignUnsentCalls(node -> true);\n                }\n\n                @Override\n                boolean handleUnsupportedVersionException(final UnsupportedVersionException e) {\n                    metadataManager.updateFailed(e);\n                    return false;\n                }\n\n                @Override\n                public void handleFailure(Throwable e) {\n                    metadataManager.updateFailed(e);\n                }\n            };\n        }\n    }\n\n    static Cluster parseDescribeClusterResponse(DescribeClusterResponseData response) {\n        ApiError apiError = new ApiError(response.errorCode(), response.errorMessage());\n        if (apiError.isFailure()) {\n            throw apiError.exception();\n        }\n        if (response.endpointType() != EndpointType.CONTROLLER.id()) {\n            throw new MismatchedEndpointTypeException(\"Expected response from CONTROLLER \" +\n                \"endpoint, but got response from endpoint type \" + (int) response.endpointType());\n        }\n        List<Node> nodes = new ArrayList<>();\n        Node controllerNode = null;\n        for (DescribeClusterResponseData.DescribeClusterBroker node : response.brokers()) {\n            Node newNode = new Node(node.brokerId(), node.host(), node.port(), node.rack());\n            nodes.add(newNode);\n            if (node.brokerId() == response.controllerId()) {",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java#L1561-L1710",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 1561,
  "end_line": 1710,
  "last_modified": "2026-02-06T01:16:27.585045",
  "source_type": "github"
}