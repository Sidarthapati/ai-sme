{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_producer_internals_ProducerBatch.java_131",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/producer/internals/ProducerBatch.java",
  "content": "     */\n\n    boolean hasLeaderChangedForTheOngoingRetry() {\n        int attempts = attempts();\n        boolean isRetry = attempts >= 1;\n        if (!isRetry)\n            return false;\n        return attempts == attemptsWhenLeaderLastChanged;\n    }\n\n\n    /**\n     * Append the record to the current record set and return the relative offset within that record set\n     *\n     * @return The RecordSend corresponding to this record or null if there isn't sufficient room.\n     */\n    public FutureRecordMetadata tryAppend(long timestamp, byte[] key, byte[] value, Header[] headers, Callback callback, long now) {\n        if (!recordsBuilder.hasRoomFor(timestamp, key, value, headers)) {\n            return null;\n        } else {\n            this.recordsBuilder.append(timestamp, key, value, headers);\n            this.maxRecordSize = Math.max(this.maxRecordSize, AbstractRecords.estimateSizeInBytesUpperBound(magic(),\n                    recordsBuilder.compression().type(), key, value, headers));\n            this.lastAppendTime = now;\n            FutureRecordMetadata future = new FutureRecordMetadata(this.produceFuture, this.recordCount,\n                                                                   timestamp,\n                                                                   key == null ? -1 : key.length,\n                                                                   value == null ? -1 : value.length,\n                                                                   Time.SYSTEM);\n            // we have to keep every future returned to the users in case the batch needs to be\n            // split to several new batches and resent.\n            thunks.add(new Thunk(callback, future));\n            this.recordCount++;\n            return future;\n        }\n    }\n\n    /**\n     * This method is only used by {@link #split(int)} when splitting a large batch to smaller ones.\n     * @return true if the record has been successfully appended, false otherwise.\n     */\n    private boolean tryAppendForSplit(long timestamp, ByteBuffer key, ByteBuffer value, Header[] headers, Thunk thunk) {\n        if (!recordsBuilder.hasRoomFor(timestamp, key, value, headers)) {\n            return false;\n        } else {\n            // No need to get the CRC.\n            this.recordsBuilder.append(timestamp, key, value, headers);\n            this.maxRecordSize = Math.max(this.maxRecordSize, AbstractRecords.estimateSizeInBytesUpperBound(magic(),\n                    recordsBuilder.compression().type(), key, value, headers));\n            FutureRecordMetadata future = new FutureRecordMetadata(this.produceFuture, this.recordCount,\n                                                                   timestamp,\n                                                                   key == null ? -1 : key.remaining(),\n                                                                   value == null ? -1 : value.remaining(),\n                                                                   Time.SYSTEM);\n            // Chain the future to the original thunk.\n            thunk.future.chain(future);\n            this.thunks.add(thunk);\n            this.recordCount++;\n            return true;\n        }\n    }\n\n    /**\n     * Abort the batch and complete the future and callbacks.\n     *\n     * @param exception The exception to use to complete the future and awaiting callbacks.\n     */\n    public void abort(RuntimeException exception) {\n        if (!finalState.compareAndSet(null, FinalState.ABORTED))\n            throw new IllegalStateException(\"Batch has already been completed in final state \" + finalState.get());\n\n        log.trace(\"Aborting batch for partition {}\", topicPartition, exception);\n        completeFutureAndFireCallbacks(ProduceResponse.INVALID_OFFSET, RecordBatch.NO_TIMESTAMP, index -> exception);\n    }\n\n    /**\n     * Check if the batch has been completed (either successfully or exceptionally).\n     * @return `true` if the batch has been completed, `false` otherwise.\n     */\n    public boolean isDone() {\n        return finalState() != null;\n    }\n\n    /**\n     * Complete the batch successfully.\n     * @param baseOffset The base offset of the messages assigned by the server\n     * @param logAppendTime The log append time or -1 if CreateTime is being used\n     * @return true if the batch was completed as a result of this call, and false\n     *   if it had been completed previously\n     */\n    public boolean complete(long baseOffset, long logAppendTime) {\n        return done(baseOffset, logAppendTime, null, null);\n    }\n\n    /**\n     * Complete the batch exceptionally. The provided top-level exception will be used\n     * for each record future contained in the batch.\n     *\n     * @param topLevelException top-level partition error\n     * @param recordExceptions Record exception function mapping batchIndex to the respective record exception\n     * @return true if the batch was completed as a result of this call, and false\n     *   if it had been completed previously\n     */\n    public boolean completeExceptionally(\n        RuntimeException topLevelException,\n        Function<Integer, RuntimeException> recordExceptions\n    ) {\n        Objects.requireNonNull(topLevelException);\n        Objects.requireNonNull(recordExceptions);\n        return done(ProduceResponse.INVALID_OFFSET, RecordBatch.NO_TIMESTAMP, topLevelException, recordExceptions);\n    }\n\n    /**\n     * Finalize the state of a batch. Final state, once set, is immutable. This function may be called\n     * once or twice on a batch. It may be called twice if\n     * 1. An inflight batch expires before a response from the broker is received. The batch's final\n     * state is set to FAILED. But it could succeed on the broker and second time around batch.done() may\n     * try to set SUCCEEDED final state.\n     * 2. If a transaction abortion happens or if the producer is closed forcefully, the final state is\n     * ABORTED but again it could succeed if broker responds with a success.\n     *\n     * Attempted transitions from [FAILED | ABORTED] --> SUCCEEDED are logged.\n     * Attempted transitions from one failure state to the same or a different failed state are ignored.\n     * Attempted transitions from SUCCEEDED to the same or a failed state throw an exception.\n     *\n     * @param baseOffset The base offset of the messages assigned by the server\n     * @param logAppendTime The log append time or -1 if CreateTime is being used\n     * @param topLevelException The exception that occurred (or null if the request was successful)\n     * @param recordExceptions Record exception function mapping batchIndex to the respective record exception\n     * @return true if the batch was completed successfully and false if the batch was previously aborted\n     */\n    private boolean done(\n        long baseOffset,\n        long logAppendTime,\n        RuntimeException topLevelException,\n        Function<Integer, RuntimeException> recordExceptions\n    ) {\n        final FinalState tryFinalState = (topLevelException == null) ? FinalState.SUCCEEDED : FinalState.FAILED;\n        if (tryFinalState == FinalState.SUCCEEDED) {\n            log.trace(\"Successfully produced messages to {} with base offset {}.\", topicPartition, baseOffset);\n        } else {\n            log.trace(\"Failed to produce messages to {} with base offset {}.\", topicPartition, baseOffset, topLevelException);\n        }\n\n        if (this.finalState.compareAndSet(null, tryFinalState)) {\n            completeFutureAndFireCallbacks(baseOffset, logAppendTime, recordExceptions);\n            return true;\n        }\n\n        if (this.finalState.get() != FinalState.SUCCEEDED) {",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/ProducerBatch.java#L131-L280",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/ProducerBatch.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 131,
  "end_line": 280,
  "last_modified": "2026-02-06T01:16:27.609686",
  "source_type": "github"
}