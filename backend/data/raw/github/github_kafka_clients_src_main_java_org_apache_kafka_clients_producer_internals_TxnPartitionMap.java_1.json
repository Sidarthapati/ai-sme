{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_producer_internals_TxnPartitionMap.java_1",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/producer/internals/TxnPartitionMap.java",
  "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements. See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License. You may obtain a copy of the License at\n *\n *    http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\npackage org.apache.kafka.clients.producer.internals;\n\nimport org.apache.kafka.common.TopicPartition;\nimport org.apache.kafka.common.requests.ProduceResponse;\nimport org.apache.kafka.common.utils.LogContext;\nimport org.apache.kafka.common.utils.ProducerIdAndEpoch;\n\nimport org.slf4j.Logger;\n\nimport java.util.HashMap;\nimport java.util.Map;\nimport java.util.OptionalInt;\nimport java.util.OptionalLong;\n\nclass TxnPartitionMap {\n\n    private final Logger log;\n\n    private final Map<TopicPartition, TxnPartitionEntry> topicPartitions = new HashMap<>();\n\n    TxnPartitionMap(LogContext logContext) {\n        this.log = logContext.logger(TxnPartitionMap.class);\n    }\n\n    TxnPartitionEntry get(TopicPartition topicPartition) {\n        TxnPartitionEntry ent = topicPartitions.get(topicPartition);\n        if (ent == null) {\n            throw new IllegalStateException(\"Trying to get txnPartitionEntry for \" + topicPartition +\n                \", but it was never set for this partition.\");\n        }\n        return ent;\n    }\n\n    TxnPartitionEntry getOrCreate(TopicPartition topicPartition) {\n        return topicPartitions.computeIfAbsent(topicPartition, TxnPartitionEntry::new);\n    }\n\n    boolean contains(TopicPartition topicPartition) {\n        return topicPartitions.containsKey(topicPartition);\n    }\n\n    void reset() {\n        topicPartitions.clear();\n    }\n\n    OptionalLong lastAckedOffset(TopicPartition topicPartition) {\n        TxnPartitionEntry entry = topicPartitions.get(topicPartition);\n        if (entry != null)\n            return entry.lastAckedOffset();\n        return OptionalLong.empty();\n    }\n\n    OptionalInt lastAckedSequence(TopicPartition topicPartition) {\n        TxnPartitionEntry entry = topicPartitions.get(topicPartition);\n        if (entry != null)\n            return entry.lastAckedSequence();\n        return OptionalInt.empty();\n    }\n\n    void startSequencesAtBeginning(TopicPartition topicPartition, ProducerIdAndEpoch newProducerIdAndEpoch) {\n        TxnPartitionEntry entry = get(topicPartition);\n        if (entry != null)\n            entry.startSequencesAtBeginning(newProducerIdAndEpoch);\n    }\n\n    void remove(TopicPartition topicPartition) {\n        topicPartitions.remove(topicPartition);\n    }\n\n\n    void updateLastAckedOffset(TopicPartition topicPartition, boolean isTransactional, long lastOffset) {\n        OptionalLong lastAckedOffset = lastAckedOffset(topicPartition);\n        // It might happen that the TransactionManager has been reset while a request was reenqueued and got a valid\n        // response for this. This can happen only if the producer is only idempotent (not transactional) and in\n        // this case there will be no tracked bookkeeper entry about it, so we have to insert one.\n        if (lastAckedOffset.isEmpty() && !isTransactional)\n            getOrCreate(topicPartition);\n        if (lastOffset > lastAckedOffset.orElse(ProduceResponse.INVALID_OFFSET))\n            get(topicPartition).setLastAckedOffset(lastOffset);\n        else\n            log.trace(\"Partition {} keeps lastOffset at {}\", topicPartition, lastOffset);\n    }\n\n    // If a batch is failed fatally, the sequence numbers for future batches bound for the partition must be adjusted\n    // so that they don't fail with the OutOfOrderSequenceException.\n    //\n    // This method must only be called when we know that the batch is question has been unequivocally failed by the broker,\n    // ie. it has received a confirmed fatal status code like 'Message Too Large' or something similar.\n    void adjustSequencesDueToFailedBatch(ProducerBatch batch) {\n        if (!contains(batch.topicPartition))\n            // Sequence numbers are not being tracked for this partition. This could happen if the producer id was just\n            // reset due to a previous OutOfOrderSequenceException.\n            return;\n        log.debug(\"producerId: {}, send to partition {} failed fatally. Reducing future sequence numbers by {}\",\n                batch.producerId(), batch.topicPartition, batch.recordCount);\n\n        get(batch.topicPartition).adjustSequencesDueToFailedBatch(batch.baseSequence(), batch.recordCount);\n    }\n\n    int maybeUpdateLastAckedSequence(TopicPartition topicPartition, int sequence) {\n        TxnPartitionEntry entry = topicPartitions.get(topicPartition);\n        if (entry != null)\n            return entry.maybeUpdateLastAckedSequence(sequence);\n        return TxnPartitionEntry.NO_LAST_ACKED_SEQUENCE_NUMBER;\n    }\n\n    ProducerBatch nextBatchBySequence(TopicPartition topicPartition) {\n        return get(topicPartition).nextBatchBySequence();\n    }\n\n    void removeInFlightBatch(ProducerBatch batch) {\n        get(batch.topicPartition).removeInFlightBatch(batch);\n    }\n}\n",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/TxnPartitionMap.java#L1-L132",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TxnPartitionMap.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 1,
  "end_line": 132,
  "last_modified": "2026-02-06T01:16:27.610720",
  "source_type": "github"
}