{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_admin_KafkaAdminClient.java_2861",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java",
  "content": "                if (!resource.type().equals(ConfigResource.Type.BROKER_LOGGER)) {\n                    node = null;\n                }\n            }\n            if (node != null) {\n                NodeProvider nodeProvider = new ConstantNodeIdProvider(node, true);\n                allFutures.putAll(incrementalAlterConfigs(configs, options, Collections.singleton(resource), nodeProvider));\n            } else\n                unifiedRequestResources.add(resource);\n        }\n        if (!unifiedRequestResources.isEmpty())\n            allFutures.putAll(incrementalAlterConfigs(configs, options, unifiedRequestResources, new LeastLoadedBrokerOrActiveKController()));\n\n        return new AlterConfigsResult(new HashMap<>(allFutures));\n    }\n\n    private Map<ConfigResource, KafkaFutureImpl<Void>> incrementalAlterConfigs(Map<ConfigResource, Collection<AlterConfigOp>> configs,\n                                                                               final AlterConfigsOptions options,\n                                                                               Collection<ConfigResource> resources,\n                                                                               NodeProvider nodeProvider) {\n        final Map<ConfigResource, KafkaFutureImpl<Void>> futures = new HashMap<>();\n        for (ConfigResource resource : resources)\n            futures.put(resource, new KafkaFutureImpl<>());\n\n        final long now = time.milliseconds();\n        runnable.call(new Call(\"incrementalAlterConfigs\", calcDeadlineMs(now, options.timeoutMs()), nodeProvider) {\n\n            @Override\n            public IncrementalAlterConfigsRequest.Builder createRequest(int timeoutMs) {\n                return new IncrementalAlterConfigsRequest.Builder(resources, configs, options.shouldValidateOnly());\n            }\n\n            @Override\n            public void handleResponse(AbstractResponse abstractResponse) {\n                handleNotControllerError(abstractResponse);\n                IncrementalAlterConfigsResponse response = (IncrementalAlterConfigsResponse) abstractResponse;\n                Map<ConfigResource, ApiError> errors = IncrementalAlterConfigsResponse.fromResponseData(response.data());\n                for (Map.Entry<ConfigResource, KafkaFutureImpl<Void>> entry : futures.entrySet()) {\n                    KafkaFutureImpl<Void> future = entry.getValue();\n                    ApiException exception = errors.get(entry.getKey()).exception();\n                    if (exception != null) {\n                        future.completeExceptionally(exception);\n                    } else {\n                        future.complete(null);\n                    }\n                }\n            }\n\n            @Override\n            void handleFailure(Throwable throwable) {\n                completeAllExceptionally(futures.values(), throwable);\n            }\n        }, now);\n        return futures;\n    }\n\n    @Override\n    public AlterReplicaLogDirsResult alterReplicaLogDirs(Map<TopicPartitionReplica, String> replicaAssignment, final AlterReplicaLogDirsOptions options) {\n        final Map<TopicPartitionReplica, KafkaFutureImpl<Void>> futures = new HashMap<>(replicaAssignment.size());\n\n        for (TopicPartitionReplica replica : replicaAssignment.keySet())\n            futures.put(replica, new KafkaFutureImpl<>());\n\n        Map<Integer, AlterReplicaLogDirsRequestData> replicaAssignmentByBroker = new HashMap<>();\n        for (Map.Entry<TopicPartitionReplica, String> entry : replicaAssignment.entrySet()) {\n            TopicPartitionReplica replica = entry.getKey();\n            String logDir = entry.getValue();\n            int brokerId = replica.brokerId();\n            AlterReplicaLogDirsRequestData value = replicaAssignmentByBroker.computeIfAbsent(brokerId,\n                key -> new AlterReplicaLogDirsRequestData());\n            AlterReplicaLogDir alterReplicaLogDir = value.dirs().find(logDir);\n            if (alterReplicaLogDir == null) {\n                alterReplicaLogDir = new AlterReplicaLogDir();\n                alterReplicaLogDir.setPath(logDir);\n                value.dirs().add(alterReplicaLogDir);\n            }\n            AlterReplicaLogDirTopic alterReplicaLogDirTopic = alterReplicaLogDir.topics().find(replica.topic());\n            if (alterReplicaLogDirTopic == null) {\n                alterReplicaLogDirTopic = new AlterReplicaLogDirTopic().setName(replica.topic());\n                alterReplicaLogDir.topics().add(alterReplicaLogDirTopic);\n            }\n            alterReplicaLogDirTopic.partitions().add(replica.partition());\n        }\n\n        final long now = time.milliseconds();\n        for (Map.Entry<Integer, AlterReplicaLogDirsRequestData> entry : replicaAssignmentByBroker.entrySet()) {\n            final int brokerId = entry.getKey();\n            final AlterReplicaLogDirsRequestData assignment = entry.getValue();\n\n            runnable.call(new Call(\"alterReplicaLogDirs\", calcDeadlineMs(now, options.timeoutMs()),\n                new ConstantNodeIdProvider(brokerId)) {\n\n                @Override\n                public AlterReplicaLogDirsRequest.Builder createRequest(int timeoutMs) {\n                    return new AlterReplicaLogDirsRequest.Builder(assignment);\n                }\n\n                @Override\n                public void handleResponse(AbstractResponse abstractResponse) {\n                    AlterReplicaLogDirsResponse response = (AlterReplicaLogDirsResponse) abstractResponse;\n                    for (AlterReplicaLogDirTopicResult topicResult : response.data().results()) {\n                        for (AlterReplicaLogDirPartitionResult partitionResult : topicResult.partitions()) {\n                            TopicPartitionReplica replica = new TopicPartitionReplica(\n                                topicResult.topicName(), partitionResult.partitionIndex(), brokerId);\n                            KafkaFutureImpl<Void> future = futures.get(replica);\n                            if (future == null) {\n                                log.warn(\"The partition {} in the response from broker {} is not in the request\",\n                                    new TopicPartition(topicResult.topicName(), partitionResult.partitionIndex()),\n                                    brokerId);\n                            } else if (partitionResult.errorCode() == Errors.NONE.code()) {\n                                future.complete(null);\n                            } else {\n                                future.completeExceptionally(Errors.forCode(partitionResult.errorCode()).exception());\n                            }\n                        }\n                    }\n                    // The server should send back a response for every replica. But do a sanity check anyway.\n                    completeUnrealizedFutures(\n                        futures.entrySet().stream().filter(entry -> entry.getKey().brokerId() == brokerId),\n                        replica -> \"The response from broker \" + brokerId +\n                            \" did not contain a result for replica \" + replica);\n                }\n\n                @Override\n                void handleFailure(Throwable throwable) {\n                    // Only completes the futures of brokerId\n                    completeAllExceptionally(\n                        futures.entrySet().stream()\n                            .filter(entry -> entry.getKey().brokerId() == brokerId)\n                            .map(Map.Entry::getValue),\n                        throwable);\n                }\n            }, now);\n        }\n\n        return new AlterReplicaLogDirsResult(new HashMap<>(futures));\n    }\n\n    @Override\n    public DescribeLogDirsResult describeLogDirs(Collection<Integer> brokers, DescribeLogDirsOptions options) {\n        final Map<Integer, KafkaFutureImpl<Map<String, LogDirDescription>>> futures = new HashMap<>(brokers.size());\n\n        final long now = time.milliseconds();\n        for (final Integer brokerId : brokers) {\n            KafkaFutureImpl<Map<String, LogDirDescription>> future = new KafkaFutureImpl<>();\n            futures.put(brokerId, future);\n\n            runnable.call(new Call(\"describeLogDirs\", calcDeadlineMs(now, options.timeoutMs()),\n                new ConstantNodeIdProvider(brokerId)) {\n",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java#L2861-L3010",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 2861,
  "end_line": 3010,
  "last_modified": "2026-02-06T01:16:27.585045",
  "source_type": "github"
}