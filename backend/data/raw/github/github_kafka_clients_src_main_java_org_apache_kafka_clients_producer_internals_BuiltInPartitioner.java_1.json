{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_producer_internals_BuiltInPartitioner.java_1",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/producer/internals/BuiltInPartitioner.java",
  "content": "/*\n * Licensed to the Apache Software Foundation (ASF) under one or more\n * contributor license agreements. See the NOTICE file distributed with\n * this work for additional information regarding copyright ownership.\n * The ASF licenses this file to You under the Apache License, Version 2.0\n * (the \"License\"); you may not use this file except in compliance with\n * the License. You may obtain a copy of the License at\n *\n *    http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\npackage org.apache.kafka.clients.producer.internals;\n\nimport org.apache.kafka.common.Cluster;\nimport org.apache.kafka.common.PartitionInfo;\nimport org.apache.kafka.common.utils.LogContext;\nimport org.apache.kafka.common.utils.Utils;\n\nimport org.slf4j.Logger;\n\nimport java.util.Arrays;\nimport java.util.List;\nimport java.util.concurrent.ThreadLocalRandom;\nimport java.util.concurrent.atomic.AtomicInteger;\nimport java.util.concurrent.atomic.AtomicReference;\n\n/**\n * Built-in default partitioner.  Note, that this is just a utility class that is used directly from\n * RecordAccumulator, it does not implement the Partitioner interface.\n *\n * The class keeps track of various bookkeeping information required for adaptive sticky partitioning\n * (described in detail in KIP-794).  There is one partitioner object per topic.\n */\npublic class BuiltInPartitioner {\n    private final Logger log;\n    private final String topic;\n    private final int stickyBatchSize;\n\n    private volatile PartitionLoadStats partitionLoadStats = null;\n    private final AtomicReference<StickyPartitionInfo> stickyPartitionInfo = new AtomicReference<>();\n\n\n    /**\n     * BuiltInPartitioner constructor.\n     *\n     * @param topic The topic\n     * @param stickyBatchSize How much to produce to partition before switch\n     */\n    public BuiltInPartitioner(LogContext logContext, String topic, int stickyBatchSize) {\n        this.log = logContext.logger(BuiltInPartitioner.class);\n        this.topic = topic;\n        if (stickyBatchSize < 1) {\n            throw new IllegalArgumentException(\"stickyBatchSize must be >= 1 but got \" + stickyBatchSize);\n        }\n        this.stickyBatchSize = stickyBatchSize;\n    }\n\n    /**\n     * Calculate the next partition for the topic based on the partition load stats.\n     */\n    private int nextPartition(Cluster cluster) {\n        int random = randomPartition();\n\n        // Cache volatile variable in local variable.\n        PartitionLoadStats partitionLoadStats = this.partitionLoadStats;\n        int partition;\n\n        if (partitionLoadStats == null) {\n            // We don't have stats to do adaptive partitioning (or it's disabled), just switch to the next\n            // partition based on uniform distribution.\n            List<PartitionInfo> availablePartitions = cluster.availablePartitionsForTopic(topic);\n            if (!availablePartitions.isEmpty()) {\n                partition = availablePartitions.get(random % availablePartitions.size()).partition();\n            } else {\n                // We don't have available partitions, just pick one among all partitions.\n                List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);\n                partition = random % partitions.size();\n            }\n        } else {\n            // Calculate next partition based on load distribution.\n            // Note that partitions without leader are excluded from the partitionLoadStats.\n            assert partitionLoadStats.length > 0;\n\n            int[] cumulativeFrequencyTable = partitionLoadStats.cumulativeFrequencyTable;\n            int weightedRandom = random % cumulativeFrequencyTable[partitionLoadStats.length - 1];\n\n            // By construction, the cumulative frequency table is sorted, so we can use binary\n            // search to find the desired index.\n            int searchResult = Arrays.binarySearch(cumulativeFrequencyTable, 0, partitionLoadStats.length, weightedRandom);\n\n            // binarySearch results the index of the found element, or -(insertion_point) - 1\n            // (where insertion_point is the index of the first element greater than the key).\n            // We need to get the index of the first value that is strictly greater, which\n            // would be the insertion point, except if we found the element that's equal to\n            // the searched value (in this case we need to get next).  For example, if we have\n            //  4 5 8\n            // and we're looking for 3, then we'd get the insertion_point = 0, and the function\n            // would return -0 - 1 = -1, by adding 1 we'd get 0.  If we're looking for 4, we'd\n            // get 0, and we need the next one, so adding 1 works here as well.\n            int partitionIndex = Math.abs(searchResult + 1);\n            assert partitionIndex < partitionLoadStats.length;\n            partition = partitionLoadStats.partitionIds[partitionIndex];\n        }\n\n        log.trace(\"Switching to partition {} in topic {}\", partition, topic);\n        return partition;\n    }\n\n    int randomPartition() {\n        return Utils.toPositive(ThreadLocalRandom.current().nextInt());\n    }\n\n    /**\n     * Test-only function.  When partition load stats are defined, return the end of range for the\n     * random number.\n     */\n    public int loadStatsRangeEnd() {\n        assert partitionLoadStats != null;\n        assert partitionLoadStats.length > 0;\n        return partitionLoadStats.cumulativeFrequencyTable[partitionLoadStats.length - 1];\n    }\n\n    /**\n     * Peek currently chosen sticky partition.  This method works in conjunction with {@link #isPartitionChanged}\n     * and {@link #updatePartitionInfo}.  The workflow is the following:\n     *\n     * 1. peekCurrentPartitionInfo is called to know which partition to lock.\n     * 2. Lock partition's batch queue.\n     * 3. isPartitionChanged under lock to make sure that nobody raced us.\n     * 4. Append data to buffer.\n     * 5. updatePartitionInfo to update produced bytes and maybe switch partition.\n     *\n     *  It's important that steps 3-5 are under partition's batch queue lock.\n     *\n     * @param cluster The cluster information (needed if there is no current partition)\n     * @return sticky partition info object\n     */\n    StickyPartitionInfo peekCurrentPartitionInfo(Cluster cluster) {\n        StickyPartitionInfo partitionInfo = stickyPartitionInfo.get();\n        if (partitionInfo != null)\n            return partitionInfo;\n\n        // We're the first to create it.\n        partitionInfo = new StickyPartitionInfo(nextPartition(cluster));\n        if (stickyPartitionInfo.compareAndSet(null, partitionInfo))",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/BuiltInPartitioner.java#L1-L150",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/BuiltInPartitioner.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 1,
  "end_line": 150,
  "last_modified": "2026-02-06T01:16:27.609205",
  "source_type": "github"
}