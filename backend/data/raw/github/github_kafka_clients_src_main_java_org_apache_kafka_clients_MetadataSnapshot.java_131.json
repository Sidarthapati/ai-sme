{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_MetadataSnapshot.java_131",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/MetadataSnapshot.java",
  "content": "     * @param tp partition\n     * @return leader-epoch if known, else return OptionalInt.empty()\n     */\n    public OptionalInt leaderEpochFor(TopicPartition tp) {\n        PartitionMetadata partitionMetadata = metadataByPartition.get(tp);\n        if (partitionMetadata == null || partitionMetadata.leaderEpoch.isEmpty()) {\n            return OptionalInt.empty();\n        } else {\n            return OptionalInt.of(partitionMetadata.leaderEpoch.get());\n        }\n    }\n\n    ClusterResource clusterResource() {\n        return new ClusterResource(clusterId);\n    }\n\n    /**\n     * Merges the metadata snapshot's contents with the provided metadata, returning a new metadata snapshot. The provided\n     * metadata is presumed to be more recent than the snapshot's metadata, and therefore all overlapping metadata will\n     * be overridden.\n     *\n     * @param newClusterId the new cluster Id\n     * @param newNodes the new set of nodes\n     * @param addPartitions partitions to add\n     * @param addUnauthorizedTopics unauthorized topics to add\n     * @param addInternalTopics internal topics to add\n     * @param newController the new controller node\n     * @param addTopicIds the mapping from topic name to topic ID, for topics in addPartitions\n     * @param retainTopic returns whether a pre-existing topic's metadata should be retained\n     * @return the merged metadata snapshot\n     */\n    MetadataSnapshot mergeWith(String newClusterId,\n                            Map<Integer, Node> newNodes,\n                            Collection<PartitionMetadata> addPartitions,\n                            Set<String> addUnauthorizedTopics,\n                            Set<String> addInvalidTopics,\n                            Set<String> addInternalTopics,\n                            Node newController,\n                            Map<String, Uuid> addTopicIds,\n                            BiPredicate<String, Boolean> retainTopic) {\n\n        Predicate<String> shouldRetainTopic = topic -> retainTopic.test(topic, internalTopics.contains(topic));\n\n        Map<TopicPartition, PartitionMetadata> newMetadataByPartition = new HashMap<>(addPartitions.size());\n\n        // We want the most recent topic ID. We start with the previous ID stored for retained topics and then\n        // update with newest information from the MetadataResponse. We always take the latest state, removing existing\n        // topic IDs if the latest state contains the topic name but not a topic ID.\n        Map<String, Uuid> newTopicIds = this.topicIds.entrySet().stream()\n                .filter(entry -> shouldRetainTopic.test(entry.getKey()))\n                .collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));\n\n        for (PartitionMetadata partition : addPartitions) {\n            newMetadataByPartition.put(partition.topicPartition, partition);\n            Uuid id = addTopicIds.get(partition.topic());\n            if (id != null)\n                newTopicIds.put(partition.topic(), id);\n            else\n                // Remove if the latest metadata does not have a topic ID\n                newTopicIds.remove(partition.topic());\n        }\n        for (Map.Entry<TopicPartition, PartitionMetadata> entry : metadataByPartition.entrySet()) {\n            if (shouldRetainTopic.test(entry.getKey().topic())) {\n                newMetadataByPartition.putIfAbsent(entry.getKey(), entry.getValue());\n            }\n        }\n\n        Set<String> newUnauthorizedTopics = fillSet(addUnauthorizedTopics, unauthorizedTopics, shouldRetainTopic);\n        Set<String> newInvalidTopics = fillSet(addInvalidTopics, invalidTopics, shouldRetainTopic);\n        Set<String> newInternalTopics = fillSet(addInternalTopics, internalTopics, shouldRetainTopic);\n\n        return new MetadataSnapshot(newClusterId, newNodes, newMetadataByPartition.values(), newUnauthorizedTopics,\n                newInvalidTopics, newInternalTopics, newController, newTopicIds);\n    }\n\n    /**\n     * Copies {@code baseSet} and adds all non-existent elements in {@code fillSet} such that {@code predicate} is true.\n     * In other words, all elements of {@code baseSet} will be contained in the result, with additional non-overlapping\n     * elements in {@code fillSet} where the predicate is true.\n     *\n     * @param baseSet the base elements for the resulting set\n     * @param fillSet elements to be filled into the resulting set\n     * @param predicate tested against the fill set to determine whether elements should be added to the base set\n     */\n    private static <T> Set<T> fillSet(Set<T> baseSet, Set<T> fillSet, Predicate<T> predicate) {\n        Set<T> result = new HashSet<>(baseSet);\n        for (T element : fillSet) {\n            if (predicate.test(element)) {\n                result.add(element);\n            }\n        }\n        return result;\n    }\n\n    private void computeClusterView() {\n        List<PartitionInfo> partitionInfos = metadataByPartition.values()\n                .stream()\n                .map(metadata -> MetadataResponse.toPartitionInfo(metadata, nodes))\n                .collect(Collectors.toList());\n        this.clusterInstance = new Cluster(clusterId, nodes.values(), partitionInfos, unauthorizedTopics,\n                invalidTopics, internalTopics, controller, topicIds);\n    }\n\n    static MetadataSnapshot bootstrap(List<InetSocketAddress> addresses) {\n        Map<Integer, Node> nodes = new HashMap<>();\n        int nodeId = -1;\n        for (InetSocketAddress address : addresses) {\n            nodes.put(nodeId, new Node(nodeId, address.getHostString(), address.getPort()));\n            nodeId--;\n        }\n        return new MetadataSnapshot(null, nodes, Collections.emptyList(),\n                Collections.emptySet(), Collections.emptySet(), Collections.emptySet(),\n                null, Collections.emptyMap(), Cluster.bootstrap(addresses));\n    }\n\n    static MetadataSnapshot empty() {\n        return new MetadataSnapshot(null, Collections.emptyMap(), Collections.emptyList(),\n                Collections.emptySet(), Collections.emptySet(), Collections.emptySet(), null, Collections.emptyMap(), Cluster.empty());\n    }\n\n    @Override\n    public String toString() {\n        return \"MetadataSnapshot{\" +\n                \"clusterId='\" + clusterId + '\\'' +\n                \", nodes=\" + nodes +\n                \", partitions=\" + metadataByPartition.values() +\n                \", controller=\" + controller +\n                '}';\n    }\n\n}\n",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/MetadataSnapshot.java#L131-L262",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/MetadataSnapshot.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 131,
  "end_line": 262,
  "last_modified": "2026-02-06T01:16:27.578672",
  "source_type": "github"
}