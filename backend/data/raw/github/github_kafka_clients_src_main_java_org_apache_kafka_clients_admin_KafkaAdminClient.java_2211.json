{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_admin_KafkaAdminClient.java_2211",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java",
  "content": "        Map<Integer, Node> nodes,\n        DescribeTopicsOptions options,\n        long now\n    ) {\n        final Map<String, TopicRequest> topicsRequests = new LinkedHashMap<>();\n        topicNamesList.stream().sorted().forEach(topic ->\n            topicsRequests.put(topic, new TopicRequest().setName(topic))\n        );\n        return new Call(\"describeTopicPartitions\", calcDeadlineMs(now, options.timeoutMs()),\n            new LeastLoadedNodeProvider()) {\n            TopicDescription partiallyFinishedTopicDescription = null;\n\n            @Override\n            DescribeTopicPartitionsRequest.Builder createRequest(int timeoutMs) {\n                DescribeTopicPartitionsRequestData request = new DescribeTopicPartitionsRequestData()\n                    .setTopics(new ArrayList<>(topicsRequests.values()))\n                    .setResponsePartitionLimit(options.partitionSizeLimitPerResponse());\n                if (partiallyFinishedTopicDescription != null) {\n                    // If the previous cursor points to partition 0, it will not be set here. Instead, the previous\n                    // cursor topic will be the first topic in the request.\n                    request.setCursor(new DescribeTopicPartitionsRequestData.Cursor()\n                        .setTopicName(partiallyFinishedTopicDescription.name())\n                        .setPartitionIndex(partiallyFinishedTopicDescription.partitions().size())\n                    );\n                }\n                return new DescribeTopicPartitionsRequest.Builder(request);\n            }\n\n            @SuppressWarnings(\"NPathComplexity\")\n            @Override\n            void handleResponse(AbstractResponse abstractResponse) {\n                DescribeTopicPartitionsResponse response = (DescribeTopicPartitionsResponse) abstractResponse;\n                DescribeTopicPartitionsResponseData.Cursor responseCursor = response.data().nextCursor();\n                // The topicDescription for the cursor topic of the current batch.\n                TopicDescription nextTopicDescription = null;\n\n                for (DescribeTopicPartitionsResponseTopic topic : response.data().topics()) {\n                    String topicName = topic.name();\n                    Errors error = Errors.forCode(topic.errorCode());\n\n                    KafkaFutureImpl<TopicDescription> future = topicFutures.get(topicName);\n\n                    if (error != Errors.NONE) {\n                        future.completeExceptionally(error.exception());\n                        topicsRequests.remove(topicName);\n                        if (responseCursor != null && responseCursor.topicName().equals(topicName)) {\n                            responseCursor = null;\n                        }\n                        continue;\n                    }\n\n                    TopicDescription currentTopicDescription = getTopicDescriptionFromDescribeTopicsResponseTopic(topic, nodes, options.includeAuthorizedOperations());\n\n                    if (partiallyFinishedTopicDescription != null && partiallyFinishedTopicDescription.name().equals(topicName)) {\n                        // Add the partitions for the cursor topic of the previous batch.\n                        partiallyFinishedTopicDescription.partitions().addAll(currentTopicDescription.partitions());\n                        continue;\n                    }\n\n                    if (responseCursor != null && responseCursor.topicName().equals(topicName)) {\n                        // In the same batch of result, it may need to handle the partitions for the previous cursor\n                        // topic and the current cursor topic. Cache the result in the nextTopicDescription.\n                        nextTopicDescription = currentTopicDescription;\n                        continue;\n                    }\n\n                    topicsRequests.remove(topicName);\n                    future.complete(currentTopicDescription);\n                }\n\n                if (partiallyFinishedTopicDescription != null &&\n                    (responseCursor == null || !responseCursor.topicName().equals(partiallyFinishedTopicDescription.name()))) {\n                    // We can't simply check nextTopicDescription != null here to close the partiallyFinishedTopicDescription.\n                    // Because the responseCursor topic may not show in the response.\n                    String topicName = partiallyFinishedTopicDescription.name();\n                    topicFutures.get(topicName).complete(partiallyFinishedTopicDescription);\n                    topicsRequests.remove(topicName);\n                    partiallyFinishedTopicDescription = null;\n                }\n                if (nextTopicDescription != null) {\n                    partiallyFinishedTopicDescription = nextTopicDescription;\n                }\n\n                if (!topicsRequests.isEmpty()) {\n                    runnable.call(this, time.milliseconds());\n                }\n            }\n\n            @Override\n            boolean handleUnsupportedVersionException(UnsupportedVersionException exception) {\n                final long now = time.milliseconds();\n                runnable.call(generateDescribeTopicsCallWithMetadataApi(topicNamesList, topicFutures, options, now), now);\n                return false;\n            }\n\n            @Override\n            void handleFailure(Throwable throwable) {\n                if (!(throwable instanceof UnsupportedVersionException)) {\n                    completeAllExceptionally(topicFutures.values(), throwable);\n                }\n            }\n        };\n    }\n\n    private Map<String, KafkaFuture<TopicDescription>> handleDescribeTopicsByNamesWithDescribeTopicPartitionsApi(\n        final Collection<String> topicNames,\n        DescribeTopicsOptions options\n    ) {\n        final Map<String, KafkaFutureImpl<TopicDescription>> topicFutures = new HashMap<>(topicNames.size());\n        final ArrayList<String> topicNamesList = new ArrayList<>();\n        for (String topicName : topicNames) {\n            if (topicNameIsUnrepresentable(topicName)) {\n                KafkaFutureImpl<TopicDescription> future = new KafkaFutureImpl<>();\n                future.completeExceptionally(new InvalidTopicException(\"The given topic name '\" +\n                    topicName + \"' cannot be represented in a request.\"));\n                topicFutures.put(topicName, future);\n            } else if (!topicFutures.containsKey(topicName)) {\n                topicFutures.put(topicName, new KafkaFutureImpl<>());\n                topicNamesList.add(topicName);\n            }\n        }\n\n        if (topicNamesList.isEmpty()) {\n            return new HashMap<>(topicFutures);\n        }\n\n        // First, we need to retrieve the node info.\n        DescribeClusterResult clusterResult = describeCluster(new DescribeClusterOptions().timeoutMs(options.timeoutMs()));\n        clusterResult.nodes().whenComplete(\n            (nodes, exception) -> {\n                if (exception != null) {\n                    completeAllExceptionally(topicFutures.values(), exception);\n                    return;\n                }\n\n                final long now = time.milliseconds();\n                Map<Integer, Node> nodeIdMap = nodes.stream().collect(Collectors.toMap(Node::id, node -> node));\n                runnable.call(\n                    generateDescribeTopicsCallWithDescribeTopicPartitionsApi(topicNamesList, topicFutures, nodeIdMap, options, now),\n                    now\n                );\n            });\n\n        return new HashMap<>(topicFutures);\n    }\n\n    private Map<Uuid, KafkaFuture<TopicDescription>> handleDescribeTopicsByIds(Collection<Uuid> topicIds, DescribeTopicsOptions options) {\n\n        final Map<Uuid, KafkaFutureImpl<TopicDescription>> topicFutures = new HashMap<>(topicIds.size());\n        final List<Uuid> topicIdsList = new ArrayList<>();",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java#L2211-L2360",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 2211,
  "end_line": 2360,
  "last_modified": "2026-02-06T01:16:27.585045",
  "source_type": "github"
}