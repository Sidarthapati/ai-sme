{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_admin_KafkaAdminClient.java_3121",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java",
  "content": "                        for (Map.Entry<TopicPartition, ReplicaInfo> replicaInfoEntry : logDirInfo.replicaInfos().entrySet()) {\n                            TopicPartition tp = replicaInfoEntry.getKey();\n                            ReplicaInfo replicaInfo = replicaInfoEntry.getValue();\n                            ReplicaLogDirInfo replicaLogDirInfo = replicaDirInfoByPartition.get(tp);\n                            if (replicaLogDirInfo == null) {\n                                log.warn(\"Server response from broker {} mentioned unknown partition {}\", brokerId, tp);\n                            } else if (replicaInfo.isFuture()) {\n                                replicaDirInfoByPartition.put(tp, new ReplicaLogDirInfo(replicaLogDirInfo.getCurrentReplicaLogDir(),\n                                    replicaLogDirInfo.getCurrentReplicaOffsetLag(),\n                                    logDir,\n                                    replicaInfo.offsetLag()));\n                            } else {\n                                replicaDirInfoByPartition.put(tp, new ReplicaLogDirInfo(logDir,\n                                    replicaInfo.offsetLag(),\n                                    replicaLogDirInfo.getFutureReplicaLogDir(),\n                                    replicaLogDirInfo.getFutureReplicaOffsetLag()));\n                            }\n                        }\n                    }\n\n                    for (Map.Entry<TopicPartition, ReplicaLogDirInfo> entry : replicaDirInfoByPartition.entrySet()) {\n                        TopicPartition tp = entry.getKey();\n                        KafkaFutureImpl<ReplicaLogDirInfo> future = futures.get(new TopicPartitionReplica(tp.topic(), tp.partition(), brokerId));\n                        future.complete(entry.getValue());\n                    }\n                }\n\n                @Override\n                void handleFailure(Throwable throwable) {\n                    completeAllExceptionally(futures.values(), throwable);\n                }\n            }, now);\n        }\n\n        return new DescribeReplicaLogDirsResult(new HashMap<>(futures));\n    }\n\n    @Override\n    public CreatePartitionsResult createPartitions(final Map<String, NewPartitions> newPartitions,\n                                                   final CreatePartitionsOptions options) {\n        final Map<String, KafkaFutureImpl<Void>> futures = new HashMap<>(newPartitions.size());\n        final CreatePartitionsTopicCollection topics = new CreatePartitionsTopicCollection(newPartitions.size());\n        for (Map.Entry<String, NewPartitions> entry : newPartitions.entrySet()) {\n            final String topic = entry.getKey();\n            final NewPartitions newPartition = entry.getValue();\n            List<List<Integer>> newAssignments = newPartition.assignments();\n            List<CreatePartitionsAssignment> assignments = newAssignments == null ? null :\n                newAssignments.stream()\n                    .map(brokerIds -> new CreatePartitionsAssignment().setBrokerIds(brokerIds))\n                    .collect(Collectors.toList());\n            topics.add(new CreatePartitionsTopic()\n                .setName(topic)\n                .setCount(newPartition.totalCount())\n                .setAssignments(assignments));\n            futures.put(topic, new KafkaFutureImpl<>());\n        }\n        if (!topics.isEmpty()) {\n            final long now = time.milliseconds();\n            final long deadline = calcDeadlineMs(now, options.timeoutMs());\n            final Call call = getCreatePartitionsCall(options, futures, topics,\n                Collections.emptyMap(), now, deadline);\n            runnable.call(call, now);\n        }\n        return new CreatePartitionsResult(new HashMap<>(futures));\n    }\n\n    private Call getCreatePartitionsCall(final CreatePartitionsOptions options,\n                                         final Map<String, KafkaFutureImpl<Void>> futures,\n                                         final CreatePartitionsTopicCollection topics,\n                                         final Map<String, ThrottlingQuotaExceededException> quotaExceededExceptions,\n                                         final long now,\n                                         final long deadline) {\n        return new Call(\"createPartitions\", deadline, new ControllerNodeProvider()) {\n            @Override\n            public CreatePartitionsRequest.Builder createRequest(int timeoutMs) {\n                return new CreatePartitionsRequest.Builder(\n                    new CreatePartitionsRequestData()\n                        .setTopics(topics)\n                        .setValidateOnly(options.validateOnly())\n                        .setTimeoutMs(timeoutMs));\n            }\n\n            @Override\n            public void handleResponse(AbstractResponse abstractResponse) {\n                // Check for controller change\n                handleNotControllerError(abstractResponse);\n                // Handle server responses for particular topics.\n                final CreatePartitionsResponse response = (CreatePartitionsResponse) abstractResponse;\n                final CreatePartitionsTopicCollection retryTopics = new CreatePartitionsTopicCollection();\n                final Map<String, ThrottlingQuotaExceededException> retryTopicQuotaExceededExceptions = new HashMap<>();\n                for (CreatePartitionsTopicResult result : response.data().results()) {\n                    KafkaFutureImpl<Void> future = futures.get(result.name());\n                    if (future == null) {\n                        log.warn(\"Server response mentioned unknown topic {}\", result.name());\n                    } else {\n                        ApiError error = new ApiError(result.errorCode(), result.errorMessage());\n                        if (error.isFailure()) {\n                            if (error.is(Errors.THROTTLING_QUOTA_EXCEEDED)) {\n                                ThrottlingQuotaExceededException quotaExceededException = new ThrottlingQuotaExceededException(\n                                    response.throttleTimeMs(), error.messageWithFallback());\n                                if (options.shouldRetryOnQuotaViolation()) {\n                                    retryTopics.add(topics.find(result.name()).duplicate());\n                                    retryTopicQuotaExceededExceptions.put(result.name(), quotaExceededException);\n                                } else {\n                                    future.completeExceptionally(quotaExceededException);\n                                }\n                            } else {\n                                future.completeExceptionally(error.exception());\n                            }\n                        } else {\n                            future.complete(null);\n                        }\n                    }\n                }\n                // If there are topics to retry, retry them; complete unrealized futures otherwise.\n                if (retryTopics.isEmpty()) {\n                    // The server should send back a response for every topic. But do a sanity check anyway.\n                    completeUnrealizedFutures(futures.entrySet().stream(),\n                        topic -> \"The controller response did not contain a result for topic \" + topic);\n                } else {\n                    final long now = time.milliseconds();\n                    final Call call = getCreatePartitionsCall(options, futures, retryTopics,\n                        retryTopicQuotaExceededExceptions, now, deadline);\n                    runnable.call(call, now);\n                }\n            }\n\n            @Override\n            void handleFailure(Throwable throwable) {\n                // If there were any topics retries due to a quota exceeded exception, we propagate\n                // the initial error back to the caller if the request timed out.\n                maybeCompleteQuotaExceededException(options.shouldRetryOnQuotaViolation(),\n                    throwable, futures, quotaExceededExceptions, (int) (time.milliseconds() - now));\n                // Fail all the other remaining futures\n\n                completeAllExceptionally(futures.values(), throwable);\n            }\n        };\n    }\n\n    @Override\n    public DeleteRecordsResult deleteRecords(final Map<TopicPartition, RecordsToDelete> recordsToDelete,\n                                             final DeleteRecordsOptions options) {\n        PartitionLeaderStrategy.PartitionLeaderFuture<DeletedRecords> future =\n            DeleteRecordsHandler.newFuture(recordsToDelete.keySet(), partitionLeaderCache);\n        int timeoutMs = defaultApiTimeoutMs;\n        if (options.timeoutMs() != null) {\n            timeoutMs = options.timeoutMs();\n        }\n        DeleteRecordsHandler handler = new DeleteRecordsHandler(recordsToDelete, logContext, timeoutMs);",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java#L3121-L3270",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 3121,
  "end_line": 3270,
  "last_modified": "2026-02-06T01:16:27.585045",
  "source_type": "github"
}