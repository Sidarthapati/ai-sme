{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_admin_KafkaAdminClient.java_651",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java",
  "content": "        int requestTimeoutMs = config.getInt(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG);\n        int defaultApiTimeoutMs = config.getInt(AdminClientConfig.DEFAULT_API_TIMEOUT_MS_CONFIG);\n\n        if (defaultApiTimeoutMs < requestTimeoutMs) {\n            if (config.originals().containsKey(AdminClientConfig.DEFAULT_API_TIMEOUT_MS_CONFIG)) {\n                throw new ConfigException(\"The specified value of \" + AdminClientConfig.DEFAULT_API_TIMEOUT_MS_CONFIG +\n                    \" must be no smaller than the value of \" + AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG + \".\");\n            } else {\n                log.warn(\"Overriding the default value for {} ({}) with the explicitly configured request timeout {}\",\n                    AdminClientConfig.DEFAULT_API_TIMEOUT_MS_CONFIG, this.defaultApiTimeoutMs,\n                    requestTimeoutMs);\n                return requestTimeoutMs;\n            }\n        }\n        return defaultApiTimeoutMs;\n    }\n\n    @Override\n    public void close(Duration timeout) {\n        long waitTimeMs = timeout.toMillis();\n        if (waitTimeMs < 0)\n            throw new IllegalArgumentException(\"The timeout cannot be negative.\");\n        waitTimeMs = Math.min(TimeUnit.DAYS.toMillis(365), waitTimeMs); // Limit the timeout to a year.\n        long now = time.milliseconds();\n        long newHardShutdownTimeMs = now + waitTimeMs;\n        long prev = INVALID_SHUTDOWN_TIME;\n        clientTelemetryReporter.ifPresent(ClientTelemetryReporter::initiateClose);\n        metrics.close();\n        while (true) {\n            if (hardShutdownTimeMs.compareAndSet(prev, newHardShutdownTimeMs)) {\n                if (prev == INVALID_SHUTDOWN_TIME) {\n                    log.debug(\"Initiating close operation.\");\n                } else {\n                    log.debug(\"Moving hard shutdown time forward.\");\n                }\n                client.wakeup(); // Wake the thread, if it is blocked inside poll().\n                break;\n            }\n            prev = hardShutdownTimeMs.get();\n            if (prev < newHardShutdownTimeMs) {\n                log.debug(\"Hard shutdown time is already earlier than requested.\");\n                newHardShutdownTimeMs = prev;\n                break;\n            }\n        }\n        if (log.isDebugEnabled()) {\n            long deltaMs = Math.max(0, newHardShutdownTimeMs - time.milliseconds());\n            log.debug(\"Waiting for the I/O thread to exit. Hard shutdown in {} ms.\", deltaMs);\n        }\n        try {\n            // close() can be called by AdminClient thread when it invokes callback. That will\n            // cause deadlock, so check for that condition.\n            if (Thread.currentThread() != thread) {\n                // Wait for the thread to be joined.\n                thread.join(waitTimeMs);\n            }\n            log.debug(\"Kafka admin client closed.\");\n        } catch (InterruptedException e) {\n            log.debug(\"Interrupted while joining I/O thread\", e);\n            Thread.currentThread().interrupt();\n        }\n    }\n\n    /**\n     * An interface for providing a node for a call.\n     */\n    private interface NodeProvider {\n        Node provide();\n\n        boolean supportsUseControllers();\n    }\n\n    private class MetadataUpdateNodeIdProvider implements NodeProvider {\n        @Override\n        public Node provide() {\n            long now = time.milliseconds();\n            LeastLoadedNode leastLoadedNode = client.leastLoadedNode(now);\n            if (metadataRecoveryStrategy == MetadataRecoveryStrategy.REBOOTSTRAP\n                && !leastLoadedNode.hasNodeAvailableOrConnectionReady()) {\n                metadataManager.rebootstrap(now);\n            }\n\n            return leastLoadedNode.node();\n        }\n\n        @Override\n        public boolean supportsUseControllers() {\n            return true;\n        }\n    }\n\n    private class ConstantNodeIdProvider implements NodeProvider {\n        private final int nodeId;\n        private final boolean supportsUseControllers;\n\n        ConstantNodeIdProvider(int nodeId, boolean supportsUseControllers) {\n            this.nodeId = nodeId;\n            this.supportsUseControllers = supportsUseControllers;\n        }\n\n        ConstantNodeIdProvider(int nodeId) {\n            this.nodeId = nodeId;\n            this.supportsUseControllers = false;\n        }\n\n        @Override\n        public Node provide() {\n            if (metadataManager.isReady() &&\n                (metadataManager.nodeById(nodeId) != null)) {\n                return metadataManager.nodeById(nodeId);\n            }\n            // If we can't find the node with the given constant ID, we schedule a\n            // metadata update and hope it appears.  This behavior is useful for avoiding\n            // flaky behavior in tests when the cluster is starting up and not all nodes\n            // have appeared.\n            metadataManager.requestUpdate();\n            return null;\n        }\n\n        @Override\n        public boolean supportsUseControllers() {\n            return supportsUseControllers;\n        }\n    }\n\n    /**\n     * Provides the controller node.\n     */\n    private class ControllerNodeProvider implements NodeProvider {\n        private final boolean supportsUseControllers;\n\n        ControllerNodeProvider(boolean supportsUseControllers) {\n            this.supportsUseControllers = supportsUseControllers;\n        }\n\n        ControllerNodeProvider() {\n            this.supportsUseControllers = false;\n        }\n\n        @Override\n        public Node provide() {\n            if (metadataManager.isReady() &&\n                (metadataManager.controller() != null)) {\n                return metadataManager.controller();\n            }\n            metadataManager.requestUpdate();\n            return null;\n        }\n\n        @Override",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java#L651-L800",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 651,
  "end_line": 800,
  "last_modified": "2026-02-06T01:16:27.585045",
  "source_type": "github"
}