{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_producer_internals_TransactionManager.java_1561",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java",
  "content": "    private class AddPartitionsToTxnHandler extends TxnRequestHandler {\n        private final AddPartitionsToTxnRequest.Builder builder;\n        private long retryBackoffMs;\n\n        private AddPartitionsToTxnHandler(AddPartitionsToTxnRequest.Builder builder) {\n            super(\"AddPartitionsToTxn\");\n            this.builder = builder;\n            this.retryBackoffMs = TransactionManager.this.retryBackoffMs;\n        }\n\n        @Override\n        AddPartitionsToTxnRequest.Builder requestBuilder() {\n            return builder;\n        }\n\n        @Override\n        Priority priority() {\n            return Priority.ADD_PARTITIONS_OR_OFFSETS;\n        }\n\n        @Override\n        public void handleResponse(AbstractResponse response) {\n            AddPartitionsToTxnResponse addPartitionsToTxnResponse = (AddPartitionsToTxnResponse) response;\n            Map<TopicPartition, Errors> errors = addPartitionsToTxnResponse.errors().get(AddPartitionsToTxnResponse.V3_AND_BELOW_TXN_ID);\n            boolean hasPartitionErrors = false;\n            Set<String> unauthorizedTopics = new HashSet<>();\n            retryBackoffMs = TransactionManager.this.retryBackoffMs;\n\n            for (Map.Entry<TopicPartition, Errors> topicPartitionErrorEntry : errors.entrySet()) {\n                TopicPartition topicPartition = topicPartitionErrorEntry.getKey();\n                Errors error = topicPartitionErrorEntry.getValue();\n\n                if (error == Errors.NONE) {\n                    continue;\n                } else if (error == Errors.COORDINATOR_NOT_AVAILABLE || error == Errors.NOT_COORDINATOR) {\n                    lookupCoordinator(FindCoordinatorRequest.CoordinatorType.TRANSACTION, transactionalId);\n                    reenqueue();\n                    return;\n                } else if (error == Errors.CONCURRENT_TRANSACTIONS) {\n                    maybeOverrideRetryBackoffMs();\n                    reenqueue();\n                    return;\n                } else if (error.exception() instanceof RetriableException) {\n                    reenqueue();\n                    return;\n                } else if (error == Errors.INVALID_PRODUCER_EPOCH || error == Errors.PRODUCER_FENCED) {\n                    // We could still receive INVALID_PRODUCER_EPOCH from old versioned transaction coordinator,\n                    // just treat it the same as PRODUCE_FENCED.\n                    fatalError(Errors.PRODUCER_FENCED.exception());\n                    return;\n                } else if (error == Errors.TRANSACTIONAL_ID_AUTHORIZATION_FAILED ||\n                        error == Errors.INVALID_TXN_STATE || error == Errors.INVALID_PRODUCER_ID_MAPPING) {\n                    fatalError(error.exception());\n                    return;\n                } else if (error == Errors.TOPIC_AUTHORIZATION_FAILED) {\n                    unauthorizedTopics.add(topicPartition.topic());\n                } else if (error == Errors.OPERATION_NOT_ATTEMPTED) {\n                    log.debug(\"Did not attempt to add partition {} to transaction because other partitions in the \" +\n                            \"batch had errors.\", topicPartition);\n                    hasPartitionErrors = true;\n                } else if (error == Errors.UNKNOWN_PRODUCER_ID) {\n                    abortableErrorIfPossible(error.exception());\n                    return;\n                } else if (error == Errors.TRANSACTION_ABORTABLE) {\n                    abortableError(error.exception());\n                    return;\n                } else {\n                    log.error(\"Could not add partition {} due to unexpected error {}\", topicPartition, error);\n                    hasPartitionErrors = true;\n                }\n            }\n\n            Set<TopicPartition> partitions = errors.keySet();\n\n            // Remove the partitions from the pending set regardless of the result. We use the presence\n            // of partitions in the pending set to know when it is not safe to send batches. However, if\n            // the partitions failed to be added and we enter an error state, we expect the batches to be\n            // aborted anyway. In this case, we must be able to continue sending the batches which are in\n            // retry for partitions that were successfully added.\n            pendingPartitionsInTransaction.removeAll(partitions);\n\n            if (!unauthorizedTopics.isEmpty()) {\n                abortableError(new TopicAuthorizationException(unauthorizedTopics));\n            } else if (hasPartitionErrors) {\n                abortableError(new KafkaException(\"Could not add partitions to transaction due to errors: \" + errors));\n            } else {\n                log.debug(\"Successfully added partitions {} to transaction\", partitions);\n                partitionsInTransaction.addAll(partitions);\n                transactionStarted = true;\n                result.done();\n            }\n        }\n\n        @Override\n        public long retryBackoffMs() {\n            return Math.min(TransactionManager.this.retryBackoffMs, this.retryBackoffMs);\n        }\n\n        private void maybeOverrideRetryBackoffMs() {\n            // We only want to reduce the backoff when retrying the first AddPartition which errored out due to a\n            // CONCURRENT_TRANSACTIONS error since this means that the previous transaction is still completing and\n            // we don't want to wait too long before trying to start the new one.\n            //\n            // This is only a temporary fix, the long term solution is being tracked in\n            // https://issues.apache.org/jira/browse/KAFKA-5482\n            if (partitionsInTransaction.isEmpty())\n                this.retryBackoffMs = ADD_PARTITIONS_RETRY_BACKOFF_MS;\n        }\n    }\n\n    private class FindCoordinatorHandler extends TxnRequestHandler {\n        private final FindCoordinatorRequest.Builder builder;\n\n        private FindCoordinatorHandler(FindCoordinatorRequest.Builder builder) {\n            super(\"FindCoordinator\");\n            this.builder = builder;\n        }\n\n        @Override\n        FindCoordinatorRequest.Builder requestBuilder() {\n            return builder;\n        }\n\n        @Override\n        Priority priority() {\n            return Priority.FIND_COORDINATOR;\n        }\n\n        @Override\n        FindCoordinatorRequest.CoordinatorType coordinatorType() {\n            return null;\n        }\n\n        @Override\n        String coordinatorKey() {\n            return null;\n        }\n\n        @Override\n        public void handleResponse(AbstractResponse response) {\n            CoordinatorType coordinatorType = CoordinatorType.forId(builder.data().keyType());\n\n            List<Coordinator> coordinators = ((FindCoordinatorResponse) response).coordinators();\n            if (coordinators.size() != 1) {\n                log.error(\"Group coordinator lookup failed: Invalid response containing more than a single coordinator\");\n                fatalError(new IllegalStateException(\"Group coordinator lookup failed: Invalid response containing more than a single coordinator\"));\n            }\n            Coordinator coordinatorData = coordinators.get(0);\n            // For older versions without batching, obtain key from request data since it is not included in response\n            String key = coordinatorData.key() == null ? builder.data().key() : coordinatorData.key();",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java#L1561-L1710",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/TransactionManager.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 1561,
  "end_line": 1710,
  "last_modified": "2026-02-06T01:16:27.610496",
  "source_type": "github"
}