{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_producer_KafkaProducer.java_521",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java",
  "content": "        this.clientTelemetryReporter = clientTelemetryReporter;\n    }\n\n    // visible for testing\n    Sender newSender(LogContext logContext, KafkaClient kafkaClient, ProducerMetadata metadata) {\n        int maxInflightRequests = producerConfig.getInt(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION);\n        int requestTimeoutMs = producerConfig.getInt(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG);\n        ProducerMetrics metricsRegistry = new ProducerMetrics(this.metrics);\n        Sensor throttleTimeSensor = Sender.throttleTimeSensor(metricsRegistry.senderMetrics);\n        KafkaClient client = kafkaClient != null ? kafkaClient : ClientUtils.createNetworkClient(producerConfig,\n                this.metrics,\n                \"producer\",\n                logContext,\n                apiVersions,\n                time,\n                maxInflightRequests,\n                metadata,\n                throttleTimeSensor,\n                clientTelemetryReporter.map(ClientTelemetryReporter::telemetrySender).orElse(null));\n\n        short acks = Short.parseShort(producerConfig.getString(ProducerConfig.ACKS_CONFIG));\n        return new Sender(logContext,\n                client,\n                metadata,\n                this.accumulator,\n                maxInflightRequests == 1,\n                producerConfig.getInt(ProducerConfig.MAX_REQUEST_SIZE_CONFIG),\n                acks,\n                producerConfig.getInt(ProducerConfig.RETRIES_CONFIG),\n                metricsRegistry.senderMetrics,\n                time,\n                requestTimeoutMs,\n                producerConfig.getLong(ProducerConfig.RETRY_BACKOFF_MS_CONFIG),\n                this.transactionManager);\n    }\n\n    private static Compression configureCompression(ProducerConfig config) {\n        CompressionType type = CompressionType.forName(config.getString(ProducerConfig.COMPRESSION_TYPE_CONFIG));\n        switch (type) {\n            case GZIP: {\n                return Compression.gzip()\n                        .level(config.getInt(ProducerConfig.COMPRESSION_GZIP_LEVEL_CONFIG))\n                        .build();\n            }\n            case LZ4: {\n                return Compression.lz4()\n                        .level(config.getInt(ProducerConfig.COMPRESSION_LZ4_LEVEL_CONFIG))\n                        .build();\n            }\n            case ZSTD: {\n                return Compression.zstd()\n                        .level(config.getInt(ProducerConfig.COMPRESSION_ZSTD_LEVEL_CONFIG))\n                        .build();\n            }\n            default:\n                return Compression.of(type).build();\n        }\n    }\n\n    private static int lingerMs(ProducerConfig config) {\n        return (int) Math.min(config.getLong(ProducerConfig.LINGER_MS_CONFIG), Integer.MAX_VALUE);\n    }\n\n    private static int configureDeliveryTimeout(ProducerConfig config, Logger log) {\n        int deliveryTimeoutMs = config.getInt(ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG);\n        int lingerMs = lingerMs(config);\n        int requestTimeoutMs = config.getInt(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG);\n        int lingerAndRequestTimeoutMs = (int) Math.min((long) lingerMs + requestTimeoutMs, Integer.MAX_VALUE);\n\n        if (deliveryTimeoutMs < lingerAndRequestTimeoutMs) {\n            if (config.originals().containsKey(ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG)) {\n                // throw an exception if the user explicitly set an inconsistent value\n                throw new ConfigException(ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG\n                    + \" should be equal to or larger than \" + ProducerConfig.LINGER_MS_CONFIG\n                    + \" + \" + ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG);\n            } else {\n                // override deliveryTimeoutMs default value to lingerMs + requestTimeoutMs for backward compatibility\n                deliveryTimeoutMs = lingerAndRequestTimeoutMs;\n                log.warn(\"{} should be equal to or larger than {} + {}. Setting it to {}.\",\n                    ProducerConfig.DELIVERY_TIMEOUT_MS_CONFIG, ProducerConfig.LINGER_MS_CONFIG,\n                    ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, deliveryTimeoutMs);\n            }\n        }\n        return deliveryTimeoutMs;\n    }\n\n    private TransactionManager configureTransactionState(ProducerConfig config,\n                                                         LogContext logContext) {\n        TransactionManager transactionManager = null;\n\n        if (config.getBoolean(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG)) {\n            final String transactionalId = config.getString(ProducerConfig.TRANSACTIONAL_ID_CONFIG);\n            final boolean enable2PC = config.getBoolean(ProducerConfig.TRANSACTION_TWO_PHASE_COMMIT_ENABLE_CONFIG);\n            final int transactionTimeoutMs = config.getInt(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG);\n            final long retryBackoffMs = config.getLong(ProducerConfig.RETRY_BACKOFF_MS_CONFIG);\n            \n            transactionManager = new TransactionManager(\n                logContext,\n                transactionalId,\n                transactionTimeoutMs,\n                retryBackoffMs,\n                apiVersions,\n                enable2PC\n            );\n\n            if (transactionManager.isTransactional())\n                log.info(\"Instantiated a transactional producer.\");\n            else\n                log.info(\"Instantiated an idempotent producer.\");\n        } else {\n            // ignore unretrieved configurations related to producer transaction\n            config.ignore(ProducerConfig.TRANSACTION_TIMEOUT_CONFIG);\n        }\n        return transactionManager;\n    }\n\n    /**\n     * Initialize the transactional state for this producer, similar to {@link #initTransactions()} but\n     * with additional capabilities to keep a previously prepared transaction.\n     *\n     * Needs to be called before any other methods when the {@code transactional.id} is set in the configuration.\n     *\n     * When {@code keepPreparedTxn} is {@code false}, this behaves like the standard transactional\n     * initialization where the method does the following:\n     * <ol>\n     * <li>Ensures any transactions initiated by previous instances of the producer with the same\n     *      {@code transactional.id} are completed. If the previous instance had failed with a transaction in\n     *      progress, it will be aborted. If the last transaction had begun completion,\n     *      but not yet finished, this method awaits its completion.</li>\n     * <li>Gets the internal producer id and epoch, used in all future transactional\n     *      messages issued by the producer.</li>\n     * </ol>\n     *\n     * <p>\n     * When {@code keepPreparedTxn} is set to {@code true}, the producer does <em>not</em> automatically abort existing\n     * transactions. Instead, it enters a recovery mode allowing only finalization of those previously\n     * prepared transactions.\n     * This behavior is especially crucial for 2PC scenarios, where transactions should remain intact\n     * until the external transaction manager decides whether to commit or abort.\n     * <p>\n     *\n     * @param keepPreparedTxn true to retain any in-flight prepared transactions (necessary for 2PC\n     *                        recovery), false to abort existing transactions and behave like\n     *                        the standard initTransactions.\n     *\n     * Note that this method will raise {@link TimeoutException} if the transactional state cannot\n     * be initialized before expiration of {@code max.block.ms}. Additionally, it will raise {@link InterruptException}\n     * if interrupted. It is safe to retry in either case, but once the transactional state has been successfully\n     * initialized, this method should no longer be used.\n     *",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java#L521-L670",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 521,
  "end_line": 670,
  "last_modified": "2026-02-06T01:16:27.608270",
  "source_type": "github"
}