{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_FetchSessionHandler.java_131",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/FetchSessionHandler.java",
  "content": "                         Map<TopicPartition, PartitionData> sessionPartitions,\n                         FetchMetadata metadata,\n                         boolean canUseTopicIds) {\n            this.toSend = toSend;\n            this.toForget = toForget;\n            this.toReplace = toReplace;\n            this.sessionPartitions = sessionPartitions;\n            this.metadata = metadata;\n            this.canUseTopicIds = canUseTopicIds;\n        }\n\n        /**\n         * Get the set of partitions to send in this fetch request.\n         */\n        public Map<TopicPartition, PartitionData> toSend() {\n            return toSend;\n        }\n\n        /**\n         * Get a list of partitions to forget in this fetch request.\n         */\n        public List<TopicIdPartition> toForget() {\n            return toForget;\n        }\n\n        /**\n         * Get a list of partitions to forget in this fetch request.\n         */\n        public List<TopicIdPartition> toReplace() {\n            return toReplace;\n        }\n\n        /**\n         * Get the full set of partitions involved in this fetch request.\n         */\n        public Map<TopicPartition, PartitionData> sessionPartitions() {\n            return sessionPartitions;\n        }\n\n        public FetchMetadata metadata() {\n            return metadata;\n        }\n\n        public boolean canUseTopicIds() {\n            return canUseTopicIds;\n        }\n\n        @Override\n        public String toString() {\n            StringBuilder bld;\n            if (metadata.isFull()) {\n                bld = new StringBuilder(\"FullFetchRequest(toSend=(\");\n                String prefix = \"\";\n                for (TopicPartition partition : toSend.keySet()) {\n                    bld.append(prefix);\n                    bld.append(partition);\n                    prefix = \", \";\n                }\n            } else {\n                bld = new StringBuilder(\"IncrementalFetchRequest(toSend=(\");\n                String prefix = \"\";\n                for (TopicPartition partition : toSend.keySet()) {\n                    bld.append(prefix);\n                    bld.append(partition);\n                    prefix = \", \";\n                }\n                bld.append(\"), toForget=(\");\n                prefix = \"\";\n                for (TopicIdPartition partition : toForget) {\n                    bld.append(prefix);\n                    bld.append(partition);\n                    prefix = \", \";\n                }\n                bld.append(\"), toReplace=(\");\n                prefix = \"\";\n                for (TopicIdPartition partition : toReplace) {\n                    bld.append(prefix);\n                    bld.append(partition);\n                    prefix = \", \";\n                }\n                bld.append(\"), implied=(\");\n                prefix = \"\";\n                for (TopicPartition partition : sessionPartitions.keySet()) {\n                    if (!toSend.containsKey(partition)) {\n                        bld.append(prefix);\n                        bld.append(partition);\n                        prefix = \", \";\n                    }\n                }\n            }\n            if (canUseTopicIds) {\n                bld.append(\"), canUseTopicIds=True\");\n            } else {\n                bld.append(\"), canUseTopicIds=False\");\n            }\n            bld.append(\")\");\n            return bld.toString();\n        }\n    }\n\n    public class Builder {\n        private final Map<Uuid, String> topicNames;\n        private final boolean copySessionPartitions;\n        /**\n         * The next partitions which we want to fetch.\n         *\n         * It is important to maintain the insertion order of this list by using a LinkedHashMap rather\n         * than a regular Map.\n         *\n         * One reason is that when dealing with FULL fetch requests, if there is not enough response\n         * space to return data from all partitions, the server will only return data from partitions\n         * early in this list.\n         *\n         * Another reason is because we make use of the list ordering to optimize the preparation of\n         * incremental fetch requests (see below).\n         */\n        private LinkedHashMap<TopicPartition, PartitionData> next;\n        private int partitionsWithoutTopicIds = 0;\n\n        Builder() {\n            this.next = new LinkedHashMap<>();\n            this.topicNames = new HashMap<>();\n            this.copySessionPartitions = true;\n        }\n\n        Builder(int initialSize, boolean copySessionPartitions) {\n            this.next = new LinkedHashMap<>(initialSize);\n            this.topicNames = new HashMap<>();\n            this.copySessionPartitions = copySessionPartitions;\n        }\n\n        /**\n         * Mark that we want data from this partition in the upcoming fetch.\n         */\n        public void add(TopicPartition topicPartition, PartitionData data) {\n            next.put(topicPartition, data);\n            // topicIds should not change between adding partitions and building, so we can use putIfAbsent\n            if (data.topicId.equals(Uuid.ZERO_UUID)) {\n                partitionsWithoutTopicIds++;\n            } else {\n                topicNames.putIfAbsent(data.topicId, topicPartition.topic());\n            }\n        }\n\n        public FetchRequestData build() {\n            boolean canUseTopicIds = partitionsWithoutTopicIds == 0;\n\n            if (nextMetadata.isFull()) {\n                if (log.isDebugEnabled()) {\n                    log.debug(\"Built full fetch {} for node {} with {}.\",",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/FetchSessionHandler.java#L131-L280",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/FetchSessionHandler.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 131,
  "end_line": 280,
  "last_modified": "2026-02-06T01:16:27.577970",
  "source_type": "github"
}