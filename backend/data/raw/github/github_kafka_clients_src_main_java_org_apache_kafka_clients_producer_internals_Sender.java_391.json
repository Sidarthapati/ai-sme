{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_producer_internals_Sender.java_391",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java",
  "content": "                this.metadata.add(topic, now);\n\n            log.debug(\"Requesting metadata update due to unknown leader topics from the batched records: {}\",\n                result.unknownLeaderTopics);\n            this.metadata.requestUpdate(false);\n        }\n\n        // remove any nodes we aren't ready to send to\n        Iterator<Node> iter = result.readyNodes.iterator();\n        long notReadyTimeout = Long.MAX_VALUE;\n        while (iter.hasNext()) {\n            Node node = iter.next();\n            if (!this.client.ready(node, now)) {\n                // Update just the readyTimeMs of the latency stats, so that it moves forward\n                // every time the batch is ready (then the difference between readyTimeMs and\n                // drainTimeMs would represent how long data is waiting for the node).\n                this.accumulator.updateNodeLatencyStats(node.id(), now, false);\n                iter.remove();\n                notReadyTimeout = Math.min(notReadyTimeout, this.client.pollDelayMs(node, now));\n            } else {\n                // Update both readyTimeMs and drainTimeMs, this would \"reset\" the node\n                // latency.\n                this.accumulator.updateNodeLatencyStats(node.id(), now, true);\n            }\n        }\n\n        // create produce requests\n        Map<Integer, List<ProducerBatch>> batches = this.accumulator.drain(metadataSnapshot, result.readyNodes, this.maxRequestSize, now);\n        addToInflightBatches(batches);\n        if (guaranteeMessageOrder) {\n            // Mute all the partitions drained\n            for (List<ProducerBatch> batchList : batches.values()) {\n                for (ProducerBatch batch : batchList)\n                    this.accumulator.mutePartition(batch.topicPartition);\n            }\n        }\n\n        accumulator.resetNextBatchExpiryTime();\n        List<ProducerBatch> expiredInflightBatches = getExpiredInflightBatches(now);\n        List<ProducerBatch> expiredBatches = this.accumulator.expiredBatches(now);\n\n        failExpiredBatches(expiredBatches, now, true);\n        failExpiredBatches(expiredInflightBatches, now, false);\n\n        sensors.updateProduceRequestMetrics(batches);\n\n        // If we have any nodes that are ready to send + have sendable data, poll with 0 timeout so this can immediately\n        // loop and try sending more data. Otherwise, the timeout will be the smaller value between next batch expiry\n        // time, and the delay time for checking data availability. Note that the nodes may have data that isn't yet\n        // sendable due to lingering, backing off, etc. This specifically does not include nodes with sendable data\n        // that aren't ready to send since they would cause busy looping.\n        long pollTimeout = Math.min(result.nextReadyCheckDelayMs, notReadyTimeout);\n        pollTimeout = Math.min(pollTimeout, this.accumulator.nextExpiryTimeMs() - now);\n        pollTimeout = Math.max(pollTimeout, 0);\n        if (!result.readyNodes.isEmpty()) {\n            log.trace(\"Nodes with data ready to send: {}\", result.readyNodes);\n            // if some partitions are already ready to be sent, the select time would be 0;\n            // otherwise if some partition already has some data accumulated but not ready yet,\n            // the select time will be the time difference between now and its linger expiry time;\n            // otherwise the select time will be the time difference between now and the metadata expiry time;\n            pollTimeout = 0;\n        }\n        sendProduceRequests(batches, now);\n        return pollTimeout;\n    }\n\n    /**\n     * Returns true if a transactional request is sent or polled, or if a FindCoordinator request is enqueued\n     */\n    private boolean maybeSendAndPollTransactionalRequest() {\n        if (transactionManager.hasInFlightRequest()) {\n            // as long as there are outstanding transactional requests, we simply wait for them to return\n            client.poll(retryBackoffMs, time.milliseconds());\n            return true;\n        }\n\n        if (transactionManager.hasAbortableError()) {\n            accumulator.abortUndrainedBatches(transactionManager.lastError());\n        } else if (transactionManager.isAborting()) {\n            accumulator.abortUndrainedBatches(new TransactionAbortedException());\n        }\n\n        TransactionManager.TxnRequestHandler nextRequestHandler = transactionManager.nextRequest(accumulator.hasIncomplete());\n        if (nextRequestHandler == null)\n            return false;\n\n        AbstractRequest.Builder<?> requestBuilder = nextRequestHandler.requestBuilder();\n        Node targetNode = null;\n        try {\n            FindCoordinatorRequest.CoordinatorType coordinatorType = nextRequestHandler.coordinatorType();\n            targetNode = coordinatorType != null ?\n                    transactionManager.coordinator(coordinatorType) :\n                    client.leastLoadedNode(time.milliseconds()).node();\n            if (targetNode != null) {\n                if (!awaitNodeReady(targetNode, coordinatorType)) {\n                    log.trace(\"Target node {} not ready within request timeout, will retry when node is ready.\", targetNode);\n                    maybeFindCoordinatorAndRetry(nextRequestHandler);\n                    return true;\n                }\n            } else if (coordinatorType != null) {\n                log.trace(\"Coordinator not known for {}, will retry {} after finding coordinator.\", coordinatorType, requestBuilder.apiKey());\n                maybeFindCoordinatorAndRetry(nextRequestHandler);\n                return true;\n            } else {\n                log.trace(\"No nodes available to send requests, will poll and retry when until a node is ready.\");\n                transactionManager.retry(nextRequestHandler);\n                client.poll(retryBackoffMs, time.milliseconds());\n                return true;\n            }\n\n            if (nextRequestHandler.isRetry())\n                time.sleep(nextRequestHandler.retryBackoffMs());\n\n            long currentTimeMs = time.milliseconds();\n            ClientRequest clientRequest = client.newClientRequest(targetNode.idString(), requestBuilder, currentTimeMs,\n                true, requestTimeoutMs, nextRequestHandler);\n            log.debug(\"Sending transactional request {} to node {} with correlation ID {}\", requestBuilder, targetNode, clientRequest.correlationId());\n            client.send(clientRequest, currentTimeMs);\n            transactionManager.setInFlightCorrelationId(clientRequest.correlationId());\n            client.poll(retryBackoffMs, time.milliseconds());\n            return true;\n        } catch (IOException e) {\n            log.debug(\"Disconnect from {} while trying to send request {}. Going \" +\n                    \"to back off and retry.\", targetNode, requestBuilder, e);\n            // We break here so that we pick up the FindCoordinator request immediately.\n            maybeFindCoordinatorAndRetry(nextRequestHandler);\n            return true;\n        }\n    }\n\n    private void maybeFindCoordinatorAndRetry(TransactionManager.TxnRequestHandler nextRequestHandler) {\n        if (nextRequestHandler.needsCoordinator()) {\n            transactionManager.lookupCoordinator(nextRequestHandler);\n        } else {\n            // For non-coordinator requests, sleep here to prevent a tight loop when no node is available\n            time.sleep(retryBackoffMs);\n            metadata.requestUpdate(false);\n        }\n\n        transactionManager.retry(nextRequestHandler);\n    }\n\n    private void maybeAbortBatches(RuntimeException exception) {\n        if (accumulator.hasIncomplete()) {\n            log.error(\"Aborting producer batches due to fatal error\", exception);\n            accumulator.abortBatches(exception);\n            inFlightBatches.clear();\n        }\n    }\n",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java#L391-L540",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 391,
  "end_line": 540,
  "last_modified": "2026-02-06T01:16:27.610196",
  "source_type": "github"
}