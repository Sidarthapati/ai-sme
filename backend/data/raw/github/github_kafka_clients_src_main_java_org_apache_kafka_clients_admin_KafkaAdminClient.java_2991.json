{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_admin_KafkaAdminClient.java_2991",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java",
  "content": "                        throwable);\n                }\n            }, now);\n        }\n\n        return new AlterReplicaLogDirsResult(new HashMap<>(futures));\n    }\n\n    @Override\n    public DescribeLogDirsResult describeLogDirs(Collection<Integer> brokers, DescribeLogDirsOptions options) {\n        final Map<Integer, KafkaFutureImpl<Map<String, LogDirDescription>>> futures = new HashMap<>(brokers.size());\n\n        final long now = time.milliseconds();\n        for (final Integer brokerId : brokers) {\n            KafkaFutureImpl<Map<String, LogDirDescription>> future = new KafkaFutureImpl<>();\n            futures.put(brokerId, future);\n\n            runnable.call(new Call(\"describeLogDirs\", calcDeadlineMs(now, options.timeoutMs()),\n                new ConstantNodeIdProvider(brokerId)) {\n\n                @Override\n                public DescribeLogDirsRequest.Builder createRequest(int timeoutMs) {\n                    // Query selected partitions in all log directories\n                    return new DescribeLogDirsRequest.Builder(new DescribeLogDirsRequestData().setTopics(null));\n                }\n\n                @Override\n                public void handleResponse(AbstractResponse abstractResponse) {\n                    DescribeLogDirsResponse response = (DescribeLogDirsResponse) abstractResponse;\n                    Map<String, LogDirDescription> descriptions = logDirDescriptions(response);\n                    if (!descriptions.isEmpty()) {\n                        future.complete(descriptions);\n                    } else {\n                        // Up to v3 DescribeLogDirsResponse did not have an error code field, hence it defaults to None\n                        Errors error = response.data().errorCode() == Errors.NONE.code()\n                            ? Errors.CLUSTER_AUTHORIZATION_FAILED\n                            : Errors.forCode(response.data().errorCode());\n                        future.completeExceptionally(error.exception());\n                    }\n                }\n\n                @Override\n                void handleFailure(Throwable throwable) {\n                    future.completeExceptionally(throwable);\n                }\n            }, now);\n        }\n\n        return new DescribeLogDirsResult(new HashMap<>(futures));\n    }\n\n    private static Map<String, LogDirDescription> logDirDescriptions(DescribeLogDirsResponse response) {\n        Map<String, LogDirDescription> result = new HashMap<>(response.data().results().size());\n        for (DescribeLogDirsResponseData.DescribeLogDirsResult logDirResult : response.data().results()) {\n            Map<TopicPartition, ReplicaInfo> replicaInfoMap = new HashMap<>();\n            for (DescribeLogDirsResponseData.DescribeLogDirsTopic t : logDirResult.topics()) {\n                for (DescribeLogDirsResponseData.DescribeLogDirsPartition p : t.partitions()) {\n                    replicaInfoMap.put(\n                        new TopicPartition(t.name(), p.partitionIndex()),\n                        new ReplicaInfo(p.partitionSize(), p.offsetLag(), p.isFutureKey()));\n                }\n            }\n            result.put(logDirResult.logDir(), new LogDirDescription(\n                Errors.forCode(logDirResult.errorCode()).exception(),\n                replicaInfoMap,\n                logDirResult.totalBytes(),\n                logDirResult.usableBytes()));\n        }\n        return result;\n    }\n\n    @Override\n    public DescribeReplicaLogDirsResult describeReplicaLogDirs(Collection<TopicPartitionReplica> replicas, DescribeReplicaLogDirsOptions options) {\n        final Map<TopicPartitionReplica, KafkaFutureImpl<DescribeReplicaLogDirsResult.ReplicaLogDirInfo>> futures = new HashMap<>(replicas.size());\n\n        for (TopicPartitionReplica replica : replicas) {\n            futures.put(replica, new KafkaFutureImpl<>());\n        }\n\n        Map<Integer, DescribeLogDirsRequestData> partitionsByBroker = new HashMap<>();\n\n        for (TopicPartitionReplica replica : replicas) {\n            DescribeLogDirsRequestData requestData = partitionsByBroker.computeIfAbsent(replica.brokerId(),\n                brokerId -> new DescribeLogDirsRequestData());\n            DescribableLogDirTopic describableLogDirTopic = requestData.topics().find(replica.topic());\n            if (describableLogDirTopic == null) {\n                List<Integer> partitions = new ArrayList<>();\n                partitions.add(replica.partition());\n                describableLogDirTopic = new DescribableLogDirTopic().setTopic(replica.topic())\n                    .setPartitions(partitions);\n                requestData.topics().add(describableLogDirTopic);\n            } else {\n                describableLogDirTopic.partitions().add(replica.partition());\n            }\n        }\n\n        final long now = time.milliseconds();\n        for (Map.Entry<Integer, DescribeLogDirsRequestData> entry : partitionsByBroker.entrySet()) {\n            final int brokerId = entry.getKey();\n            final DescribeLogDirsRequestData topicPartitions = entry.getValue();\n            final Map<TopicPartition, ReplicaLogDirInfo> replicaDirInfoByPartition = new HashMap<>();\n            for (DescribableLogDirTopic topicPartition : topicPartitions.topics()) {\n                for (Integer partitionId : topicPartition.partitions()) {\n                    replicaDirInfoByPartition.put(new TopicPartition(topicPartition.topic(), partitionId), new ReplicaLogDirInfo());\n                }\n            }\n\n            runnable.call(new Call(\"describeReplicaLogDirs\", calcDeadlineMs(now, options.timeoutMs()),\n                new ConstantNodeIdProvider(brokerId)) {\n\n                @Override\n                public DescribeLogDirsRequest.Builder createRequest(int timeoutMs) {\n                    // Query selected partitions in all log directories\n                    return new DescribeLogDirsRequest.Builder(topicPartitions);\n                }\n\n                @Override\n                public void handleResponse(AbstractResponse abstractResponse) {\n                    DescribeLogDirsResponse response = (DescribeLogDirsResponse) abstractResponse;\n                    for (Map.Entry<String, LogDirDescription> responseEntry : logDirDescriptions(response).entrySet()) {\n                        String logDir = responseEntry.getKey();\n                        LogDirDescription logDirInfo = responseEntry.getValue();\n\n                        // No replica info will be provided if the log directory is offline\n                        if (logDirInfo.error() instanceof KafkaStorageException)\n                            continue;\n                        if (logDirInfo.error() != null)\n                            handleFailure(new IllegalStateException(\n                                \"The error \" + logDirInfo.error().getClass().getName() + \" for log directory \" + logDir + \" in the response from broker \" + brokerId + \" is illegal\"));\n\n                        for (Map.Entry<TopicPartition, ReplicaInfo> replicaInfoEntry : logDirInfo.replicaInfos().entrySet()) {\n                            TopicPartition tp = replicaInfoEntry.getKey();\n                            ReplicaInfo replicaInfo = replicaInfoEntry.getValue();\n                            ReplicaLogDirInfo replicaLogDirInfo = replicaDirInfoByPartition.get(tp);\n                            if (replicaLogDirInfo == null) {\n                                log.warn(\"Server response from broker {} mentioned unknown partition {}\", brokerId, tp);\n                            } else if (replicaInfo.isFuture()) {\n                                replicaDirInfoByPartition.put(tp, new ReplicaLogDirInfo(replicaLogDirInfo.getCurrentReplicaLogDir(),\n                                    replicaLogDirInfo.getCurrentReplicaOffsetLag(),\n                                    logDir,\n                                    replicaInfo.offsetLag()));\n                            } else {\n                                replicaDirInfoByPartition.put(tp, new ReplicaLogDirInfo(logDir,\n                                    replicaInfo.offsetLag(),\n                                    replicaLogDirInfo.getFutureReplicaLogDir(),\n                                    replicaLogDirInfo.getFutureReplicaOffsetLag()));\n                            }\n                        }\n                    }\n",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java#L2991-L3140",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 2991,
  "end_line": 3140,
  "last_modified": "2026-02-06T01:16:27.585045",
  "source_type": "github"
}