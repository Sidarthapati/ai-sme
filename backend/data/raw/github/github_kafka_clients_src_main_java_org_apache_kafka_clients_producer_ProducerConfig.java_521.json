{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_producer_ProducerConfig.java_521",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/producer/ProducerConfig.java",
  "content": "                                        Type.STRING,\n                                        null,\n                                        Importance.LOW,\n                                        SECURITY_PROVIDERS_DOC)\n                                .withClientSslSupport()\n                                .withClientSaslSupport()\n                                .define(ENABLE_IDEMPOTENCE_CONFIG,\n                                        Type.BOOLEAN,\n                                        true,\n                                        Importance.LOW,\n                                        ENABLE_IDEMPOTENCE_DOC)\n                                .define(TRANSACTION_TIMEOUT_CONFIG,\n                                        Type.INT,\n                                        60000,\n                                        Importance.LOW,\n                                        TRANSACTION_TIMEOUT_DOC)\n                                .define(TRANSACTIONAL_ID_CONFIG,\n                                        Type.STRING,\n                                        null,\n                                        new ConfigDef.NonEmptyString(),\n                                        Importance.LOW,\n                                        TRANSACTIONAL_ID_DOC)\n                                .define(TRANSACTION_TWO_PHASE_COMMIT_ENABLE_CONFIG,\n                                        Type.BOOLEAN,\n                                        false,\n                                        Importance.LOW,\n                                        TRANSACTION_TWO_PHASE_COMMIT_ENABLE_DOC)\n                                .define(CommonClientConfigs.METADATA_RECOVERY_STRATEGY_CONFIG,\n                                        Type.STRING,\n                                        CommonClientConfigs.DEFAULT_METADATA_RECOVERY_STRATEGY,\n                                        ConfigDef.CaseInsensitiveValidString\n                                                .in(Utils.enumOptions(MetadataRecoveryStrategy.class)),\n                                        Importance.LOW,\n                                        CommonClientConfigs.METADATA_RECOVERY_STRATEGY_DOC)\n                                .define(CommonClientConfigs.METADATA_RECOVERY_REBOOTSTRAP_TRIGGER_MS_CONFIG,\n                                        Type.LONG,\n                                        CommonClientConfigs.DEFAULT_METADATA_RECOVERY_REBOOTSTRAP_TRIGGER_MS,\n                                        atLeast(0),\n                                        Importance.LOW,\n                                        CommonClientConfigs.METADATA_RECOVERY_REBOOTSTRAP_TRIGGER_MS_DOC)\n                                .define(CONFIG_PROVIDERS_CONFIG,\n                                        ConfigDef.Type.LIST,\n                                        List.of(),\n                                        ConfigDef.ValidList.anyNonDuplicateValues(true, false),\n                                        ConfigDef.Importance.LOW,\n                                        CONFIG_PROVIDERS_DOC);\n    }\n\n    @Override\n    protected Map<String, Object> postProcessParsedConfig(final Map<String, Object> parsedValues) {\n        CommonClientConfigs.postValidateSaslMechanismConfig(this);\n        CommonClientConfigs.warnDisablingExponentialBackoff(this);\n        Map<String, Object> refinedConfigs = CommonClientConfigs.postProcessReconnectBackoffConfigs(this, parsedValues);\n        postProcessAndValidateIdempotenceConfigs(refinedConfigs);\n        maybeOverrideClientId(refinedConfigs);\n        return refinedConfigs;\n    }\n\n    private void maybeOverrideClientId(final Map<String, Object> configs) {\n        String refinedClientId;\n        boolean userConfiguredClientId = this.originals().containsKey(CLIENT_ID_CONFIG);\n        if (userConfiguredClientId) {\n            refinedClientId = this.getString(CLIENT_ID_CONFIG);\n        } else {\n            String transactionalId = this.getString(TRANSACTIONAL_ID_CONFIG);\n            refinedClientId = \"producer-\" + (transactionalId != null ? transactionalId : PRODUCER_CLIENT_ID_SEQUENCE.getAndIncrement());\n        }\n        configs.put(CLIENT_ID_CONFIG, refinedClientId);\n    }\n\n    private void postProcessAndValidateIdempotenceConfigs(final Map<String, Object> configs) {\n        final Map<String, Object> originalConfigs = this.originals();\n        final String acksStr = parseAcks(this.getString(ACKS_CONFIG));\n        configs.put(ACKS_CONFIG, acksStr);\n        final boolean userConfiguredIdempotence = this.originals().containsKey(ENABLE_IDEMPOTENCE_CONFIG);\n        boolean idempotenceEnabled = this.getBoolean(ENABLE_IDEMPOTENCE_CONFIG);\n        boolean shouldDisableIdempotence = false;\n\n        // For idempotence producers, values for `retries` and `acks` and `max.in.flight.requests.per.connection` need validation\n        if (idempotenceEnabled) {\n            final int retries = this.getInt(RETRIES_CONFIG);\n            if (retries == 0) {\n                if (userConfiguredIdempotence) {\n                    throw new ConfigException(\"Must set \" + RETRIES_CONFIG + \" to non-zero when using the idempotent producer.\");\n                }\n                log.info(\"Idempotence will be disabled because {} is set to 0.\", RETRIES_CONFIG);\n                shouldDisableIdempotence = true;\n            }\n\n            final short acks = Short.parseShort(acksStr);\n            if (acks != (short) -1) {\n                if (userConfiguredIdempotence) {\n                    throw new ConfigException(\"Must set \" + ACKS_CONFIG + \" to all in order to use the idempotent \" +\n                        \"producer. Otherwise we cannot guarantee idempotence.\");\n                }\n                log.info(\"Idempotence will be disabled because {} is set to {}, not set to 'all'.\", ACKS_CONFIG, acks);\n                shouldDisableIdempotence = true;\n            }\n\n            final int inFlightConnection = this.getInt(MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION);\n            if (MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION_FOR_IDEMPOTENCE < inFlightConnection) {\n                throw new ConfigException(\"To use the idempotent producer, \" + MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION +\n                                          \" must be set to at most 5. Current value is \" + inFlightConnection + \".\");\n            }\n        }\n\n        if (shouldDisableIdempotence) {\n            configs.put(ENABLE_IDEMPOTENCE_CONFIG, false);\n            idempotenceEnabled = false;\n        }\n\n        // validate `transaction.id` after validating idempotence dependant configs because `enable.idempotence` config might be overridden\n        boolean userConfiguredTransactions = originalConfigs.containsKey(TRANSACTIONAL_ID_CONFIG);\n        if (!idempotenceEnabled && userConfiguredTransactions) {\n            throw new ConfigException(\"Cannot set a \" + ProducerConfig.TRANSACTIONAL_ID_CONFIG + \" without also enabling idempotence.\");\n        }\n\n        // Validate that transaction.timeout.ms is not set when transaction.two.phase.commit.enable is true\n        // In standard Kafka transactions, the broker enforces transaction.timeout.ms and aborts any\n        // transaction that isn't completed in time. With two-phase commit (2PC), an external coordinator\n        // decides when to finalize, so broker-side timeouts don't apply. Disallow using both.\n        boolean enable2PC = this.getBoolean(TRANSACTION_TWO_PHASE_COMMIT_ENABLE_CONFIG);\n        boolean userConfiguredTransactionTimeout = originalConfigs.containsKey(TRANSACTION_TIMEOUT_CONFIG);\n        if (enable2PC && userConfiguredTransactionTimeout) {\n            throw new ConfigException(\n                \"Cannot set \" + ProducerConfig.TRANSACTION_TIMEOUT_CONFIG +\n                \" when \" + ProducerConfig.TRANSACTION_TWO_PHASE_COMMIT_ENABLE_CONFIG +\n                \" is set to true. Transactions will not expire with two-phase commit enabled.\"\n            );\n        }\n    }\n\n    private static String parseAcks(String acksString) {\n        try {\n            return acksString.trim().equalsIgnoreCase(\"all\") ? \"-1\" : Short.parseShort(acksString.trim()) + \"\";\n        } catch (NumberFormatException e) {\n            throw new ConfigException(\"Invalid configuration value for 'acks': \" + acksString);\n        }\n    }\n\n    static Map<String, Object> appendSerializerToConfig(Map<String, Object> configs,\n            Serializer<?> keySerializer,\n            Serializer<?> valueSerializer) {\n        // validate serializer configuration, if the passed serializer instance is null, the user must explicitly set a valid serializer configuration value\n        Map<String, Object> newConfigs = new HashMap<>(configs);\n        if (keySerializer != null)\n            newConfigs.put(KEY_SERIALIZER_CLASS_CONFIG, keySerializer.getClass());\n        else if (newConfigs.get(KEY_SERIALIZER_CLASS_CONFIG) == null)\n            throw new ConfigException(KEY_SERIALIZER_CLASS_CONFIG, null, \"must be non-null.\");\n        if (valueSerializer != null)",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/ProducerConfig.java#L521-L670",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/producer/ProducerConfig.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 521,
  "end_line": 670,
  "last_modified": "2026-02-06T01:16:27.608681",
  "source_type": "github"
}