{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_producer_KafkaProducer.java_261",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java",
  "content": "            \"AbortTransaction timed out - did not complete EndTxn(abort) with the transaction coordinator within max.block.ms\";\n    \n    private final String clientId;\n    // Visible for testing\n    final Metrics metrics;\n    private final KafkaProducerMetrics producerMetrics;\n    private final Plugin<Partitioner> partitionerPlugin;\n    private final int maxRequestSize;\n    private final long totalMemorySize;\n    private final ProducerMetadata metadata;\n    private final RecordAccumulator accumulator;\n    private final Sender sender;\n    private final Sender.SenderThread ioThread;\n    private final Compression compression;\n    private final Sensor errors;\n    private final Time time;\n    private final Plugin<Serializer<K>> keySerializerPlugin;\n    private final Plugin<Serializer<V>> valueSerializerPlugin;\n    private final ProducerConfig producerConfig;\n    private final long maxBlockTimeMs;\n    private final boolean partitionerIgnoreKeys;\n    private final ProducerInterceptors<K, V> interceptors;\n    private final ApiVersions apiVersions;\n    private final TransactionManager transactionManager;\n    // Init value is needed to avoid NPE in case of exception raised in the constructor\n    private Optional<ClientTelemetryReporter> clientTelemetryReporter = Optional.empty();\n\n    /**\n     * A producer is instantiated by providing a set of key-value pairs as configuration. Valid configuration strings\n     * are documented <a href=\"http://kafka.apache.org/documentation.html#producerconfigs\">here</a>. Values can be\n     * either strings or Objects of the appropriate type (for example a numeric configuration would accept either the\n     * string \"42\" or the integer 42).\n     * <p>\n     * Note: after creating a {@code KafkaProducer} you must always {@link #close()} it to avoid resource leaks.\n     * @param configs   The producer configs\n     *\n     */\n    public KafkaProducer(final Map<String, Object> configs) {\n        this(configs, null, null);\n    }\n\n    /**\n     * A producer is instantiated by providing a set of key-value pairs as configuration, a key and a value {@link Serializer}.\n     * Valid configuration strings are documented <a href=\"http://kafka.apache.org/documentation.html#producerconfigs\">here</a>.\n     * Values can be either strings or Objects of the appropriate type (for example a numeric configuration would accept\n     * either the string \"42\" or the integer 42).\n     * <p>\n     * Note: after creating a {@code KafkaProducer} you must always {@link #close()} it to avoid resource leaks.\n     * @param configs   The producer configs\n     * @param keySerializer  The serializer for key that implements {@link Serializer}. The configure() method won't be\n     *                       called in the producer when the serializer is passed in directly.\n     * @param valueSerializer  The serializer for value that implements {@link Serializer}. The configure() method won't\n     *                         be called in the producer when the serializer is passed in directly.\n     */\n    public KafkaProducer(Map<String, Object> configs, Serializer<K> keySerializer, Serializer<V> valueSerializer) {\n        this(new ProducerConfig(ProducerConfig.appendSerializerToConfig(configs, keySerializer, valueSerializer)),\n                keySerializer, valueSerializer, null, null, null, new ApiVersions(), Time.SYSTEM);\n    }\n\n    /**\n     * A producer is instantiated by providing a set of key-value pairs as configuration. Valid configuration strings\n     * are documented <a href=\"http://kafka.apache.org/documentation.html#producerconfigs\">here</a>.\n     * <p>\n     * Note: after creating a {@code KafkaProducer} you must always {@link #close()} it to avoid resource leaks.\n     * @param properties   The producer configs\n     */\n    public KafkaProducer(Properties properties) {\n        this(properties, null, null);\n    }\n\n    /**\n     * A producer is instantiated by providing a set of key-value pairs as configuration, a key and a value {@link Serializer}.\n     * Valid configuration strings are documented <a href=\"http://kafka.apache.org/documentation.html#producerconfigs\">here</a>.\n     * <p>\n     * Note: after creating a {@code KafkaProducer} you must always {@link #close()} it to avoid resource leaks.\n     * @param properties   The producer configs\n     * @param keySerializer  The serializer for key that implements {@link Serializer}. The configure() method won't be\n     *                       called in the producer when the serializer is passed in directly.\n     * @param valueSerializer  The serializer for value that implements {@link Serializer}. The configure() method won't\n     *                         be called in the producer when the serializer is passed in directly.\n     */\n    public KafkaProducer(Properties properties, Serializer<K> keySerializer, Serializer<V> valueSerializer) {\n        this(Utils.propsToMap(properties), keySerializer, valueSerializer);\n    }\n\n    // visible for testing\n    @SuppressWarnings({\"unchecked\", \"this-escape\"})\n    KafkaProducer(ProducerConfig config,\n                  Serializer<K> keySerializer,\n                  Serializer<V> valueSerializer,\n                  ProducerMetadata metadata,\n                  KafkaClient kafkaClient,\n                  ProducerInterceptors<K, V> interceptors,\n                  ApiVersions apiVersions,\n                  Time time) {\n        try {\n            this.producerConfig = config;\n            this.time = time;\n\n            String transactionalId = config.getString(ProducerConfig.TRANSACTIONAL_ID_CONFIG);\n\n            this.clientId = config.getString(ProducerConfig.CLIENT_ID_CONFIG);\n\n            LogContext logContext;\n            if (transactionalId == null)\n                logContext = new LogContext(String.format(\"[Producer clientId=%s] \", clientId));\n            else\n                logContext = new LogContext(String.format(\"[Producer clientId=%s, transactionalId=%s] \", clientId, transactionalId));\n            log = logContext.logger(KafkaProducer.class);\n            log.trace(\"Starting the Kafka producer\");\n\n            Map<String, String> metricTags = Collections.singletonMap(\"client-id\", clientId);\n            MetricConfig metricConfig = new MetricConfig().samples(config.getInt(ProducerConfig.METRICS_NUM_SAMPLES_CONFIG))\n                    .timeWindow(config.getLong(ProducerConfig.METRICS_SAMPLE_WINDOW_MS_CONFIG), TimeUnit.MILLISECONDS)\n                    .recordLevel(Sensor.RecordingLevel.forName(config.getString(ProducerConfig.METRICS_RECORDING_LEVEL_CONFIG)))\n                    .tags(metricTags);\n            List<MetricsReporter> reporters = CommonClientConfigs.metricsReporters(clientId, config);\n            this.clientTelemetryReporter = CommonClientConfigs.telemetryReporter(clientId, config);\n            this.clientTelemetryReporter.ifPresent(reporters::add);\n            MetricsContext metricsContext = new KafkaMetricsContext(JMX_PREFIX,\n                    config.originalsWithPrefix(CommonClientConfigs.METRICS_CONTEXT_PREFIX));\n            this.metrics = new Metrics(metricConfig, reporters, time, metricsContext);\n            this.producerMetrics = new KafkaProducerMetrics(metrics);\n            this.partitionerPlugin = Plugin.wrapInstance(\n                    config.getConfiguredInstance(\n                        ProducerConfig.PARTITIONER_CLASS_CONFIG,\n                        Partitioner.class,\n                        Collections.singletonMap(ProducerConfig.CLIENT_ID_CONFIG, clientId)),\n                    metrics,\n                    ProducerConfig.PARTITIONER_CLASS_CONFIG);\n            this.partitionerIgnoreKeys = config.getBoolean(ProducerConfig.PARTITIONER_IGNORE_KEYS_CONFIG);\n            long retryBackoffMs = config.getLong(ProducerConfig.RETRY_BACKOFF_MS_CONFIG);\n            long retryBackoffMaxMs = config.getLong(ProducerConfig.RETRY_BACKOFF_MAX_MS_CONFIG);\n            if (keySerializer == null) {\n                keySerializer = config.getConfiguredInstance(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, Serializer.class);\n                keySerializer.configure(config.originals(Collections.singletonMap(ProducerConfig.CLIENT_ID_CONFIG, clientId)), true);\n            } else {\n                config.ignore(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);\n            }\n            this.keySerializerPlugin = Plugin.wrapInstance(keySerializer, metrics, ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);\n\n            if (valueSerializer == null) {\n                valueSerializer = config.getConfiguredInstance(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, Serializer.class);\n                valueSerializer.configure(config.originals(Collections.singletonMap(ProducerConfig.CLIENT_ID_CONFIG, clientId)), false);\n            } else {\n                config.ignore(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG);\n            }\n            this.valueSerializerPlugin = Plugin.wrapInstance(valueSerializer, metrics, ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG);\n\n",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java#L261-L410",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 261,
  "end_line": 410,
  "last_modified": "2026-02-06T01:16:27.608270",
  "source_type": "github"
}