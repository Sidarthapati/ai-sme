{
  "id": "kafka_clients_src_main_java_org_apache_kafka_clients_admin_KafkaAdminClient.java_2081",
  "title": "kafka/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java",
  "content": "                        topic -> \"The controller response did not contain a result for topic \" + topic);\n                } else {\n                    final long now = time.milliseconds();\n                    final Call call = getDeleteTopicsWithIdsCall(options, futures, retryTopics,\n                        retryTopicQuotaExceededExceptions, now, deadline);\n                    runnable.call(call, now);\n                }\n            }\n\n            @Override\n            void handleFailure(Throwable throwable) {\n                // If there were any topics retries due to a quota exceeded exception, we propagate\n                // the initial error back to the caller if the request timed out.\n                maybeCompleteQuotaExceededException(options.shouldRetryOnQuotaViolation(),\n                    throwable, futures, quotaExceededExceptions, (int) (time.milliseconds() - now));\n                // Fail all the other remaining futures\n                completeAllExceptionally(futures.values(), throwable);\n            }\n        };\n    }\n\n    @Override\n    public ListTopicsResult listTopics(final ListTopicsOptions options) {\n        final KafkaFutureImpl<Map<String, TopicListing>> topicListingFuture = new KafkaFutureImpl<>();\n        final long now = time.milliseconds();\n        runnable.call(new Call(\"listTopics\", calcDeadlineMs(now, options.timeoutMs()),\n            new LeastLoadedNodeProvider()) {\n\n            @Override\n            MetadataRequest.Builder createRequest(int timeoutMs) {\n                return MetadataRequest.Builder.allTopics();\n            }\n\n            @Override\n            void handleResponse(AbstractResponse abstractResponse) {\n                MetadataResponse response = (MetadataResponse) abstractResponse;\n                Map<String, TopicListing> topicListing = new HashMap<>();\n                for (MetadataResponse.TopicMetadata topicMetadata : response.topicMetadata()) {\n                    String topicName = topicMetadata.topic();\n                    boolean isInternal = topicMetadata.isInternal();\n                    if (!topicMetadata.isInternal() || options.shouldListInternal())\n                        topicListing.put(topicName, new TopicListing(topicName, topicMetadata.topicId(), isInternal));\n                }\n                topicListingFuture.complete(topicListing);\n            }\n\n            @Override\n            void handleFailure(Throwable throwable) {\n                topicListingFuture.completeExceptionally(throwable);\n            }\n        }, now);\n        return new ListTopicsResult(topicListingFuture);\n    }\n\n    @Override\n    public DescribeTopicsResult describeTopics(final TopicCollection topics, DescribeTopicsOptions options) {\n        if (topics instanceof TopicIdCollection)\n            return DescribeTopicsResult.ofTopicIds(handleDescribeTopicsByIds(((TopicIdCollection) topics).topicIds(), options));\n        else if (topics instanceof TopicNameCollection)\n            return DescribeTopicsResult.ofTopicNames(handleDescribeTopicsByNamesWithDescribeTopicPartitionsApi(((TopicNameCollection) topics).topicNames(), options));\n        else\n            throw new IllegalArgumentException(\"The TopicCollection: \" + topics + \" provided did not match any supported classes for describeTopics.\");\n    }\n\n    private Call generateDescribeTopicsCallWithMetadataApi(\n        List<String> topicNamesList,\n        Map<String, KafkaFutureImpl<TopicDescription>> topicFutures,\n        DescribeTopicsOptions options,\n        long now\n    ) {\n        return new Call(\"describeTopics\", calcDeadlineMs(now, options.timeoutMs()),\n            new LeastLoadedNodeProvider()) {\n\n            private boolean supportsDisablingTopicCreation = true;\n\n            @Override\n            MetadataRequest.Builder createRequest(int timeoutMs) {\n                if (supportsDisablingTopicCreation)\n                    return new MetadataRequest.Builder(new MetadataRequestData()\n                        .setTopics(convertToMetadataRequestTopic(topicNamesList))\n                        .setAllowAutoTopicCreation(false)\n                        .setIncludeTopicAuthorizedOperations(options.includeAuthorizedOperations()));\n                else\n                    return MetadataRequest.Builder.allTopics();\n            }\n\n            @Override\n            void handleResponse(AbstractResponse abstractResponse) {\n                MetadataResponse response = (MetadataResponse) abstractResponse;\n                // Handle server responses for particular topics.\n                Cluster cluster = response.buildCluster();\n                Map<String, Errors> errors = response.errors();\n                for (Map.Entry<String, KafkaFutureImpl<TopicDescription>> entry : topicFutures.entrySet()) {\n                    String topicName = entry.getKey();\n                    KafkaFutureImpl<TopicDescription> future = entry.getValue();\n                    Errors topicError = errors.get(topicName);\n                    if (topicError != null) {\n                        future.completeExceptionally(topicError.exception());\n                        continue;\n                    }\n                    if (!cluster.topics().contains(topicName)) {\n                        future.completeExceptionally(new UnknownTopicOrPartitionException(\"Topic \" + topicName + \" not found.\"));\n                        continue;\n                    }\n                    Uuid topicId = cluster.topicId(topicName);\n                    Integer authorizedOperations = response.topicAuthorizedOperations(topicName).get();\n                    TopicDescription topicDescription = getTopicDescriptionFromCluster(cluster, topicName, topicId, authorizedOperations);\n                    future.complete(topicDescription);\n                }\n            }\n\n            @Override\n            boolean handleUnsupportedVersionException(UnsupportedVersionException exception) {\n                if (supportsDisablingTopicCreation) {\n                    supportsDisablingTopicCreation = false;\n                    return true;\n                }\n                return false;\n            }\n\n            @Override\n            void handleFailure(Throwable throwable) {\n                completeAllExceptionally(topicFutures.values(), throwable);\n            }\n        };\n    }\n\n    private Call generateDescribeTopicsCallWithDescribeTopicPartitionsApi(\n        List<String> topicNamesList,\n        Map<String, KafkaFutureImpl<TopicDescription>> topicFutures,\n        Map<Integer, Node> nodes,\n        DescribeTopicsOptions options,\n        long now\n    ) {\n        final Map<String, TopicRequest> topicsRequests = new LinkedHashMap<>();\n        topicNamesList.stream().sorted().forEach(topic ->\n            topicsRequests.put(topic, new TopicRequest().setName(topic))\n        );\n        return new Call(\"describeTopicPartitions\", calcDeadlineMs(now, options.timeoutMs()),\n            new LeastLoadedNodeProvider()) {\n            TopicDescription partiallyFinishedTopicDescription = null;\n\n            @Override\n            DescribeTopicPartitionsRequest.Builder createRequest(int timeoutMs) {\n                DescribeTopicPartitionsRequestData request = new DescribeTopicPartitionsRequestData()\n                    .setTopics(new ArrayList<>(topicsRequests.values()))\n                    .setResponsePartitionLimit(options.partitionSizeLimitPerResponse());\n                if (partiallyFinishedTopicDescription != null) {\n                    // If the previous cursor points to partition 0, it will not be set here. Instead, the previous\n                    // cursor topic will be the first topic in the request.",
  "url": "https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java#L2081-L2230",
  "file_path": "clients/src/main/java/org/apache/kafka/clients/admin/KafkaAdminClient.java",
  "repo_name": "kafka",
  "language": "java",
  "start_line": 2081,
  "end_line": 2230,
  "last_modified": "2026-02-06T01:16:27.585045",
  "source_type": "github"
}